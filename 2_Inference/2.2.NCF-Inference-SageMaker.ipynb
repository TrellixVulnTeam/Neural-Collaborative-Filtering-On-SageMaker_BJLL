{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Module 2.2] 세이지 메이커 인퍼런스\n",
    "\n",
    "본 워크샵의 모든 노트북은 `conda_python3` 추가 패키지를 설치하고 모두 이 커널 에서 작업 합니다.\n",
    "\n",
    "- 1. 배포 준비\n",
    "- 2. 로컬 앤드포인트 생성\n",
    "- 3. 로컬 추론\n",
    "\n",
    "\n",
    "\n",
    "---    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기본 세팅\n",
    "사용하는 패키지는 import 시점에 다시 재로딩 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('./src')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이전 노트북에서 인퍼런스 테스트를 완료한 티펙트를 가져옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r artifact_path\n",
    "%store -r bucket\n",
    "%store -r prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 배포 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artifact_path:  s3://sagemaker-us-east-1-057716757052/pytorch-training-2022-05-17-11-59-58-456/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "print(\"artifact_path: \", artifact_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트 데이터 세트 로딩\n",
    "- 로컬에서 저장된 데이터를 가져와서 데이터를 변환 합니다.\n",
    "- batch_size 만큼 데이터를 로딩하는 데이터 로더를 정의 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_utils \n",
    "train_data, test_data, user_num ,item_num, train_mat = data_utils.load_all(test_num=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of epochs:  1\n"
     ]
    }
   ],
   "source": [
    "class Params:\n",
    "    def __init__(self):\n",
    "        self.epochs = 1        \n",
    "        self.num_ng = 4\n",
    "        self.batch_size = 256\n",
    "        self.test_num_ng = 99\n",
    "        self.factor_num = 32\n",
    "        self.num_layers = 3\n",
    "        self.dropout = 0.0\n",
    "        self.lr = 0.001\n",
    "        self.top_k = 10\n",
    "        self.out = True\n",
    "        self.gpu = \"0\"\n",
    "                        \n",
    "args = Params()\n",
    "print(\"# of epochs: \", args.epochs)\n",
    "\n",
    "import torch.utils.data as data\n",
    "\n",
    "test_dataset = data_utils.NCFData(\n",
    "\t\ttest_data, item_num, train_mat, 0, False)\n",
    "\n",
    "test_loader = data.DataLoader(test_dataset,\n",
    "\t\tbatch_size=args.test_num_ng+1, shuffle=False, num_workers=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user, item, label in test_loader:   \n",
    "    user_np = user.detach().cpu().numpy()\n",
    "    item_np = item.detach().cpu().numpy()            \n",
    "    break\n",
    "payload = {'user':user_np.tolist(), 'item':item_np.tolist()}\n",
    "\n",
    "# predict(inf_model, payload, top_k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 엔드포인트 생성\n",
    "- 이 과정은 세이지 메이커 엔드포인트를 생성합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "\n",
    "instance_type = 'ml.p2.xlarge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------!CPU times: user 830 ms, sys: 73 ms, total: 903 ms\n",
      "Wall time: 6min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "endpoint_name = \"sm-ncf-{}\".format(int(time.time()))\n",
    "\n",
    "\n",
    "sm_pytorch_model = PyTorchModel(model_data=artifact_path,\n",
    "                                   role=role,\n",
    "                                   entry_point='inference.py',\n",
    "                                   source_dir = 'src',\n",
    "                                   framework_version='1.8.1',\n",
    "                                   py_version='py3',\n",
    "                                   model_server_workers=1,\n",
    "                                  )\n",
    "\n",
    "sm_predictor = sm_pytorch_model.deploy(instance_type= instance_type, \n",
    "                           initial_instance_count=1, \n",
    "                           endpoint_name=endpoint_name,\n",
    "                           wait=True,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import JSONSerializer\n",
    "sm_predictor.serializer = JSONSerializer('application/json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 엔드 포인트 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 25, 273, 128, 881, 464, 175, 864,  58, 340, 174])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_predictor.predict(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "if instance_type == 'local_gpu':\n",
    "    runtime_client = sagemaker.local.LocalSagemakerRuntimeClient()    \n",
    "else:\n",
    "    runtime_client = boto3.Session().client('sagemaker-runtime')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.018736839294433594 seconds ---\n",
      "result:  ['[25, 273, 128, 881, 464, 175, 864, 58, 340, 174]']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from inference_utils import invoke_endpoint\n",
    "# https://stackoverflow.com/questions/68072684/call-sagemaker-endpoint-invoke-endpoint-in-lambda-function-question-for-request\n",
    "\n",
    "# data = json.loads(json.dumps(payload))\n",
    "payload_dump = json.dumps(payload)\n",
    "\n",
    "start_time = time.time()\n",
    "result = invoke_endpoint(runtime_client, endpoint_name, \n",
    "                         payload_dump,\n",
    "                         content_type='application/json'\n",
    "                        )\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print('result: ', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean-up\n",
    "\n",
    "위의 엔드포인트를 삭제 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Deleted model: pytorch-inference-2022-05-21-07-14-49-329\n",
      "--- Deleted endpoint: sm-ncf-1653117288\n",
      "--- Deleted endpoint_config: sm-ncf-1653117288\n"
     ]
    }
   ],
   "source": [
    "from inference_utils import delete_endpoint\n",
    "\n",
    "# client = sagemaker.local.LocalSagemakerClient()\n",
    "client = boto3.Session().client('sagemaker')\n",
    "delete_endpoint(client, endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
