{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Module 1.1] 세이지메이커에서 추론 다커 이미지 빌딩\n",
    "\n",
    "이 노트북은 아래와 같은 작업을 합니다.\n",
    "\n",
    "\n",
    "- 참고: \n",
    "- [Extending our PyTorch containers](https://sagemaker-examples.readthedocs.io/en/latest/advanced_functionality/pytorch_extending_our_containers/pytorch_extending_our_containers.html)\n",
    "- [사용자 정의 다커](https://github.com/gonsoomoon-ml/churn-prediction-workshop2/tree/master/BYOC)\n",
    "- [TorchServe on AWS](https://catalog.us-east-1.prod.workshops.aws/workshops/04eb9f59-6d25-40c5-a828-67df58b85739/en-US)\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 다커 이미지 빌당을 위한 베이스 컨테이너 이미지를 가져옴\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "registry_uri_inference: \n",
      " 763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-inference:1.8.1-gpu-py3\n",
      "ecr_uri_prefix:  057716757052.dkr.ecr.us-east-1.amazonaws.com\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import utils\n",
    "session = sagemaker.Session()\n",
    "\n",
    "region = session.boto_region_name\n",
    "client = session.boto_session.client(\n",
    "    \"sts\", region_name=region, endpoint_url=utils.sts_regional_endpoint(region)\n",
    ")\n",
    "account = client.get_caller_identity()[\"Account\"]\n",
    "\n",
    "\n",
    "region = session.boto_region_name\n",
    "\n",
    "\n",
    "registry_uri_inference = sagemaker.image_uris.retrieve(\n",
    "    framework=\"pytorch\",\n",
    "    region=region,\n",
    "    version=\"1.8.1\",\n",
    "    py_version=\"py3\",\n",
    "    instance_type=\"ml.g4dn.xlarge\",\n",
    "    image_scope=\"inference\",\n",
    ")\n",
    "\n",
    "ecr_uri_prefix = account + \".\" + \".\".join(registry_uri_inference.split(\"/\")[0].split(\".\")[1:])\n",
    "\n",
    "print(\"registry_uri_inference: \\n\", registry_uri_inference)\n",
    "print(\"ecr_uri_prefix: \", ecr_uri_prefix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# 2. 다커 이미지 빌딩\n",
    "- 추론의 다커 이미지 리파지토리 이름을 지정 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "inference_algorithm_name = \"ncf-sagemaker-inference\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 및 추론 다커 이미지에 필요한 파리미터의 값을 확인 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###### Inference  #####\n",
      " \n",
      "account:  057716757052\n",
      "region:  us-east-1\n",
      "inference_algorithm_name:  ncf-sagemaker-inference\n",
      "ecr_uri_prefix:  057716757052.dkr.ecr.us-east-1.amazonaws.com\n",
      "registry_uri_inference:  763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-inference:1.8.1-gpu-py3\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n###### Inference  #####\\n \")\n",
    "print(\"account: \", account)\n",
    "print(\"region: \", region)\n",
    "print(\"inference_algorithm_name: \", inference_algorithm_name)\n",
    "print(\"ecr_uri_prefix: \", ecr_uri_prefix)\n",
    "# print(\"registry_uri_training.split('/')[0].split('.')[0]}: \", registry_uri_training.split('/')[0].split('.')[0])\n",
    "print(\"registry_uri_inference: \", registry_uri_inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Dockerfile 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARG REGISTRY_URI\n",
      "FROM ${REGISTRY_URI}\n",
      "\n",
      "# Defines inference.py as script entrypoint\n",
      "ENV SAGEMAKER_PROGRAM inference.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! cat Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. 추론 이미지 빌딩\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/Neural-Collaborative-Filtering-On-SageMaker/2_Inference/sagemaker_inference_container/container-inference\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "Sending build context to Docker daemon  12.45MB\n",
      "Step 1/3 : ARG REGISTRY_URI\n",
      "Step 2/3 : FROM ${REGISTRY_URI}\n",
      " ---> 2e5970c79f06\n",
      "Step 3/3 : ENV SAGEMAKER_PROGRAM inference.py\n",
      " ---> Using cache\n",
      " ---> 0cc97ca7e8de\n",
      "Successfully built 0cc97ca7e8de\n",
      "Successfully tagged ncf-sagemaker-inference:latest\n",
      "The push refers to repository [057716757052.dkr.ecr.us-east-1.amazonaws.com/ncf-sagemaker-inference]\n",
      "\n",
      "\u001b[1Bcea4292f: Preparing \n",
      "\u001b[1B2e1d3444: Preparing \n",
      "\u001b[1B89a42703: Preparing \n",
      "\u001b[1B219a6846: Preparing \n",
      "\u001b[1Bd01dd820: Preparing \n",
      "\u001b[1B9cb9b79a: Preparing \n",
      "\u001b[1B1ad5eae8: Preparing \n",
      "\u001b[1B47b50780: Preparing \n",
      "\u001b[1B37cfd579: Preparing \n",
      "\u001b[1Bd4cbaa9c: Preparing \n",
      "\u001b[1Bc8c76dd0: Preparing \n",
      "\u001b[1B6d6142a3: Preparing \n",
      "\u001b[1B2e5d97c6: Preparing \n",
      "\u001b[1Bae2602a2: Preparing \n",
      "\u001b[8B47b50780: Waiting g \n",
      "\u001b[7Bd4cbaa9c: Waiting g \n",
      "\u001b[1Bd5870745: Preparing \n",
      "\u001b[1B65b30602: Preparing \n",
      "\u001b[13Bad5eae8: Waiting g \n",
      "\u001b[1B19484fba: Preparing \n",
      "\u001b[1Bb8d7120b: Preparing \n",
      "\u001b[9Bae2602a2: Waiting g \n",
      "\u001b[1Bebddd046: Preparing \n",
      "\u001b[8Bd5870745: Waiting g \n",
      "\u001b[1B9a93ca9e: Preparing \n",
      "\u001b[1Bb2730523: Preparing \n",
      "\u001b[1Baf7504f7: Preparing \n",
      "\u001b[11B5b30602: Waiting g \n",
      "\u001b[1B9f547566: Preparing \n",
      "\u001b[1B61aa0ac3: Preparing \n",
      "\u001b[1Bb56be259: Layer already exists \u001b[26A\u001b[2K\u001b[21A\u001b[2K\u001b[16A\u001b[2K\u001b[11A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2Klatest: digest: sha256:13eef85899d48abe1b33f754dcfe9140f03e7afe835b6909c1e2702dad3cdfc7 size: 6837\n",
      "CPU times: user 45.1 ms, sys: 15.3 ms, total: 60.4 ms\n",
      "Wall time: 2.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "! /bin/bash build_push_inference.sh {account} {region} {inference_algorithm_name} {ecr_uri_prefix} {registry_uri_inference.split('/')[0].split('.')[0]} {registry_uri_inference}\n",
    "# ! /bin/bash ./container-inference/build_push_inference.sh {account} {region} {inference_algorithm_name} {ecr_uri_prefix} {registry_uri_inference.split('/')[0].split('.')[0]} {registry_uri_inference}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Docker Image 관련 변수 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference_docker_image: \n",
      " 057716757052.dkr.ecr.us-east-1.amazonaws.com/ncf-sagemaker-inference\n"
     ]
    }
   ],
   "source": [
    "inference_docker_image = f\"{ecr_uri_prefix}/{inference_algorithm_name}\"\n",
    "print(\"inference_docker_image: \\n\", inference_docker_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'inference_docker_image' (str)\n"
     ]
    }
   ],
   "source": [
    "%store inference_docker_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
