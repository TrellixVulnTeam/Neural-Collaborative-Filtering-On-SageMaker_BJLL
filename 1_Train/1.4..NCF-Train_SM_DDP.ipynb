{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Module 1.4] SM DDP 분산 훈련\n",
    "\n",
    "### 본 워크샵의 모든 노트북은 `conda_python3` 여기에서 작업 합니다.\n",
    "### 이 노트북은 ml.p3.16xlarge 이상의 노트북 인스턴스에서 실행이 가능합니다.\n",
    "\n",
    "이 노트북은 아래와 같은 작업을 합니다.\n",
    "- 1. 환경 셋업\n",
    "- 2. 세이지 메이크 로컬 모드 훈련\n",
    "- 3. SageMaker Host Mode 로 훈련\n",
    "- 4. 모델 아티펙트 저장\n",
    " \n",
    "---\n",
    "\n",
    "### 참고\n",
    "- [Amazon SageMaker Distributed Training Libraries](https://docs.aws.amazon.com/sagemaker/latest/dg/distributed-training.html)\n",
    "- [Amazon SageMaker Distributed Training Notebook Examples](https://docs.aws.amazon.com/sagemaker/latest/dg/distributed-training-notebook-examples.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 환경 셋업"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기본 세팅\n",
    "사용하는 패키지는 import 시점에 다시 재로딩 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('./src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 커스텀 라이브러리\n",
    "import config "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "버킷 및 폴더(prefix) 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "use_default_bucket = True\n",
    "if use_default_bucket:\n",
    "    bucket = sagemaker_session.default_bucket()\n",
    "else:\n",
    "    bucket = '<Type your bucket>'\n",
    "    \n",
    "prefix = \"NCFModel\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 세이지 메이크 로컬 모드 훈련\n",
    "#### 로컬의 GPU, CPU 여부로 instance_type 결정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance type = local_gpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "\n",
    "try:\n",
    "    if subprocess.call(\"nvidia-smi\") == 0:\n",
    "        ## Set type to GPU if one is present\n",
    "        instance_type = \"local_gpu\"\n",
    "    else:\n",
    "        instance_type = \"local\"        \n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(\"Instance type = \" + instance_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. 스크립트 모드의 코드 작성 방법\n",
    "- ![script_mode_example](img/script_mode_example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.훈련 코드 확인\n",
    "- 아래의 코드는 전형적인 스크립트 모드의 코드 작성 방법을 따르고 있습니다.\n",
    "- 훈련 함수는 `from train_lib import train` 로서 이전 노트북의 **[세이지 메이커 없이]** 작성한 스크래치 버전에서 사용한 훈련 함수와 동일 합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_code = 'src/train_horovod.py'\n",
    "# !pygmentize {train_code}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. 로컬에 있는 데이타 세트의 위치를 지정 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_inputs:  ../data/\n"
     ]
    }
   ],
   "source": [
    "local_inputs = config.main_path\n",
    "print(\"local_inputs: \", local_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_inputs = {'train': f'file://{local_inputs}',\n",
    "          'test': f'file://{local_inputs}'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. 로컬 모드로 훈련 실행\n",
    "- 아래의 두 라인이 로컬모드로 훈련을 지시 합니다.\n",
    "```python\n",
    "    instance_type=instance_type, # local_gpu or local 지정\n",
    "    session = sagemaker.LocalSession(), # 로컬 세션을 사용합니다.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {'epochs': 1, \n",
    "                   'lr': 0.001,\n",
    "                   'batch_size': 256,\n",
    "                   'top_k' : 10,\n",
    "                   'dropout' : 0.0,\n",
    "                   'factor_num' : 32,\n",
    "                   'num_layers' : 3,\n",
    "                   'num_ng' : 4,\n",
    "                   'test_num_ng' : 99,  \n",
    "                    'log_interval': 500                                           \n",
    "                    }  \n",
    "\n",
    "distribution = {\"smdistributed\": \n",
    "                {\"dataparallel\": \n",
    "                 {\"enabled\": True}\n",
    "                }\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dlt1mbzjtr-algo-1-fzp46 ... \n",
      "Creating dlt1mbzjtr-algo-1-fzp46 ... done\n",
      "Attaching to dlt1mbzjtr-algo-1-fzp46\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m 2022-05-30 06:40:24,429 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m 2022-05-30 06:40:24,507 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m 2022-05-30 06:40:24,510 sagemaker_pytorch_container.training INFO     Invoking SMDataParallel\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m 2022-05-30 06:40:24,511 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m 2022-05-30 06:40:24,724 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m /opt/conda/bin/python3.6 -m pip install -r requirements.txt\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m Requirement already satisfied: nvidia-ml-py3==7.352 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (7.352.0)\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m Collecting pandas==0.24.2\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m   Downloading pandas-0.24.2-cp36-cp36m-manylinux1_x86_64.whl (10.1 MB)\n",
      "     |████████████████████████████████| 10.1 MB 25.2 MB/s            \n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m \u001b[?25hCollecting numpy==1.16.6\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m   Downloading numpy-1.16.6-cp36-cp36m-manylinux1_x86_64.whl (17.4 MB)\n",
      "     |████████████████████████████████| 17.4 MB 46.6 MB/s            \n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m \u001b[?25hRequirement already satisfied: torch==1.8.1 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 4)) (1.8.1)\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m Collecting gensim==3.7.1\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m   Downloading gensim-3.7.1-cp36-cp36m-manylinux1_x86_64.whl (24.2 MB)\n",
      "     |████████████████████████████████| 24.2 MB 39.0 MB/s            \n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m \u001b[?25hCollecting tensorboardX==1.6\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m   Downloading tensorboardX-1.6-py2.py3-none-any.whl (129 kB)\n",
      "     |████████████████████████████████| 129 kB 73.8 MB/s            \n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m \u001b[?25hRequirement already satisfied: pytz>=2011k in /opt/conda/lib/python3.6/site-packages (from pandas==0.24.2->-r requirements.txt (line 2)) (2021.3)\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m Requirement already satisfied: python-dateutil>=2.5.0 in /opt/conda/lib/python3.6/site-packages (from pandas==0.24.2->-r requirements.txt (line 2)) (2.8.2)\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.6/site-packages (from torch==1.8.1->-r requirements.txt (line 4)) (3.10.0.2)\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from torch==1.8.1->-r requirements.txt (line 4)) (0.8)\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m Requirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.6/site-packages (from gensim==3.7.1->-r requirements.txt (line 5)) (1.5.4)\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m Requirement already satisfied: smart-open>=1.7.0 in /opt/conda/lib/python3.6/site-packages (from gensim==3.7.1->-r requirements.txt (line 5)) (5.2.1)\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m Requirement already satisfied: six>=1.5.0 in /opt/conda/lib/python3.6/site-packages (from gensim==3.7.1->-r requirements.txt (line 5)) (1.16.0)\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m Requirement already satisfied: protobuf>=3.2.0 in /opt/conda/lib/python3.6/site-packages (from tensorboardX==1.6->-r requirements.txt (line 6)) (3.19.1)\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m Installing collected packages: numpy, tensorboardX, pandas, gensim\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m   Attempting uninstall: numpy\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m     Found existing installation: numpy 1.19.1\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m     Uninstalling numpy-1.19.1:\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m       Successfully uninstalled numpy-1.19.1\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m   Attempting uninstall: pandas\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m     Found existing installation: pandas 1.1.5\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m     Uninstalling pandas-1.1.5:\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m       Successfully uninstalled pandas-1.1.5\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m Successfully installed gensim-3.7.1 numpy-1.16.6 pandas-0.24.2 tensorboardX-1.6\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m \n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m 2022-05-30 06:40:36,748 sagemaker-training-toolkit INFO     Starting MPI run as worker node.\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m 2022-05-30 06:40:36,749 sagemaker-training-toolkit INFO     Creating SSH daemon.\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m 2022-05-30 06:40:36,751 sagemaker-training-toolkit INFO     Waiting for MPI workers to establish their SSH connections\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m 2022-05-30 06:40:36,752 sagemaker-training-toolkit INFO     Network interface name: eth0\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m 2022-05-30 06:40:36,752 sagemaker-training-toolkit INFO     Host: ['algo-1-fzp46']\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m 2022-05-30 06:40:36,753 sagemaker-training-toolkit INFO     instance type: local_gpu\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m 2022-05-30 06:40:36,830 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m \n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m Training Env:\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m \n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m {\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m     \"additional_framework_parameters\": {\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m         \"sagemaker_distributed_dataparallel_enabled\": true,\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m         \"sagemaker_instance_type\": \"local_gpu\",\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m         \"sagemaker_distributed_dataparallel_custom_mpi_options\": \"\"\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m     },\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m         \"train\": \"/opt/ml/input/data/train\",\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m         \"test\": \"/opt/ml/input/data/test\"\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m     },\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m     \"current_host\": \"algo-1-fzp46\",\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m     \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m     \"hosts\": [\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m         \"algo-1-fzp46\"\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m     ],\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m         \"epochs\": 1,\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m         \"lr\": 0.001,\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m         \"batch_size\": 256,\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m         \"top_k\": 10,\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m         \"dropout\": 0.0,\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m         \"factor_num\": 32,\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m         \"num_layers\": 3,\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m         \"num_ng\": 4,\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m         \"test_num_ng\": 99,\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m         \"log_interval\": 500\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m     },\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m         \"train\": {\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m         },\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m         \"test\": {\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m         }\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m     },\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m     \"job_name\": \"pytorch-training-2022-05-30-06-40-21-138\",\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m     \"master_hostname\": \"algo-1-fzp46\",\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-057716757052/pytorch-training-2022-05-30-06-40-21-138/source/sourcedir.tar.gz\",\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m     \"module_name\": \"train_sm_ddp\",\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m     \"num_cpus\": 64,\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m     \"num_gpus\": 8,\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m         \"current_host\": \"algo-1-fzp46\",\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m         \"hosts\": [\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m             \"algo-1-fzp46\"\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m         ]\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m     },\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m     \"user_entry_point\": \"train_sm_ddp.py\"\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m }\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m \n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m Environment variables:\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m \n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m SM_HOSTS=[\"algo-1-fzp46\"]\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m SM_HPS={\"batch_size\":256,\"dropout\":0.0,\"epochs\":1,\"factor_num\":32,\"log_interval\":500,\"lr\":0.001,\"num_layers\":3,\"num_ng\":4,\"test_num_ng\":99,\"top_k\":10}\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m SM_USER_ENTRY_POINT=train_sm_ddp.py\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m SM_FRAMEWORK_PARAMS={\"sagemaker_distributed_dataparallel_custom_mpi_options\":\"\",\"sagemaker_distributed_dataparallel_enabled\":true,\"sagemaker_instance_type\":\"local_gpu\"}\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-fzp46\",\"hosts\":[\"algo-1-fzp46\"]}\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m SM_INPUT_DATA_CONFIG={\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m SM_CHANNELS=[\"test\",\"train\"]\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m SM_CURRENT_HOST=algo-1-fzp46\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m SM_MODULE_NAME=train_sm_ddp\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m SM_NUM_CPUS=64\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m SM_NUM_GPUS=8\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-057716757052/pytorch-training-2022-05-30-06-40-21-138/source/sourcedir.tar.gz\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_distributed_dataparallel_custom_mpi_options\":\"\",\"sagemaker_distributed_dataparallel_enabled\":true,\"sagemaker_instance_type\":\"local_gpu\"},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1-fzp46\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1-fzp46\"],\"hyperparameters\":{\"batch_size\":256,\"dropout\":0.0,\"epochs\":1,\"factor_num\":32,\"log_interval\":500,\"lr\":0.001,\"num_layers\":3,\"num_ng\":4,\"test_num_ng\":99,\"top_k\":10},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2022-05-30-06-40-21-138\",\"log_level\":20,\"master_hostname\":\"algo-1-fzp46\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-057716757052/pytorch-training-2022-05-30-06-40-21-138/source/sourcedir.tar.gz\",\"module_name\":\"train_sm_ddp\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-fzp46\",\"hosts\":[\"algo-1-fzp46\"]},\"user_entry_point\":\"train_sm_ddp.py\"}\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m SM_USER_ARGS=[\"--batch_size\",\"256\",\"--dropout\",\"0.0\",\"--epochs\",\"1\",\"--factor_num\",\"32\",\"--log_interval\",\"500\",\"--lr\",\"0.001\",\"--num_layers\",\"3\",\"--num_ng\",\"4\",\"--test_num_ng\",\"99\",\"--top_k\",\"10\"]\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m SM_CHANNEL_TEST=/opt/ml/input/data/test\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m SM_HP_EPOCHS=1\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m SM_HP_LR=0.001\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m SM_HP_BATCH_SIZE=256\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m SM_HP_TOP_K=10\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m SM_HP_DROPOUT=0.0\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m SM_HP_FACTOR_NUM=32\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m SM_HP_NUM_LAYERS=3\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m SM_HP_NUM_NG=4\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m SM_HP_TEST_NUM_NG=99\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m SM_HP_LOG_INTERVAL=500\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m \n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m \n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m mpirun --host algo-1-fzp46 -np 8 --allow-run-as-root --tag-output --oversubscribe -mca btl_tcp_if_include eth0 -mca oob_tcp_if_include eth0 -mca plm_rsh_no_tree_spawn 1 -mca pml ob1 -mca btl ^openib -mca orte_abort_on_non_zero_status 1 -mca btl_vader_single_copy_mechanism none -mca plm_rsh_num_concurrent 1 -x NCCL_SOCKET_IFNAME=eth0 -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH -x SMDATAPARALLEL_USE_SINGLENODE=1 -x FI_PROVIDER=efa -x RDMAV_FORK_SAFE=1 -x LD_PRELOAD=/opt/conda/lib/python3.6/site-packages/gethostname.cpython-36m-x86_64-linux-gnu.so smddprun /opt/conda/bin/python3.6 -m mpi4py train_sm_ddp.py --batch_size 256 --dropout 0.0 --epochs 1 --factor_num 32 --log_interval 500 --lr 0.001 --num_layers 3 --num_ng 4 --test_num_ng 99 --top_k 10\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m \n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m \n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Bootstrap : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO NET/Socket : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Using network Socket\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:NCCL version 2.7.8+cuda11.1\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Bootstrap : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Bootstrap : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Bootstrap : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Bootstrap : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Bootstrap : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Bootstrap : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Bootstrap : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO NET/Socket : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Using network Socket\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO NET/Socket : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Using network Socket\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO NET/Socket : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Using network Socket\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO NET/Socket : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Using network Socket\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO NET/Socket : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Using network Socket\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO NET/Socket : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Using network Socket\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] find_ofi_provider:542 NCCL WARN NET/OFI Couldn't find any optimal provider\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO NET/Socket : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Using network Socket\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Trees [0] 1/-1/-1->2->3|3->2->1/-1/-1 [1] 1/-1/-1->2->3|3->2->1/-1/-1 [2] 3/-1/-1->2->1|1->2->3/-1/-1 [3] 3/-1/-1->2->1|1->2->3/-1/-1 [4] -1/-1/-1->2->6|6->2->-1/-1/-1 [5] 6/-1/-1->2->0|0->2->6/-1/-1 [6] 1/-1/-1->2->3|3->2->1/-1/-1 [7] 1/-1/-1->2->3|3->2->1/-1/-1 [8] 3/-1/-1->2->1|1->2->3/-1/-1 [9] 3/-1/-1->2->1|1->2->3/-1/-1 [10] -1/-1/-1->2->6|6->2->-1/-1/-1 [11] 6/-1/-1->2->0|0->2->6/-1/-1\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Trees [0] 2/-1/-1->3->0|0->3->2/-1/-1 [1] 2/-1/-1->3->0|0->3->2/-1/-1 [2] -1/-1/-1->3->2|2->3->-1/-1/-1 [3] -1/-1/-1->3->2|2->3->-1/-1/-1 [4] 7/-1/-1->3->1|1->3->7/-1/-1 [5] 1/-1/-1->3->7|7->3->1/-1/-1 [6] 2/-1/-1->3->0|0->3->2/-1/-1 [7] 2/-1/-1->3->0|0->3->2/-1/-1 [8] -1/-1/-1->3->2|2->3->-1/-1/-1 [9] -1/-1/-1->3->2|2->3->-1/-1/-1 [10] 7/-1/-1->3->1|1->3->7/-1/-1 [11] 1/-1/-1->3->7|7->3->1/-1/-1\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Trees [0] -1/-1/-1->4->7|7->4->-1/-1/-1 [1] -1/-1/-1->4->7|7->4->-1/-1/-1 [2] 7/-1/-1->4->0|0->4->7/-1/-1 [3] 7/-1/-1->4->0|0->4->7/-1/-1 [4] 6/-1/-1->4->5|5->4->6/-1/-1 [5] 5/-1/-1->4->6|6->4->5/-1/-1 [6] -1/-1/-1->4->7|7->4->-1/-1/-1 [7] -1/-1/-1->4->7|7->4->-1/-1/-1 [8] 7/-1/-1->4->0|0->4->7/-1/-1 [9] 7/-1/-1->4->0|0->4->7/-1/-1 [10] 6/-1/-1->4->5|5->4->6/-1/-1 [11] 5/-1/-1->4->6|6->4->5/-1/-1\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Trees [0] 6/-1/-1->5->1|1->5->6/-1/-1 [1] 6/-1/-1->5->1|1->5->6/-1/-1 [2] 1/-1/-1->5->6|6->5->1/-1/-1 [3] 1/-1/-1->5->6|6->5->1/-1/-1 [4] 4/-1/-1->5->7|7->5->4/-1/-1 [5] 7/-1/-1->5->4|4->5->7/-1/-1 [6] 6/-1/-1->5->1|1->5->6/-1/-1 [7] 6/-1/-1->5->1|1->5->6/-1/-1 [8] 1/-1/-1->5->6|6->5->1/-1/-1 [9] 1/-1/-1->5->6|6->5->1/-1/-1 [10] 4/-1/-1->5->7|7->5->4/-1/-1 [11] 7/-1/-1->5->4|4->5->7/-1/-1\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Trees [0] 7/-1/-1->6->5|5->6->7/-1/-1 [1] 7/-1/-1->6->5|5->6->7/-1/-1 [2] 5/-1/-1->6->7|7->6->5/-1/-1 [3] 5/-1/-1->6->7|7->6->5/-1/-1 [4] 2/-1/-1->6->4|4->6->2/-1/-1 [5] 4/-1/-1->6->2|2->6->4/-1/-1 [6] 7/-1/-1->6->5|5->6->7/-1/-1 [7] 7/-1/-1->6->5|5->6->7/-1/-1 [8] 5/-1/-1->6->7|7->6->5/-1/-1 [9] 5/-1/-1->6->7|7->6->5/-1/-1 [10] 2/-1/-1->6->4|4->6->2/-1/-1 [11] 4/-1/-1->6->2|2->6->4/-1/-1\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Trees [0] 4/-1/-1->7->6|6->7->4/-1/-1 [1] 4/-1/-1->7->6|6->7->4/-1/-1 [2] 6/-1/-1->7->4|4->7->6/-1/-1 [3] 6/-1/-1->7->4|4->7->6/-1/-1 [4] 5/-1/-1->7->3|3->7->5/-1/-1 [5] 3/-1/-1->7->5|5->7->3/-1/-1 [6] 4/-1/-1->7->6|6->7->4/-1/-1 [7] 4/-1/-1->7->6|6->7->4/-1/-1 [8] 6/-1/-1->7->4|4->7->6/-1/-1 [9] 6/-1/-1->7->4|4->7->6/-1/-1 [10] 5/-1/-1->7->3|3->7->5/-1/-1 [11] 3/-1/-1->7->5|5->7->3/-1/-1\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Channel 00/12 :    0   3   2   1   5   6   7   4\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Channel 01/12 :    0   3   2   1   5   6   7   4\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Channel 02/12 :    0   4   7   6   5   1   2   3\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Trees [0] 5/-1/-1->1->2|2->1->5/-1/-1 [1] 5/-1/-1->1->2|2->1->5/-1/-1 [2] 2/-1/-1->1->5|5->1->2/-1/-1 [3] 2/-1/-1->1->5|5->1->2/-1/-1 [4] 3/-1/-1->1->0|0->1->3/-1/-1 [5] -1/-1/-1->1->3|3->1->-1/-1/-1 [6] 5/-1/-1->1->2|2->1->5/-1/-1 [7] 5/-1/-1->1->2|2->1->5/-1/-1 [8] 2/-1/-1->1->5|5->1->2/-1/-1 [9] 2/-1/-1->1->5|5->1->2/-1/-1 [10] 3/-1/-1->1->0|0->1->3/-1/-1 [11] -1/-1/-1->1->3|3->1->-1/-1/-1\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Channel 03/12 :    0   4   7   6   5   1   2   3\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Channel 04/12 :    0   1   3   7   5   4   6   2\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Channel 05/12 :    0   2   6   4   5   7   3   1\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Channel 06/12 :    0   3   2   1   5   6   7   4\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Channel 07/12 :    0   3   2   1   5   6   7   4\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Channel 08/12 :    0   4   7   6   5   1   2   3\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Channel 09/12 :    0   4   7   6   5   1   2   3\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Channel 10/12 :    0   1   3   7   5   4   6   2\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Channel 11/12 :    0   2   6   4   5   7   3   1\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Trees [0] 3/-1/-1->0->-1|-1->0->3/-1/-1 [1] 3/-1/-1->0->-1|-1->0->3/-1/-1 [2] 4/-1/-1->0->-1|-1->0->4/-1/-1 [3] 4/-1/-1->0->-1|-1->0->4/-1/-1 [4] 1/-1/-1->0->-1|-1->0->1/-1/-1 [5] 2/-1/-1->0->-1|-1->0->2/-1/-1 [6] 3/-1/-1->0->-1|-1->0->3/-1/-1 [7] 3/-1/-1->0->-1|-1->0->3/-1/-1 [8] 4/-1/-1->0->-1|-1->0->4/-1/-1 [9] 4/-1/-1->0->-1|-1->0->4/-1/-1 [10] 1/-1/-1->0->-1|-1->0->1/-1/-1 [11] 2/-1/-1->0->-1|-1->0->2/-1/-1\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Channel 00 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Channel 00 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Channel 00 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Channel 00 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Channel 00 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Channel 00 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Channel 00 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Channel 00 : 0[170] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Channel 00 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Channel 00 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Channel 00 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Channel 00 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Channel 00 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Channel 00 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Channel 00 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Channel 01 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Channel 01 : 0[170] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Channel 01 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Channel 01 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Channel 01 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Channel 01 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Channel 01 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Channel 01 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Channel 01 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Channel 01 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Channel 01 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Channel 01 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Channel 01 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Channel 01 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Channel 01 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Channel 02 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Channel 02 : 0[170] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Channel 02 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Channel 02 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Channel 02 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Channel 02 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Channel 02 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Channel 02 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Channel 02 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Channel 02 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Channel 02 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Channel 02 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Channel 02 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Channel 02 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Channel 02 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Channel 03 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Channel 03 : 0[170] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Channel 03 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Channel 03 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Channel 03 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Channel 03 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Channel 03 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Channel 03 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Channel 03 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Channel 03 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Channel 03 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Channel 03 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Channel 03 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Channel 03 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Channel 03 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Channel 04 : 3[1a0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Channel 04 : 0[170] -> 1[180] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Channel 04 : 4[1b0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Channel 04 : 2[190] -> 0[170] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Channel 04 : 5[1c0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Channel 04 : 1[180] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Channel 04 : 7[1e0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Channel 04 : 6[1d0] -> 2[190] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Channel 04 : 2[190] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Channel 04 : 3[1a0] -> 1[180] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Channel 04 : 4[1b0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Channel 04 : 5[1c0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Channel 04 : 6[1d0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Channel 04 : 1[180] -> 0[170] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Channel 04 : 7[1e0] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Channel 05 : 2[190] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Channel 05 : 3[1a0] -> 1[180] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Channel 05 : 4[1b0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Channel 05 : 0[170] -> 2[190] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Channel 05 : 5[1c0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Channel 05 : 7[1e0] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Channel 05 : 1[180] -> 0[170] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Channel 05 : 6[1d0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Channel 05 : 1[180] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Channel 05 : 2[190] -> 0[170] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Channel 05 : 3[1a0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Channel 05 : 4[1b0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Channel 05 : 5[1c0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Channel 05 : 7[1e0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Channel 05 : 6[1d0] -> 2[190] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Channel 06 : 0[170] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Channel 06 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Channel 06 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Channel 06 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Channel 06 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Channel 06 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Channel 06 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Channel 06 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Channel 06 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Channel 06 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Channel 06 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Channel 06 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Channel 06 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Channel 06 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Channel 06 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Channel 07 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Channel 07 : 0[170] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Channel 07 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Channel 07 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Channel 07 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Channel 07 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Channel 07 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Channel 07 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Channel 07 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Channel 07 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Channel 07 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Channel 07 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Channel 07 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Channel 07 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Channel 07 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Channel 08 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Channel 08 : 0[170] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Channel 08 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Channel 08 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Channel 08 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Channel 08 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Channel 08 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Channel 08 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Channel 08 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Channel 08 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Channel 08 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Channel 08 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Channel 08 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Channel 08 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Channel 08 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Channel 09 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Channel 09 : 0[170] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Channel 09 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Channel 09 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Channel 09 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Channel 09 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Channel 09 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Channel 09 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Channel 09 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Channel 09 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Channel 09 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Channel 09 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Channel 09 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Channel 09 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Channel 09 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Channel 10 : 3[1a0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Channel 10 : 0[170] -> 1[180] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Channel 10 : 1[180] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Channel 10 : 4[1b0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Channel 10 : 2[190] -> 0[170] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Channel 10 : 5[1c0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Channel 10 : 7[1e0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Channel 10 : 6[1d0] -> 2[190] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Channel 10 : 2[190] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Channel 10 : 3[1a0] -> 1[180] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Channel 10 : 1[180] -> 0[170] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Channel 10 : 4[1b0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Channel 10 : 5[1c0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Channel 10 : 6[1d0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Channel 10 : 7[1e0] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Channel 11 : 2[190] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Channel 11 : 0[170] -> 2[190] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Channel 11 : 1[180] -> 0[170] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Channel 11 : 3[1a0] -> 1[180] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Channel 11 : 4[1b0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Channel 11 : 5[1c0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Channel 11 : 7[1e0] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Channel 11 : 6[1d0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Channel 11 : 1[180] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Channel 11 : 2[190] -> 0[170] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Channel 11 : 3[1a0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Channel 11 : 4[1b0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Channel 11 : 5[1c0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Channel 11 : 7[1e0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Channel 11 : 6[1d0] -> 2[190] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO comm 0x5577b591ab00 rank 1 nranks 8 cudaDev 1 busId 180 - Init COMPLETE\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO comm 0x55be07e03b90 rank 0 nranks 8 cudaDev 0 busId 170 - Init COMPLETE\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO comm 0x55a891bcb090 rank 3 nranks 8 cudaDev 3 busId 1a0 - Init COMPLETE\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO comm 0x561c4a16ae10 rank 2 nranks 8 cudaDev 2 busId 190 - Init COMPLETE\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO comm 0x55f2242ebd70 rank 4 nranks 8 cudaDev 4 busId 1b0 - Init COMPLETE\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO comm 0x5633e7e9c930 rank 5 nranks 8 cudaDev 5 busId 1c0 - Init COMPLETE\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO comm 0x55c5f65c61c0 rank 7 nranks 8 cudaDev 7 busId 1e0 - Init COMPLETE\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO comm 0x564c321ae6e0 rank 6 nranks 8 cudaDev 6 busId 1d0 - Init COMPLETE\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Trees [0] 4/-1/-1->7->6|6->7->4/-1/-1 [1] 4/-1/-1->7->6|6->7->4/-1/-1 [2] 6/-1/-1->7->4|4->7->6/-1/-1 [3] 6/-1/-1->7->4|4->7->6/-1/-1 [4] 5/-1/-1->7->3|3->7->5/-1/-1 [5] 3/-1/-1->7->5|5->7->3/-1/-1 [6] 4/-1/-1->7->6|6->7->4/-1/-1 [7] 4/-1/-1->7->6|6->7->4/-1/-1 [8] 6/-1/-1->7->4|4->7->6/-1/-1 [9] 6/-1/-1->7->4|4->7->6/-1/-1 [10] 5/-1/-1->7->3|3->7->5/-1/-1 [11] 3/-1/-1->7->5|5->7->3/-1/-1\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Trees [0] 7/-1/-1->6->5|5->6->7/-1/-1 [1] 7/-1/-1->6->5|5->6->7/-1/-1 [2] 5/-1/-1->6->7|7->6->5/-1/-1 [3] 5/-1/-1->6->7|7->6->5/-1/-1 [4] 2/-1/-1->6->4|4->6->2/-1/-1 [5] 4/-1/-1->6->2|2->6->4/-1/-1 [6] 7/-1/-1->6->5|5->6->7/-1/-1 [7] 7/-1/-1->6->5|5->6->7/-1/-1 [8] 5/-1/-1->6->7|7->6->5/-1/-1 [9] 5/-1/-1->6->7|7->6->5/-1/-1 [10] 2/-1/-1->6->4|4->6->2/-1/-1 [11] 4/-1/-1->6->2|2->6->4/-1/-1\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Channel 00/12 :    0   3   2   1   5   6   7   4\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Channel 01/12 :    0   3   2   1   5   6   7   4\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Channel 02/12 :    0   4   7   6   5   1   2   3\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Channel 03/12 :    0   4   7   6   5   1   2   3\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Channel 04/12 :    0   1   3   7   5   4   6   2\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Channel 05/12 :    0   2   6   4   5   7   3   1\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Channel 06/12 :    0   3   2   1   5   6   7   4\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Channel 07/12 :    0   3   2   1   5   6   7   4\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Channel 08/12 :    0   4   7   6   5   1   2   3\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Trees [0] 5/-1/-1->1->2|2->1->5/-1/-1 [1] 5/-1/-1->1->2|2->1->5/-1/-1 [2] 2/-1/-1->1->5|5->1->2/-1/-1 [3] 2/-1/-1->1->5|5->1->2/-1/-1 [4] 3/-1/-1->1->0|0->1->3/-1/-1 [5] -1/-1/-1->1->3|3->1->-1/-1/-1 [6] 5/-1/-1->1->2|2->1->5/-1/-1 [7] 5/-1/-1->1->2|2->1->5/-1/-1 [8] 2/-1/-1->1->5|5->1->2/-1/-1 [9] 2/-1/-1->1->5|5->1->2/-1/-1 [10] 3/-1/-1->1->0|0->1->3/-1/-1 [11] -1/-1/-1->1->3|3->1->-1/-1/-1\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Channel 09/12 :    0   4   7   6   5   1   2   3\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Channel 10/12 :    0   1   3   7   5   4   6   2\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Channel 11/12 :    0   2   6   4   5   7   3   1\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Trees [0] 1/-1/-1->2->3|3->2->1/-1/-1 [1] 1/-1/-1->2->3|3->2->1/-1/-1 [2] 3/-1/-1->2->1|1->2->3/-1/-1 [3] 3/-1/-1->2->1|1->2->3/-1/-1 [4] -1/-1/-1->2->6|6->2->-1/-1/-1 [5] 6/-1/-1->2->0|0->2->6/-1/-1 [6] 1/-1/-1->2->3|3->2->1/-1/-1 [7] 1/-1/-1->2->3|3->2->1/-1/-1 [8] 3/-1/-1->2->1|1->2->3/-1/-1 [9] 3/-1/-1->2->1|1->2->3/-1/-1 [10] -1/-1/-1->2->6|6->2->-1/-1/-1 [11] 6/-1/-1->2->0|0->2->6/-1/-1\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Trees [0] 2/-1/-1->3->0|0->3->2/-1/-1 [1] 2/-1/-1->3->0|0->3->2/-1/-1 [2] -1/-1/-1->3->2|2->3->-1/-1/-1 [3] -1/-1/-1->3->2|2->3->-1/-1/-1 [4] 7/-1/-1->3->1|1->3->7/-1/-1 [5] 1/-1/-1->3->7|7->3->1/-1/-1 [6] 2/-1/-1->3->0|0->3->2/-1/-1 [7] 2/-1/-1->3->0|0->3->2/-1/-1 [8] -1/-1/-1->3->2|2->3->-1/-1/-1 [9] -1/-1/-1->3->2|2->3->-1/-1/-1 [10] 7/-1/-1->3->1|1->3->7/-1/-1 [11] 1/-1/-1->3->7|7->3->1/-1/-1\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Trees [0] -1/-1/-1->4->7|7->4->-1/-1/-1 [1] -1/-1/-1->4->7|7->4->-1/-1/-1 [2] 7/-1/-1->4->0|0->4->7/-1/-1 [3] 7/-1/-1->4->0|0->4->7/-1/-1 [4] 6/-1/-1->4->5|5->4->6/-1/-1 [5] 5/-1/-1->4->6|6->4->5/-1/-1 [6] -1/-1/-1->4->7|7->4->-1/-1/-1 [7] -1/-1/-1->4->7|7->4->-1/-1/-1 [8] 7/-1/-1->4->0|0->4->7/-1/-1 [9] 7/-1/-1->4->0|0->4->7/-1/-1 [10] 6/-1/-1->4->5|5->4->6/-1/-1 [11] 5/-1/-1->4->6|6->4->5/-1/-1\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Trees [0] 3/-1/-1->0->-1|-1->0->3/-1/-1 [1] 3/-1/-1->0->-1|-1->0->3/-1/-1 [2] 4/-1/-1->0->-1|-1->0->4/-1/-1 [3] 4/-1/-1->0->-1|-1->0->4/-1/-1 [4] 1/-1/-1->0->-1|-1->0->1/-1/-1 [5] 2/-1/-1->0->-1|-1->0->2/-1/-1 [6] 3/-1/-1->0->-1|-1->0->3/-1/-1 [7] 3/-1/-1->0->-1|-1->0->3/-1/-1 [8] 4/-1/-1->0->-1|-1->0->4/-1/-1 [9] 4/-1/-1->0->-1|-1->0->4/-1/-1 [10] 1/-1/-1->0->-1|-1->0->1/-1/-1 [11] 2/-1/-1->0->-1|-1->0->2/-1/-1\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Trees [0] 6/-1/-1->5->1|1->5->6/-1/-1 [1] 6/-1/-1->5->1|1->5->6/-1/-1 [2] 1/-1/-1->5->6|6->5->1/-1/-1 [3] 1/-1/-1->5->6|6->5->1/-1/-1 [4] 4/-1/-1->5->7|7->5->4/-1/-1 [5] 7/-1/-1->5->4|4->5->7/-1/-1 [6] 6/-1/-1->5->1|1->5->6/-1/-1 [7] 6/-1/-1->5->1|1->5->6/-1/-1 [8] 1/-1/-1->5->6|6->5->1/-1/-1 [9] 1/-1/-1->5->6|6->5->1/-1/-1 [10] 4/-1/-1->5->7|7->5->4/-1/-1 [11] 7/-1/-1->5->4|4->5->7/-1/-1\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Channel 00 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Channel 00 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Channel 00 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Channel 00 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Channel 00 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Channel 00 : 0[170] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Channel 00 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Channel 00 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Channel 00 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Channel 00 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Channel 00 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Channel 00 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Channel 00 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Channel 00 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Channel 00 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Channel 01 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Channel 01 : 0[170] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Channel 01 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Channel 01 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Channel 01 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Channel 01 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Channel 01 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Channel 01 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Channel 01 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Channel 01 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Channel 01 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Channel 01 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Channel 01 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Channel 01 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Channel 01 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Channel 02 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Channel 02 : 0[170] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Channel 02 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Channel 02 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Channel 02 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Channel 02 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Channel 02 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Channel 02 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Channel 02 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Channel 02 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Channel 02 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Channel 02 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Channel 02 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Channel 02 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Channel 02 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Channel 03 : 0[170] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Channel 03 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Channel 03 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Channel 03 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Channel 03 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Channel 03 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Channel 03 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Channel 03 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Channel 03 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Channel 03 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Channel 03 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Channel 03 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Channel 03 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Channel 03 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Channel 03 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Channel 04 : 0[170] -> 1[180] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Channel 04 : 3[1a0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Channel 04 : 4[1b0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Channel 04 : 6[1d0] -> 2[190] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Channel 04 : 7[1e0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Channel 04 : 1[180] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Channel 04 : 2[190] -> 0[170] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Channel 04 : 5[1c0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Channel 04 : 2[190] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Channel 04 : 3[1a0] -> 1[180] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Channel 04 : 6[1d0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Channel 04 : 4[1b0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Channel 04 : 7[1e0] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Channel 04 : 1[180] -> 0[170] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Channel 04 : 5[1c0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Channel 05 : 2[190] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Channel 05 : 0[170] -> 2[190] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Channel 05 : 3[1a0] -> 1[180] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Channel 05 : 4[1b0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Channel 05 : 6[1d0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Channel 05 : 7[1e0] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Channel 05 : 1[180] -> 0[170] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Channel 05 : 5[1c0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Channel 05 : 2[190] -> 0[170] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Channel 05 : 1[180] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Channel 05 : 3[1a0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Channel 05 : 4[1b0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Channel 05 : 6[1d0] -> 2[190] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Channel 05 : 7[1e0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Channel 05 : 5[1c0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Channel 06 : 0[170] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Channel 06 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Channel 06 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Channel 06 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Channel 06 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Channel 06 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Channel 06 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Channel 06 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Channel 06 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Channel 06 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Channel 06 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Channel 06 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Channel 06 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Channel 06 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Channel 06 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Channel 07 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Channel 07 : 0[170] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Channel 07 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Channel 07 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Channel 07 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Channel 07 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Channel 07 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Channel 07 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Channel 07 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Channel 07 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Channel 07 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Channel 07 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Channel 07 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Channel 07 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Channel 07 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Channel 08 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Channel 08 : 0[170] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Channel 08 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Channel 08 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Channel 08 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Channel 08 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Channel 08 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Channel 08 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Channel 08 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Channel 08 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Channel 08 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Channel 08 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Channel 08 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Channel 08 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Channel 08 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Channel 09 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Channel 09 : 0[170] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Channel 09 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Channel 09 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Channel 09 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Channel 09 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Channel 09 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Channel 09 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Channel 09 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Channel 09 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Channel 09 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Channel 09 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Channel 09 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Channel 09 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Channel 09 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Channel 10 : 3[1a0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Channel 10 : 0[170] -> 1[180] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Channel 10 : 4[1b0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Channel 10 : 2[190] -> 0[170] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Channel 10 : 1[180] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Channel 10 : 6[1d0] -> 2[190] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Channel 10 : 7[1e0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Channel 10 : 5[1c0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Channel 10 : 2[190] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Channel 10 : 3[1a0] -> 1[180] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Channel 10 : 4[1b0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Channel 10 : 1[180] -> 0[170] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Channel 10 : 6[1d0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Channel 10 : 7[1e0] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Channel 10 : 5[1c0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Channel 11 : 2[190] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO Channel 11 : 0[170] -> 2[190] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Channel 11 : 3[1a0] -> 1[180] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Channel 11 : 4[1b0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Channel 11 : 1[180] -> 0[170] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Channel 11 : 6[1d0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Channel 11 : 7[1e0] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Channel 11 : 5[1c0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO Channel 11 : 1[180] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO Channel 11 : 2[190] -> 0[170] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO Channel 11 : 3[1a0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO Channel 11 : 4[1b0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO Channel 11 : 6[1d0] -> 2[190] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO Channel 11 : 7[1e0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO Channel 11 : 5[1c0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:algo-1-fzp46:45:45 [1] NCCL INFO comm 0x5577b85ed860 rank 1 nranks 8 cudaDev 1 busId 180 - Init COMPLETE\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:537 [0] NCCL INFO comm 0x55be0aad65b0 rank 0 nranks 8 cudaDev 0 busId 170 - Init COMPLETE\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:algo-1-fzp46:47:47 [2] NCCL INFO comm 0x561c4ce3d830 rank 2 nranks 8 cudaDev 2 busId 190 - Init COMPLETE\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:algo-1-fzp46:50:50 [3] NCCL INFO comm 0x55a89489ddf0 rank 3 nranks 8 cudaDev 3 busId 1a0 - Init COMPLETE\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:algo-1-fzp46:51:51 [4] NCCL INFO comm 0x55f226fbead0 rank 4 nranks 8 cudaDev 4 busId 1b0 - Init COMPLETE\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:algo-1-fzp46:55:55 [6] NCCL INFO comm 0x564c34e81440 rank 6 nranks 8 cudaDev 6 busId 1d0 - Init COMPLETE\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:algo-1-fzp46:54:54 [7] NCCL INFO comm 0x55c5f9298f20 rank 7 nranks 8 cudaDev 7 busId 1e0 - Init COMPLETE\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:algo-1-fzp46:53:53 [5] NCCL INFO comm 0x5633eab6f350 rank 5 nranks 8 cudaDev 5 busId 1c0 - Init COMPLETE\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:Running smdistributed.dataparallel v1.2.3\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:################################\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:Global batch size: 256\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:each gpu batch_size: 32\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:world size: 8\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:##### Args: \n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>: Namespace(batch_size=256, dropout=0.0, epochs=1, factor_num=32, gpu='0', log_interval=500, lr=0.001, model_dir='/opt/ml/model', num_layers=3, num_ng=4, out=True, seed=42, test_data_dir='/opt/ml/input/data/test', test_num_ng=99, top_k=10, train_data_dir='/opt/ml/input/data/train')\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:args.train_data_dir: \n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:args.test_data_dir: \n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:args.model_dir: \n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:=====> data loading <===========\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:Get train data sampler and data loader\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:Get test data sampler and data loader\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:Processes 621356/4970845 (13%) of train data\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:Processes 604000/604000 (100%) of test data\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:Pretrained model is NOT used\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:algo-1-fzp46:537:738 [0] NCCL INFO Launch mode Parallel\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:### Model loaded\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:labels_ps:  994169\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:labels_ng:  3976676\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:total train size :  4970845\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:labels_ps:  994169\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:labels_ng:  3976676\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,2]<stdout>:total train size :  4970845\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:labels_ps:  994169\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:labels_ng:  3976676\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,6]<stdout>:total train size :  4970845\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:labels_ps:  994169\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:labels_ng:  3976676\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,4]<stdout>:total train size :  4970845\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:labels_ps:  994169\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:labels_ng:  3976676\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,5]<stdout>:total train size :  4970845\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:labels_ps:  994169\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:labels_ng:  3976676\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,3]<stdout>:total train size :  4970845\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:labels_ps:  994169\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:labels_ng:  3976676\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,7]<stdout>:total train size :  4970845\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:labels_ps:  994169\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:labels_ng:  3976676\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,1]<stdout>:total train size :  4970845\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:Train Epoch: 0 [128000/621356 (21%)] Loss=0.376662;\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:Train Epoch: 0 [256000/621356 (41%)] Loss=0.359810;\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:Train Epoch: 0 [384000/621356 (62%)] Loss=0.284535;\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:Train Epoch: 0 [512000/621356 (82%)] Loss=0.269138;\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:The time elapse of epoch 000 is: 00: 00: 28\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:cuda\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:HR=0.597; \t NDCG=0.340;\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:best_hr:  0.5966887417218543\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:the model is saved at /opt/ml/model/NeuMF-end.pth\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stdout>:End. Best epoch 000: HR = 0.597, NDCG = 0.340\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stderr>:INFO:__main__:Train Epoch: 0 [128000/621356 (21%)] Loss=0.376662;\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stderr>:INFO:__main__:Train Epoch: 0 [256000/621356 (41%)] Loss=0.359810;\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stderr>:INFO:__main__:Train Epoch: 0 [384000/621356 (62%)] Loss=0.284535;\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stderr>:INFO:__main__:Train Epoch: 0 [512000/621356 (82%)] Loss=0.269138;\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m [1,0]<stderr>:INFO:__main__:the model is saved at /opt/ml/model/NeuMF-end.pth\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m \n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 |\u001b[0m 2022-05-30 06:42:18,047 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "\u001b[36mdlt1mbzjtr-algo-1-fzp46 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "\n",
    "\n",
    "local_estimator = PyTorch(\n",
    "    entry_point=\"train_sm_ddp.py\",    \n",
    "    source_dir='src',    \n",
    "    role=role,\n",
    "    framework_version='1.8.1',\n",
    "    py_version='py3',\n",
    "    instance_count=1,\n",
    "    instance_type=instance_type, # local_gpu or local 지정\n",
    "    session = sagemaker.LocalSession(), # 로컬 세션을 사용합니다.\n",
    "    distribution=distribution,\n",
    "    debugger_hook_config=False,    \n",
    "    hyperparameters= hyperparameters               \n",
    "    \n",
    ")\n",
    "local_estimator.fit(local_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. SageMaker Host Mode 로 훈련\n",
    "- instance_type, session 을 수정 합니다.\n",
    "- 입력 데이터를 inputs로서 S3 의 경로를 제공합니다.\n",
    "- wait=False 로 지정해서 async 모드로 훈련을 실행합니다. \n",
    "- 실행 경과는 아래의 cifar10_estimator.logs() 에서 확인 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. 데이터 세트를 S3에 업로드\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3_data_loc:  s3://sagemaker-us-east-1-057716757052/NCFModel/data\n"
     ]
    }
   ],
   "source": [
    "s3_data_loc = sagemaker_session.upload_data(path=config.main_path, bucket=bucket, \n",
    "                                       key_prefix=f\"{prefix}/data\")\n",
    "print(\"s3_data_loc: \", s3_data_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-24 12:16:00     128039 NCFModel/data/.ipynb_checkpoints/ml-1m.test-checkpoint.rating\n",
      "2022-05-24 12:16:00   20982911 NCFModel/data/.ipynb_checkpoints/ml-1m.train-checkpoint.rating\n",
      "2022-05-30 06:42:48    2891424 NCFModel/data/ml-1m.test.negative\n",
      "2022-05-30 06:42:48     128039 NCFModel/data/ml-1m.test.rating\n",
      "2022-05-30 06:42:48   20982911 NCFModel/data/ml-1m.train.rating\n",
      "2022-05-24 12:16:00      57986 NCFModel/data/ml-1m.train.rating-small\n",
      "2022-05-21 07:03:58   27404899 NCFModel/data/pinterest-20.test.negative\n",
      "2022-05-21 07:03:54     807267 NCFModel/data/pinterest-20.test.rating\n",
      "2022-05-21 07:03:55   21138451 NCFModel/data/pinterest-20.train.rating\n"
     ]
    }
   ],
   "source": [
    "! aws s3 ls {s3_data_loc} --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. 훈련 및 테스트 데이터를 S3 로 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3_inputs: \n",
      " {'train': 's3://sagemaker-us-east-1-057716757052/NCFModel/data', 'test': 's3://sagemaker-us-east-1-057716757052/NCFModel/data'}\n"
     ]
    }
   ],
   "source": [
    "s3_inputs = {\n",
    "            'train': f'{s3_data_loc}',\n",
    "            'test': f'{s3_data_loc}'\n",
    "            }\n",
    "\n",
    "print(\"s3_inputs: \\n\", s3_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. 실험 세팅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실험(Experiment) 세팅\n",
    "- Amazon SageMaker 실험은 기계 학습 실험을 구성, 추적, 비교 및 평가할 수 있는 Amazon SageMaker 의 기능입니다\n",
    "- 상세 사항은 개발자 가이드 참조 하세요. --> [Amazon SageMaker 실험을 통한 Machine Learning 관리](https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/experiments.html)\n",
    "- sagemaker experiment는 추가적인 패키지를 설치하여야 합니다. 1_Setup_Environment 가 실행이 안되었다고 하면, `!pip install --upgrade sagemaker-experiments` 를 통해 설치 해주세요.\n",
    "- 여기서는 boto3 API를 통해서 실험을 생성합니다. SageMaker Python SDK를 통해서도 가능합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실험 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment:NCFModel-single-train already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# !pip install --upgrade sagemaker-experiments\n",
    "import boto3\n",
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "from smexperiments.trial_component import TrialComponent\n",
    "from smexperiments.tracker import Tracker\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "sm_client = boto3.client('sagemaker')\n",
    "\n",
    "\n",
    "# 설험에 대한 이름을 생성 합니다.\n",
    "experiment_name = prefix + '-single-train'\n",
    "\n",
    "# 실험이 존재하지 않으면 생성하고, 그렇지 않으면 지나갑니다.\n",
    "try:\n",
    "    response = sm_client.describe_experiment(ExperimentName=experiment_name)\n",
    "    print(f\"Experiment:{experiment_name} already exists\")    \n",
    "    \n",
    "except:\n",
    "    response = sm_client.create_experiment(\n",
    "        ExperimentName = experiment_name,\n",
    "        Description = 'Experiment for NCF',\n",
    "    )\n",
    "    print(f\"Experiment:{experiment_name} is created\")        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하이퍼 파라미터 세팅\n",
    "- epochs 값을 조절해서 실행 시간을 조정 하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_hyperparameters = {'epochs': 5, \n",
    "                       'lr': 0.001,\n",
    "                       'batch_size': 256,\n",
    "                       'top_k' : 10,\n",
    "                       'dropout' : 0.0,\n",
    "                       'factor_num' : 32,\n",
    "                       'num_layers' : 3,\n",
    "                       'num_ng' : 4,\n",
    "                       'test_num_ng' : 99,                   \n",
    "                       'log_interval': 500                                                \n",
    "                    }  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시도(Trial) 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "# 시도 이름 생성\n",
    "ts = datetime.now().strftime('%Y-%m-%d-%H-%M-%S-%f')\n",
    "trial_name = experiment_name + f\"-{ts}\"\n",
    "\n",
    "# 1개의 실험 안에 시도를 생성함.\n",
    "response = sm_client.create_trial(\n",
    "    ExperimentName = experiment_name,\n",
    "    TrialName = trial_name,\n",
    ")    \n",
    "\n",
    "# 실험 설정: 실험 이름, 시도 이름으로 구성\n",
    "experiment_config = {\n",
    "    'ExperimentName' : experiment_name,\n",
    "    'TrialName' : trial_name,\n",
    "    \"TrialComponentDisplayName\" : 'Training',\n",
    "}    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 훈련 실행\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련 메트릭을 CloudWatch 에서 보기\n",
    "- 개발자 가이드\n",
    "    - [Monitor and Analyze Training Jobs Using Amazon CloudWatch ](https://docs.amazonaws.cn/en_us/sagemaker/latest/dg/training-metrics.html#define-train-metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions=[\n",
    "       {'Name': 'HR', 'Regex': 'HR=(.*?);'},\n",
    "       {'Name': 'NDCG', 'Regex': 'NDCG=(.*?);'},\n",
    "       {'Name': 'Loss', 'Regex': 'Loss=(.*?);'}        \n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2022-05-30-07-27-00-364\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "# instance_type = 'ml.p3.16xlarge'\n",
    "instance_type = 'ml.p4d.24xlarge'\n",
    "\n",
    "host_estimator = PyTorch(\n",
    "    entry_point=\"train_sm_ddp.py\",    \n",
    "    source_dir='src',    \n",
    "    role=role,\n",
    "    framework_version='1.8.1',\n",
    "    py_version='py3',\n",
    "    instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    session = sagemaker.Session(), # 세이지 메이커 세션\n",
    "    distribution=distribution,    \n",
    "    hyperparameters=host_hyperparameters,\n",
    "    metric_definitions = metric_definitions\n",
    "    \n",
    ")\n",
    "host_estimator.fit(s3_inputs, \n",
    "                   experiment_config = experiment_config, # 실험 설정 제공                   \n",
    "                   wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-30 07:27:00 Starting - Starting the training job...ProfilerReport-1653895620: InProgress\n",
      "...\n",
      "2022-05-30 07:27:59 Starting - Preparing the instances for training...................................................\n",
      "2022-05-30 07:36:36 Downloading - Downloading input data\n",
      "2022-05-30 07:36:36 Training - Downloading the training image...........................\n",
      "2022-05-30 07:41:08 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2022-05-30 07:41:11,296 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2022-05-30 07:41:11,377 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2022-05-30 07:41:11,386 sagemaker_pytorch_container.training INFO     Invoking SMDataParallel\u001b[0m\n",
      "\u001b[34m2022-05-30 07:41:11,386 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2022-05-30 07:41:11,967 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: nvidia-ml-py3==7.352 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (7.352.0)\u001b[0m\n",
      "\u001b[34mCollecting pandas==0.24.2\n",
      "  Downloading pandas-0.24.2-cp36-cp36m-manylinux1_x86_64.whl (10.1 MB)\u001b[0m\n",
      "\u001b[34mCollecting numpy==1.16.6\n",
      "  Downloading numpy-1.16.6-cp36-cp36m-manylinux1_x86_64.whl (17.4 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch==1.8.1 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 4)) (1.8.1)\u001b[0m\n",
      "\u001b[34mCollecting gensim==3.7.1\n",
      "  Downloading gensim-3.7.1-cp36-cp36m-manylinux1_x86_64.whl (24.2 MB)\u001b[0m\n",
      "\u001b[34mCollecting tensorboardX==1.6\n",
      "  Downloading tensorboardX-1.6-py2.py3-none-any.whl (129 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.5.0 in /opt/conda/lib/python3.6/site-packages (from pandas==0.24.2->-r requirements.txt (line 2)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2011k in /opt/conda/lib/python3.6/site-packages (from pandas==0.24.2->-r requirements.txt (line 2)) (2021.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from torch==1.8.1->-r requirements.txt (line 4)) (0.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.6/site-packages (from torch==1.8.1->-r requirements.txt (line 4)) (3.10.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5.0 in /opt/conda/lib/python3.6/site-packages (from gensim==3.7.1->-r requirements.txt (line 5)) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.6/site-packages (from gensim==3.7.1->-r requirements.txt (line 5)) (1.5.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: smart-open>=1.7.0 in /opt/conda/lib/python3.6/site-packages (from gensim==3.7.1->-r requirements.txt (line 5)) (5.2.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf>=3.2.0 in /opt/conda/lib/python3.6/site-packages (from tensorboardX==1.6->-r requirements.txt (line 6)) (3.19.1)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: numpy, tensorboardX, pandas, gensim\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.1\n",
      "    Uninstalling numpy-1.19.1:\n",
      "      Successfully uninstalled numpy-1.19.1\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.1.5\n",
      "    Uninstalling pandas-1.1.5:\u001b[0m\n",
      "\u001b[34m      Successfully uninstalled pandas-1.1.5\u001b[0m\n",
      "\u001b[34mSuccessfully installed gensim-3.7.1 numpy-1.16.6 pandas-0.24.2 tensorboardX-1.6\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m2022-05-30 07:41:24,706 sagemaker-training-toolkit INFO     Starting MPI run as worker node.\u001b[0m\n",
      "\u001b[34m2022-05-30 07:41:24,706 sagemaker-training-toolkit INFO     Creating SSH daemon.\u001b[0m\n",
      "\u001b[34m2022-05-30 07:41:24,711 sagemaker-training-toolkit INFO     Waiting for MPI workers to establish their SSH connections\u001b[0m\n",
      "\u001b[34m2022-05-30 07:41:24,711 sagemaker-training-toolkit INFO     Network interface name: eth0\u001b[0m\n",
      "\u001b[34m2022-05-30 07:41:24,712 sagemaker-training-toolkit INFO     Host: ['algo-1']\u001b[0m\n",
      "\u001b[34m2022-05-30 07:41:24,713 sagemaker-training-toolkit INFO     instance type: ml.p4d.24xlarge\u001b[0m\n",
      "\u001b[34m2022-05-30 07:41:24,792 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_distributed_dataparallel_custom_mpi_options\": \"\",\n",
      "        \"sagemaker_distributed_dataparallel_enabled\": true,\n",
      "        \"sagemaker_instance_type\": \"ml.p4d.24xlarge\"\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch_size\": 256,\n",
      "        \"dropout\": 0.0,\n",
      "        \"epochs\": 5,\n",
      "        \"factor_num\": 32,\n",
      "        \"log_interval\": 500,\n",
      "        \"lr\": 0.001,\n",
      "        \"num_layers\": 3,\n",
      "        \"num_ng\": 4,\n",
      "        \"test_num_ng\": 99,\n",
      "        \"top_k\": 10\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2022-05-30-07-27-00-364\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-057716757052/pytorch-training-2022-05-30-07-27-00-364/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_sm_ddp\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 96,\n",
      "    \"num_gpus\": 8,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p4d.24xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p4d.24xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_sm_ddp.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch_size\":256,\"dropout\":0.0,\"epochs\":5,\"factor_num\":32,\"log_interval\":500,\"lr\":0.001,\"num_layers\":3,\"num_ng\":4,\"test_num_ng\":99,\"top_k\":10}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_sm_ddp.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={\"sagemaker_distributed_dataparallel_custom_mpi_options\":\"\",\"sagemaker_distributed_dataparallel_enabled\":true,\"sagemaker_instance_type\":\"ml.p4d.24xlarge\"}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p4d.24xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p4d.24xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_sm_ddp\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=96\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=8\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-057716757052/pytorch-training-2022-05-30-07-27-00-364/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_distributed_dataparallel_custom_mpi_options\":\"\",\"sagemaker_distributed_dataparallel_enabled\":true,\"sagemaker_instance_type\":\"ml.p4d.24xlarge\"},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch_size\":256,\"dropout\":0.0,\"epochs\":5,\"factor_num\":32,\"log_interval\":500,\"lr\":0.001,\"num_layers\":3,\"num_ng\":4,\"test_num_ng\":99,\"top_k\":10},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2022-05-30-07-27-00-364\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-057716757052/pytorch-training-2022-05-30-07-27-00-364/source/sourcedir.tar.gz\",\"module_name\":\"train_sm_ddp\",\"network_interface_name\":\"eth0\",\"num_cpus\":96,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p4d.24xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p4d.24xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_sm_ddp.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch_size\",\"256\",\"--dropout\",\"0.0\",\"--epochs\",\"5\",\"--factor_num\",\"32\",\"--log_interval\",\"500\",\"--lr\",\"0.001\",\"--num_layers\",\"3\",\"--num_ng\",\"4\",\"--test_num_ng\",\"99\",\"--top_k\",\"10\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH_SIZE=256\u001b[0m\n",
      "\u001b[34mSM_HP_DROPOUT=0.0\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=5\u001b[0m\n",
      "\u001b[34mSM_HP_FACTOR_NUM=32\u001b[0m\n",
      "\u001b[34mSM_HP_LOG_INTERVAL=500\u001b[0m\n",
      "\u001b[34mSM_HP_LR=0.001\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_LAYERS=3\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_NG=4\u001b[0m\n",
      "\u001b[34mSM_HP_TEST_NUM_NG=99\u001b[0m\n",
      "\u001b[34mSM_HP_TOP_K=10\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34mmpirun --host algo-1 -np 8 --allow-run-as-root --tag-output --oversubscribe -mca btl_tcp_if_include eth0 -mca oob_tcp_if_include eth0 -mca plm_rsh_no_tree_spawn 1 -mca pml ob1 -mca btl ^openib -mca orte_abort_on_non_zero_status 1 -mca btl_vader_single_copy_mechanism none -mca plm_rsh_num_concurrent 1 -x NCCL_SOCKET_IFNAME=eth0 -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH -x SMDATAPARALLEL_USE_SINGLENODE=1 -x FI_PROVIDER=efa -x RDMAV_FORK_SAFE=1 -x LD_PRELOAD=/opt/conda/lib/python3.6/site-packages/gethostname.cpython-36m-x86_64-linux-gnu.so smddprun /opt/conda/bin/python3.6 -m mpi4py train_sm_ddp.py --batch_size 256 --dropout 0.0 --epochs 5 --factor_num 32 --log_interval 500 --lr 0.001 --num_layers 3 --num_ng 4 --test_num_ng 99 --top_k 10\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Bootstrap : Using [0]eth0:10.0.234.178<0>\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO NET/OFI Running on P4d platform, Setting NCCL_TOPO_FILE environment variable to /usr/local/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO NET/OFI Forcing AWS OFI ndev 4\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO NET/OFI Selected Provider is efa\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:NCCL version 2.7.8+cuda11.1\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Bootstrap : Using [0]eth0:10.0.234.178<0>\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Bootstrap : Using [0]eth0:10.0.234.178<0>\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO NET/OFI Running on P4d platform, Setting NCCL_TOPO_FILE environment variable to /usr/local/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO NET/OFI Running on P4d platform, Setting NCCL_TOPO_FILE environment variable to /usr/local/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Bootstrap : Using [0]eth0:10.0.234.178<0>\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Bootstrap : Using [0]eth0:10.0.234.178<0>\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO NET/OFI Running on P4d platform, Setting NCCL_TOPO_FILE environment variable to /usr/local/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO NET/OFI Running on P4d platform, Setting NCCL_TOPO_FILE environment variable to /usr/local/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO NET/OFI Forcing AWS OFI ndev 4\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO NET/OFI Selected Provider is efa\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO NET/OFI Forcing AWS OFI ndev 4\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO NET/OFI Selected Provider is efa\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO NET/OFI Forcing AWS OFI ndev 4\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO NET/OFI Selected Provider is efa\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO NET/OFI Forcing AWS OFI ndev 4\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO NET/OFI Selected Provider is efa\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Bootstrap : Using [0]eth0:10.0.234.178<0>\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO NET/OFI Running on P4d platform, Setting NCCL_TOPO_FILE environment variable to /usr/local/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO NET/OFI Forcing AWS OFI ndev 4\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO NET/OFI Selected Provider is efa\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Bootstrap : Using [0]eth0:10.0.234.178<0>\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO NET/OFI Running on P4d platform, Setting NCCL_TOPO_FILE environment variable to /usr/local/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO NET/OFI Forcing AWS OFI ndev 4\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO NET/OFI Selected Provider is efa\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Bootstrap : Using [0]eth0:10.0.234.178<0>\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO NET/OFI Running on P4d platform, Setting NCCL_TOPO_FILE environment variable to /usr/local/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO NET/OFI Forcing AWS OFI ndev 4\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO NET/OFI Selected Provider is efa\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO NET/OFI [3] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO NET/OFI [5] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO NET/OFI [2] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO NET/OFI [4] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO NET/OFI [4] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO NET/OFI [0] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10/\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO NET/OFI [6] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO NET/OFI [6] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO NET/OFI [1] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10/\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO NET/OFI [1] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO NET/OFI [7] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO NET/OFI [7] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO NET/OFI [3] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10/\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO NET/OFI [5] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO NET/OFI [2] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10/\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO NET/OFI [0] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO NET/OFI [1] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO NET/OFI [4] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20/\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO NET/OFI [6] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO NET/OFI [7] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO NET/OFI [3] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO NET/OFI [5] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20/\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO NET/OFI [0] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO NET/OFI [1] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO NET/OFI [2] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO NET/OFI [4] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO NET/OFI [6] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20/\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO NET/OFI [7] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20/\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO NET/OFI [3] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO NET/OFI [0] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO NET/OFI [5] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO NET/OFI [2] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO NET/OFI [2] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO NET/OFI [2] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10/\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO NET/OFI [2] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO NET/OFI [2] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO NET/OFI [5] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO NET/OFI [5] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO NET/OFI [5] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20/\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO NET/OFI [5] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO NET/OFI [3] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO NET/OFI [3] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10/\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO NET/OFI [3] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO NET/OFI [3] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO NET/OFI [7] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO NET/OFI [7] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO NET/OFI [7] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO NET/OFI [7] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20/\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO NET/OFI [6] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO NET/OFI [6] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO NET/OFI [6] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO NET/OFI [6] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20/\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO NET/OFI [1] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10/\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO NET/OFI [1] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO NET/OFI [1] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO NET/OFI [1] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO NET/OFI [4] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO NET/OFI [4] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO NET/OFI [4] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20/\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO NET/OFI [4] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO NET/OFI [0] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10/\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO NET/OFI [0] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO NET/OFI [0] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO NET/OFI [0] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Trees [0] 2/-1/-1->1->0|0->1->2/-1/-1 [1] 2/-1/-1->1->0|0->1->2/-1/-1 [2] 2/-1/-1->1->0|0->1->2/-1/-1 [3] 2/-1/-1->1->0|0->1->2/-1/-1 [4] 2/-1/-1->1->0|0->1->2/-1/-1 [5] 2/-1/-1->1->0|0->1->2/-1/-1 [6] 2/-1/-1->1->0|0->1->2/-1/-1 [7] 2/-1/-1->1->0|0->1->2/-1/-1 [8] 2/-1/-1->1->0|0->1->2/-1/-1 [9] 2/-1/-1->1->0|0->1->2/-1/-1 [10] 2/-1/-1->1->0|0->1->2/-1/-1 [11] 2/-1/-1->1->0|0->1->2/-1/-1 [12] 2/-1/-1->1->0|0->1->2/-1/-1 [13] 2/-1/-1->1->0|0->1->2/-1/-1 [14] 2/-1/-1->1->0|0->1->2/-1/-1 [15] 2/-1/-1->1->0|0->1->2/-1/-1 [16] 2/-1/-1->1->0|0->1->2/-1/-1 [17] 2/-1/-1->1->0|0->1->2/-1/-1 [18] 2/-1/-1->1->0|0->1->2/-1/-1 [19] 2/-1/-1->1->0|0->1->2/-1/-1 [20] 2/-1/-1->1->0|0->1->2/-1/-1 [21] 2/-1/-1->1->0|0->1->2/-1/-1 [22] 2/-1/-1->1->0|0->1->2/-1/-1 [23] 2/-1/-1->1->0|0->1->2/-1/-1\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Setting affinity for GPU 1 to ff,ffff0000,00ffffff\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Trees [0] 4/-1/-1->3->2|2->3->4/-1/-1 [1] 4/-1/-1->3->2|2->3->4/-1/-1 [2] 4/-1/-1->3->2|2->3->4/-1/-1 [3] 4/-1/-1->3->2|2->3->4/-1/-1 [4] 4/-1/-1->3->2|2->3->4/-1/-1 [5] 4/-1/-1->3->2|2->3->4/-1/-1 [6] 4/-1/-1->3->2|2->3->4/-1/-1 [7] 4/-1/-1->3->2|2->3->4/-1/-1 [8] 4/-1/-1->3->2|2->3->4/-1/-1 [9] 4/-1/-1->3->2|2->3->4/-1/-1 [10] 4/-1/-1->3->2|2->3->4/-1/-1 [11] 4/-1/-1->3->2|2->3->4/-1/-1 [12] 4/-1/-1->3->2|2->3->4/-1/-1 [13] 4/-1/-1->3->2|2->3->4/-1/-1 [14] 4/-1/-1->3->2|2->3->4/-1/-1 [15] 4/-1/-1->3->2|2->3->4/-1/-1 [16] 4/-1/-1->3->2|2->3->4/-1/-1 [17] 4/-1/-1->3->2|2->3->4/-1/-1 [18] 4/-1/-1->3->2|2->3->4/-1/-1 [19] 4/-1/-1->3->2|2->3->4/-1/-1 [20] 4/-1/-1->3->2|2->3->4/-1/-1 [21] 4/-1/-1->3->2|2->3->4/-1/-1 [22] 4/-1/-1->3->2|2->3->4/-1/-1 [23] 4/-1/-1->3->2|2->3->4/-1/-1\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Setting affinity for GPU 3 to ff,ffff0000,00ffffff\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Trees [0] 3/-1/-1->2->1|1->2->3/-1/-1 [1] 3/-1/-1->2->1|1->2->3/-1/-1 [2] 3/-1/-1->2->1|1->2->3/-1/-1 [3] 3/-1/-1->2->1|1->2->3/-1/-1 [4] 3/-1/-1->2->1|1->2->3/-1/-1 [5] 3/-1/-1->2->1|1->2->3/-1/-1 [6] 3/-1/-1->2->1|1->2->3/-1/-1 [7] 3/-1/-1->2->1|1->2->3/-1/-1 [8] 3/-1/-1->2->1|1->2->3/-1/-1 [9] 3/-1/-1->2->1|1->2->3/-1/-1 [10] 3/-1/-1->2->1|1->2->3/-1/-1 [11] 3/-1/-1->2->1|1->2->3/-1/-1 [12] 3/-1/-1->2->1|1->2->3/-1/-1 [13] 3/-1/-1->2->1|1->2->3/-1/-1 [14] 3/-1/-1->2->1|1->2->3/-1/-1 [15] 3/-1/-1->2->1|1->2->3/-1/-1 [16] 3/-1/-1->2->1|1->2->3/-1/-1 [17] 3/-1/-1->2->1|1->2->3/-1/-1 [18] 3/-1/-1->2->1|1->2->3/-1/-1 [19] 3/-1/-1->2->1|1->2->3/-1/-1 [20] 3/-1/-1->2->1|1->2->3/-1/-1 [21] 3/-1/-1->2->1|1->2->3/-1/-1 [22] 3/-1/-1->2->1|1->2->3/-1/-1 [23] 3/-1/-1->2->1|1->2->3/-1/-1\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Setting affinity for GPU 2 to ff,ffff0000,00ffffff\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Trees [0] 5/-1/-1->4->3|3->4->5/-1/-1 [1] 5/-1/-1->4->3|3->4->5/-1/-1 [2] 5/-1/-1->4->3|3->4->5/-1/-1 [3] 5/-1/-1->4->3|3->4->5/-1/-1 [4] 5/-1/-1->4->3|3->4->5/-1/-1 [5] 5/-1/-1->4->3|3->4->5/-1/-1 [6] 5/-1/-1->4->3|3->4->5/-1/-1 [7] 5/-1/-1->4->3|3->4->5/-1/-1 [8] 5/-1/-1->4->3|3->4->5/-1/-1 [9] 5/-1/-1->4->3|3->4->5/-1/-1 [10] 5/-1/-1->4->3|3->4->5/-1/-1 [11] 5/-1/-1->4->3|3->4->5/-1/-1 [12] 5/-1/-1->4->3|3->4->5/-1/-1 [13] 5/-1/-1->4->3|3->4->5/-1/-1 [14] 5/-1/-1->4->3|3->4->5/-1/-1 [15] 5/-1/-1->4->3|3->4->5/-1/-1 [16] 5/-1/-1->4->3|3->4->5/-1/-1 [17] 5/-1/-1->4->3|3->4->5/-1/-1 [18] 5/-1/-1->4->3|3->4->5/-1/-1 [19] 5/-1/-1->4->3|3->4->5/-1/-1 [20] 5/-1/-1->4->3|3->4->5/-1/-1 [21] 5/-1/-1->4->3|3->4->5/-1/-1 [22] 5/-1/-1->4->3|3->4->5/-1/-1 [23] 5/-1/-1->4->3|3->4->5/-1/-1\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Trees [0] 6/-1/-1->5->4|4->5->6/-1/-1 [1] 6/-1/-1->5->4|4->5->6/-1/-1 [2] 6/-1/-1->5->4|4->5->6/-1/-1 [3] 6/-1/-1->5->4|4->5->6/-1/-1 [4] 6/-1/-1->5->4|4->5->6/-1/-1 [5] 6/-1/-1->5->4|4->5->6/-1/-1 [6] 6/-1/-1->5->4|4->5->6/-1/-1 [7] 6/-1/-1->5->4|4->5->6/-1/-1 [8] 6/-1/-1->5->4|4->5->6/-1/-1 [9] 6/-1/-1->5->4|4->5->6/-1/-1 [10] 6/-1/-1->5->4|4->5->6/-1/-1 [11] 6/-1/-1->5->4|4->5->6/-1/-1 [12] 6/-1/-1->5->4|4->5->6/-1/-1 [13] 6/-1/-1->5->4|4->5->6/-1/-1 [14] 6/-1/-1->5->4|4->5->6/-1/-1 [15] 6/-1/-1->5->4|4->5->6/-1/-1 [16] 6/-1/-1->5->4|4->5->6/-1/-1 [17] 6/-1/-1->5->4|4->5->6/-1/-1 [18] 6/-1/-1->5->4|4->5->6/-1/-1 [19] 6/-1/-1->5->4|4->5->6/-1/-1 [20] 6/-1/-1->5->4|4->5->6/-1/-1 [21] 6/-1/-1->5->4|4->5->6/-1/-1 [22] 6/-1/-1->5->4|4->5->6/-1/-1 [23] 6/-1/-1->5->4|4->5->6/-1/-1\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Setting affinity for GPU 4 to ffffff00,0000ffff,ff000000\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Setting affinity for GPU 5 to ffffff00,0000ffff,ff000000\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Trees [0] 7/-1/-1->6->5|5->6->7/-1/-1 [1] 7/-1/-1->6->5|5->6->7/-1/-1 [2] 7/-1/-1->6->5|5->6->7/-1/-1 [3] 7/-1/-1->6->5|5->6->7/-1/-1 [4] 7/-1/-1->6->5|5->6->7/-1/-1 [5] 7/-1/-1->6->5|5->6->7/-1/-1 [6] 7/-1/-1->6->5|5->6->7/-1/-1 [7] 7/-1/-1->6->5|5->6->7/-1/-1 [8] 7/-1/-1->6->5|5->6->7/-1/-1 [9] 7/-1/-1->6->5|5->6->7/-1/-1 [10] 7/-1/-1->6->5|5->6->7/-1/-1 [11] 7/-1/-1->6->5|5->6->7/-1/-1 [12] 7/-1/-1->6->5|5->6->7/-1/-1 [13] 7/-1/-1->6->5|5->6->7/-1/-1 [14] 7/-1/-1->6->5|5->6->7/-1/-1 [15] 7/-1/-1->6->5|5->6->7/-1/-1 [16] 7/-1/-1->6->5|5->6->7/-1/-1 [17] 7/-1/-1->6->5|5->6->7/-1/-1 [18] 7/-1/-1->6->5|5->6->7/-1/-1 [19] 7/-1/-1->6->5|5->6->7/-1/-1 [20] 7/-1/-1->6->5|5->6->7/-1/-1 [21] 7/-1/-1->6->5|5->6->7/-1/-1 [22] 7/-1/-1->6->5|5->6->7/-1/-1 [23] 7/-1/-1->6->5|5->6->7/-1/-1\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Setting affinity for GPU 6 to ffffff00,0000ffff,ff000000\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Trees [0] -1/-1/-1->7->6|6->7->-1/-1/-1 [1] -1/-1/-1->7->6|6->7->-1/-1/-1 [2] -1/-1/-1->7->6|6->7->-1/-1/-1 [3] -1/-1/-1->7->6|6->7->-1/-1/-1 [4] -1/-1/-1->7->6|6->7->-1/-1/-1 [5] -1/-1/-1->7->6|6->7->-1/-1/-1 [6] -1/-1/-1->7->6|6->7->-1/-1/-1 [7] -1/-1/-1->7->6|6->7->-1/-1/-1 [8] -1/-1/-1->7->6|6->7->-1/-1/-1 [9] -1/-1/-1->7->6|6->7->-1/-1/-1 [10] -1/-1/-1->7->6|6->7->-1/-1/-1 [11] -1/-1/-1->7->6|6->7->-1/-1/-1 [12] -1/-1/-1->7->6|6->7->-1/-1/-1 [13] -1/-1/-1->7->6|6->7->-1/-1/-1 [14] -1/-1/-1->7->6|6->7->-1/-1/-1 [15] -1/-1/-1->7->6|6->7->-1/-1/-1 [16] -1/-1/-1->7->6|6->7->-1/-1/-1 [17] -1/-1/-1->7->6|6->7->-1/-1/-1 [18] -1/-1/-1->7->6|6->7->-1/-1/-1 [19] -1/-1/-1->7->6|6->7->-1/-1/-1 [20] -1/-1/-1->7->6|6->7->-1/-1/-1 [21] -1/-1/-1->7->6|6->7->-1/-1/-1 [22] -1/-1/-1->7->6|6->7->-1/-1/-1 [23] -1/-1/-1->7->6|6->7->-1/-1/-1\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Setting affinity for GPU 7 to ffffff00,0000ffff,ff000000\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 00/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 01/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 02/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 03/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 04/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 05/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 06/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 07/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 08/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 09/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 10/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 11/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 12/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 13/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 14/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 15/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 16/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 17/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 18/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 19/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 20/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 21/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 22/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 23/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1|-1->0->1/-1/-1 [1] 1/-1/-1->0->-1|-1->0->1/-1/-1 [2] 1/-1/-1->0->-1|-1->0->1/-1/-1 [3] 1/-1/-1->0->-1|-1->0->1/-1/-1 [4] 1/-1/-1->0->-1|-1->0->1/-1/-1 [5] 1/-1/-1->0->-1|-1->0->1/-1/-1 [6] 1/-1/-1->0->-1|-1->0->1/-1/-1 [7] 1/-1/-1->0->-1|-1->0->1/-1/-1 [8] 1/-1/-1->0->-1|-1->0->1/-1/-1 [9] 1/-1/-1->0->-1|-1->0->1/-1/-1 [10] 1/-1/-1->0->-1|-1->0->1/-1/-1 [11] 1/-1/-1->0->-1|-1->0->1/-1/-1 [12] 1/-1/-1->0->-1|-1->0->1/-1/-1 [13] 1/-1/-1->0->-1|-1->0->1/-1/-1 [14] 1/-1/-1->0->-1|-1->0->1/-1/-1 [15] 1/-1/-1->0->-1|-1->0->1/-1/-1 [16] 1/-1/-1->0->-1|-1->0->1/-1/-1 [17] 1/-1/-1->0->-1|-1->0->1/-1/-1 [18] 1/-1/-1->0->-1|-1->0->1/-1/-1 [19] 1/-1/-1->0->-1|-1->0->1/-1/-1 [20] 1/-1/-1->0->-1|-1->0->1/-1/-1 [21] 1/-1/-1->0->-1|-1->0->1/-1/-1 [22] 1/-1/-1->0->-1|-1->0->1/-1/-1 [23] 1/-1/-1->0->-1|-1->0->1/-1/-1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffff0000,00ffffff\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 00 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 00 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 00 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 00 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 00 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 00 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 00 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 00 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 00 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 00 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 00 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 00 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 00 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 00 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 00 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 01 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 01 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 01 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 01 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 01 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 01 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 01 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 01 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 01 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 01 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 01 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 01 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 01 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 01 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 01 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 02 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 02 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 02 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 02 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 02 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 02 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 02 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 02 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 02 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 02 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 02 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 02 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 02 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 02 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 02 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 03 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 03 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 03 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 03 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 03 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 03 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 03 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 03 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 03 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 03 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 03 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 03 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 03 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 03 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 03 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 04 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 04 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 04 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 04 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 04 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 04 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 04 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 04 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 04 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 04 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 04 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 04 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 04 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 04 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 04 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 05 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 05 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 05 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 05 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 05 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 05 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 05 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 05 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 05 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 05 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 05 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 05 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 05 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 05 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 05 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 06 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 06 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 06 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 06 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 06 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 06 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 06 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 06 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 06 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 06 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 06 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 06 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 06 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 06 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 06 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 07 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 07 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 07 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 07 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 07 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 07 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 07 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 07 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 07 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 07 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 07 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 07 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 07 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 07 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 07 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 08 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 08 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 08 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 08 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 08 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 08 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 08 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 08 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 08 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 08 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 08 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 08 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 08 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 08 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 08 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 09 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 09 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 09 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 09 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 09 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 09 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 09 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 09 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 09 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 09 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 09 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 09 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 09 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 09 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 09 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 10 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 10 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 10 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 10 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 10 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 10 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 10 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 10 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 10 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 10 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 10 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 10 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 10 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 10 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 10 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 11 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 11 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 11 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 11 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 11 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 11 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 11 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 11 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 11 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 11 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 11 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 11 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 11 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 11 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 11 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 12 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 12 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 12 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 12 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 12 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 12 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 12 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 12 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 12 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 12 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 12 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 12 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 12 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 12 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 12 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 13 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 13 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 13 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 13 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 13 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 13 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 13 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 13 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 13 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 13 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 13 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 13 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 13 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 13 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 13 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 14 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 14 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 14 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 14 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 14 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 14 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 14 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 14 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 14 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 14 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 14 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 14 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 14 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 14 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 14 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 15 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 15 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 15 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 15 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 15 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 15 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 15 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 15 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 15 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 15 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 15 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 15 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 15 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 15 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 15 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 16 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 16 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 16 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 16 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 16 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 16 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 16 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 16 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 16 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 16 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 16 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 16 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 16 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 16 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 16 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 17 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 17 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 17 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 17 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 17 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 17 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 17 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 17 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 17 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 17 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 17 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 17 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 17 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 17 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 17 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 18 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 18 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 18 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 18 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 18 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 18 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 18 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 18 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 18 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 18 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 18 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 18 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 18 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 18 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 18 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 19 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 19 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 19 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 19 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 19 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 19 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 19 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 19 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 19 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 19 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 19 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 19 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 19 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 19 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 19 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 20 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 20 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 20 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 20 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 20 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 20 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 20 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 20 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 20 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 20 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 20 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 20 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 20 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 20 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 20 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 21 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 21 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 21 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 21 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 21 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 21 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 21 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 21 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 21 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 21 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 21 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 21 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 21 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 21 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 21 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 22 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 22 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 22 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 22 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 22 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 22 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 22 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 22 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 22 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 22 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 22 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 22 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 22 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 22 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 22 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 23 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 23 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 23 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 23 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 23 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 23 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 23 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 23 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 23 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 23 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 23 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 23 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 23 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 23 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 23 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO comm 0x5574f5c51a20 rank 7 nranks 8 cudaDev 7 busId a01d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO comm 0x55c1d34bf9b0 rank 0 nranks 8 cudaDev 0 busId 101c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO comm 0x55c4a171bd40 rank 1 nranks 8 cudaDev 1 busId 101d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO comm 0x5609bdafd7f0 rank 2 nranks 8 cudaDev 2 busId 201c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO comm 0x558ec2174260 rank 5 nranks 8 cudaDev 5 busId 901d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO comm 0x562e0ea87190 rank 4 nranks 8 cudaDev 4 busId 901c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO comm 0x5565023c6700 rank 3 nranks 8 cudaDev 3 busId 201d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO comm 0x563a365cb4c0 rank 6 nranks 8 cudaDev 6 busId a01c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO NET/OFI [2] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO NET/OFI [1] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10/\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO NET/OFI [0] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10/\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO NET/OFI [4] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO NET/OFI [5] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO NET/OFI [7] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO NET/OFI [0] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO NET/OFI [2] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10/\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO NET/OFI [1] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO NET/OFI [3] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO NET/OFI [6] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO NET/OFI [4] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO NET/OFI [7] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO NET/OFI [5] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO NET/OFI [0] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO NET/OFI [2] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO NET/OFI [3] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10/\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO NET/OFI [4] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20/\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO NET/OFI [1] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO NET/OFI [6] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO NET/OFI [5] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20/\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO NET/OFI [7] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO NET/OFI [2] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO NET/OFI [0] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO NET/OFI [3] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO NET/OFI [4] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO NET/OFI [7] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20/\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO NET/OFI [6] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO NET/OFI [6] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20/\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO NET/OFI [1] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO NET/OFI [5] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO NET/OFI [3] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO NET/OFI [3] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO NET/OFI [3] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10/\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO NET/OFI [3] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO NET/OFI [3] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO NET/OFI [6] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO NET/OFI [6] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO NET/OFI [6] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO NET/OFI [6] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20/\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO NET/OFI [5] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO NET/OFI [5] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO NET/OFI [5] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20/\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO NET/OFI [5] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO NET/OFI [1] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10/\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO NET/OFI [1] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO NET/OFI [1] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO NET/OFI [1] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO NET/OFI [4] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO NET/OFI [4] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO NET/OFI [4] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20/\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO NET/OFI [4] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO NET/OFI [7] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO NET/OFI [7] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO NET/OFI [7] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO NET/OFI [7] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20/\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO NET/OFI [0] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10/\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO NET/OFI [0] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO NET/OFI [0] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO NET/OFI [0] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO NET/OFI [2] getCudaPath dev 0 busId 0000:10:1c.0 path /sys/devices/pci0000:10\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO NET/OFI [2] getCudaPath dev 1 busId 0000:10:1d.0 path /sys/devices/pci0000:10/\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO NET/OFI [2] getCudaPath dev 2 busId 0000:20:1c.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO NET/OFI [2] getCudaPath dev 3 busId 0000:20:1d.0 path /sys/devices/pci0000:20\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Trees [0] -1/-1/-1->7->6|6->7->-1/-1/-1 [1] -1/-1/-1->7->6|6->7->-1/-1/-1 [2] -1/-1/-1->7->6|6->7->-1/-1/-1 [3] -1/-1/-1->7->6|6->7->-1/-1/-1 [4] -1/-1/-1->7->6|6->7->-1/-1/-1 [5] -1/-1/-1->7->6|6->7->-1/-1/-1 [6] -1/-1/-1->7->6|6->7->-1/-1/-1 [7] -1/-1/-1->7->6|6->7->-1/-1/-1 [8] -1/-1/-1->7->6|6->7->-1/-1/-1 [9] -1/-1/-1->7->6|6->7->-1/-1/-1 [10] -1/-1/-1->7->6|6->7->-1/-1/-1 [11] -1/-1/-1->7->6|6->7->-1/-1/-1 [12] -1/-1/-1->7->6|6->7->-1/-1/-1 [13] -1/-1/-1->7->6|6->7->-1/-1/-1 [14] -1/-1/-1->7->6|6->7->-1/-1/-1 [15] -1/-1/-1->7->6|6->7->-1/-1/-1 [16] -1/-1/-1->7->6|6->7->-1/-1/-1 [17] -1/-1/-1->7->6|6->7->-1/-1/-1 [18] -1/-1/-1->7->6|6->7->-1/-1/-1 [19] -1/-1/-1->7->6|6->7->-1/-1/-1 [20] -1/-1/-1->7->6|6->7->-1/-1/-1 [21] -1/-1/-1->7->6|6->7->-1/-1/-1 [22] -1/-1/-1->7->6|6->7->-1/-1/-1 [23] -1/-1/-1->7->6|6->7->-1/-1/-1\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Setting affinity for GPU 7 to ffffff00,0000ffff,ff000000\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Trees [0] 2/-1/-1->1->0|0->1->2/-1/-1 [1] 2/-1/-1->1->0|0->1->2/-1/-1 [2] 2/-1/-1->1->0|0->1->2/-1/-1 [3] 2/-1/-1->1->0|0->1->2/-1/-1 [4] 2/-1/-1->1->0|0->1->2/-1/-1 [5] 2/-1/-1->1->0|0->1->2/-1/-1 [6] 2/-1/-1->1->0|0->1->2/-1/-1 [7] 2/-1/-1->1->0|0->1->2/-1/-1 [8] 2/-1/-1->1->0|0->1->2/-1/-1 [9] 2/-1/-1->1->0|0->1->2/-1/-1 [10] 2/-1/-1->1->0|0->1->2/-1/-1 [11] 2/-1/-1->1->0|0->1->2/-1/-1 [12] 2/-1/-1->1->0|0->1->2/-1/-1 [13] 2/-1/-1->1->0|0->1->2/-1/-1 [14] 2/-1/-1->1->0|0->1->2/-1/-1 [15] 2/-1/-1->1->0|0->1->2/-1/-1 [16] 2/-1/-1->1->0|0->1->2/-1/-1 [17] 2/-1/-1->1->0|0->1->2/-1/-1 [18] 2/-1/-1->1->0|0->1->2/-1/-1 [19] 2/-1/-1->1->0|0->1->2/-1/-1 [20] 2/-1/-1->1->0|0->1->2/-1/-1 [21] 2/-1/-1->1->0|0->1->2/-1/-1 [22] 2/-1/-1->1->0|0->1->2/-1/-1 [23] 2/-1/-1->1->0|0->1->2/-1/-1\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Setting affinity for GPU 1 to ff,ffff0000,00ffffff\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 00/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 01/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 02/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 03/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 04/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 05/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 06/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 07/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 08/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 09/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 10/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 11/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 12/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 13/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 14/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 15/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 16/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 17/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 18/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 19/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 20/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 21/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Trees [0] 3/-1/-1->2->1|1->2->3/-1/-1 [1] 3/-1/-1->2->1|1->2->3/-1/-1 [2] 3/-1/-1->2->1|1->2->3/-1/-1 [3] 3/-1/-1->2->1|1->2->3/-1/-1 [4] 3/-1/-1->2->1|1->2->3/-1/-1 [5] 3/-1/-1->2->1|1->2->3/-1/-1 [6] 3/-1/-1->2->1|1->2->3/-1/-1 [7] 3/-1/-1->2->1|1->2->3/-1/-1 [8] 3/-1/-1->2->1|1->2->3/-1/-1 [9] 3/-1/-1->2->1|1->2->3/-1/-1 [10] 3/-1/-1->2->1|1->2->3/-1/-1 [11] 3/-1/-1->2->1|1->2->3/-1/-1 [12] 3/-1/-1->2->1|1->2->3/-1/-1 [13] 3/-1/-1->2->1|1->2->3/-1/-1 [14] 3/-1/-1->2->1|1->2->3/-1/-1 [15] 3/-1/-1->2->1|1->2->3/-1/-1 [16] 3/-1/-1->2->1|1->2->3/-1/-1 [17] 3/-1/-1->2->1|1->2->3/-1/-1 [18] 3/-1/-1->2->1|1->2->3/-1/-1 [19] 3/-1/-1->2->1|1->2->3/-1/-1 [20] 3/-1/-1->2->1|1->2->3/-1/-1 [21] 3/-1/-1->2->1|1->2->3/-1/-1 [22] 3/-1/-1->2->1|1->2->3/-1/-1 [23] 3/-1/-1->2->1|1->2->3/-1/-1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 22/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 23/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Setting affinity for GPU 2 to ff,ffff0000,00ffffff\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Trees [0] 4/-1/-1->3->2|2->3->4/-1/-1 [1] 4/-1/-1->3->2|2->3->4/-1/-1 [2] 4/-1/-1->3->2|2->3->4/-1/-1 [3] 4/-1/-1->3->2|2->3->4/-1/-1 [4] 4/-1/-1->3->2|2->3->4/-1/-1 [5] 4/-1/-1->3->2|2->3->4/-1/-1 [6] 4/-1/-1->3->2|2->3->4/-1/-1 [7] 4/-1/-1->3->2|2->3->4/-1/-1 [8] 4/-1/-1->3->2|2->3->4/-1/-1 [9] 4/-1/-1->3->2|2->3->4/-1/-1 [10] 4/-1/-1->3->2|2->3->4/-1/-1 [11] 4/-1/-1->3->2|2->3->4/-1/-1 [12] 4/-1/-1->3->2|2->3->4/-1/-1 [13] 4/-1/-1->3->2|2->3->4/-1/-1 [14] 4/-1/-1->3->2|2->3->4/-1/-1 [15] 4/-1/-1->3->2|2->3->4/-1/-1 [16] 4/-1/-1->3->2|2->3->4/-1/-1 [17] 4/-1/-1->3->2|2->3->4/-1/-1 [18] 4/-1/-1->3->2|2->3->4/-1/-1 [19] 4/-1/-1->3->2|2->3->4/-1/-1 [20] 4/-1/-1->3->2|2->3->4/-1/-1 [21] 4/-1/-1->3->2|2->3->4/-1/-1 [22] 4/-1/-1->3->2|2->3->4/-1/-1 [23] 4/-1/-1->3->2|2->3->4/-1/-1\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Setting affinity for GPU 3 to ff,ffff0000,00ffffff\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Trees [0] 5/-1/-1->4->3|3->4->5/-1/-1 [1] 5/-1/-1->4->3|3->4->5/-1/-1 [2] 5/-1/-1->4->3|3->4->5/-1/-1 [3] 5/-1/-1->4->3|3->4->5/-1/-1 [4] 5/-1/-1->4->3|3->4->5/-1/-1 [5] 5/-1/-1->4->3|3->4->5/-1/-1 [6] 5/-1/-1->4->3|3->4->5/-1/-1 [7] 5/-1/-1->4->3|3->4->5/-1/-1 [8] 5/-1/-1->4->3|3->4->5/-1/-1 [9] 5/-1/-1->4->3|3->4->5/-1/-1 [10] 5/-1/-1->4->3|3->4->5/-1/-1 [11] 5/-1/-1->4->3|3->4->5/-1/-1 [12] 5/-1/-1->4->3|3->4->5/-1/-1 [13] 5/-1/-1->4->3|3->4->5/-1/-1 [14] 5/-1/-1->4->3|3->4->5/-1/-1 [15] 5/-1/-1->4->3|3->4->5/-1/-1 [16] 5/-1/-1->4->3|3->4->5/-1/-1 [17] 5/-1/-1->4->3|3->4->5/-1/-1 [18] 5/-1/-1->4->3|3->4->5/-1/-1 [19] 5/-1/-1->4->3|3->4->5/-1/-1 [20] 5/-1/-1->4->3|3->4->5/-1/-1 [21] 5/-1/-1->4->3|3->4->5/-1/-1 [22] 5/-1/-1->4->3|3->4->5/-1/-1 [23] 5/-1/-1->4->3|3->4->5/-1/-1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1|-1->0->1/-1/-1 [1] 1/-1/-1->0->-1|-1->0->1/-1/-1 [2] 1/-1/-1->0->-1|-1->0->1/-1/-1 [3] 1/-1/-1->0->-1|-1->0->1/-1/-1 [4] 1/-1/-1->0->-1|-1->0->1/-1/-1 [5] 1/-1/-1->0->-1|-1->0->1/-1/-1 [6] 1/-1/-1->0->-1|-1->0->1/-1/-1 [7] 1/-1/-1->0->-1|-1->0->1/-1/-1 [8] 1/-1/-1->0->-1|-1->0->1/-1/-1 [9] 1/-1/-1->0->-1|-1->0->1/-1/-1 [10] 1/-1/-1->0->-1|-1->0->1/-1/-1 [11] 1/-1/-1->0->-1|-1->0->1/-1/-1 [12] 1/-1/-1->0->-1|-1->0->1/-1/-1 [13] 1/-1/-1->0->-1|-1->0->1/-1/-1 [14] 1/-1/-1->0->-1|-1->0->1/-1/-1 [15] 1/-1/-1->0->-1|-1->0->1/-1/-1 [16] 1/-1/-1->0->-1|-1->0->1/-1/-1 [17] 1/-1/-1->0->-1|-1->0->1/-1/-1 [18] 1/-1/-1->0->-1|-1->0->1/-1/-1 [19] 1/-1/-1->0->-1|-1->0->1/-1/-1 [20] 1/-1/-1->0->-1|-1->0->1/-1/-1 [21] 1/-1/-1->0->-1|-1->0->1/-1/-1 [22] 1/-1/-1->0->-1|-1->0->1/-1/-1 [23] 1/-1/-1->0->-1|-1->0->1/-1/-1\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Setting affinity for GPU 4 to ffffff00,0000ffff,ff000000\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffff0000,00ffffff\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Trees [0] 7/-1/-1->6->5|5->6->7/-1/-1 [1] 7/-1/-1->6->5|5->6->7/-1/-1 [2] 7/-1/-1->6->5|5->6->7/-1/-1 [3] 7/-1/-1->6->5|5->6->7/-1/-1 [4] 7/-1/-1->6->5|5->6->7/-1/-1 [5] 7/-1/-1->6->5|5->6->7/-1/-1 [6] 7/-1/-1->6->5|5->6->7/-1/-1 [7] 7/-1/-1->6->5|5->6->7/-1/-1 [8] 7/-1/-1->6->5|5->6->7/-1/-1 [9] 7/-1/-1->6->5|5->6->7/-1/-1 [10] 7/-1/-1->6->5|5->6->7/-1/-1 [11] 7/-1/-1->6->5|5->6->7/-1/-1 [12] 7/-1/-1->6->5|5->6->7/-1/-1 [13] 7/-1/-1->6->5|5->6->7/-1/-1 [14] 7/-1/-1->6->5|5->6->7/-1/-1 [15] 7/-1/-1->6->5|5->6->7/-1/-1 [16] 7/-1/-1->6->5|5->6->7/-1/-1 [17] 7/-1/-1->6->5|5->6->7/-1/-1 [18] 7/-1/-1->6->5|5->6->7/-1/-1 [19] 7/-1/-1->6->5|5->6->7/-1/-1 [20] 7/-1/-1->6->5|5->6->7/-1/-1 [21] 7/-1/-1->6->5|5->6->7/-1/-1 [22] 7/-1/-1->6->5|5->6->7/-1/-1 [23] 7/-1/-1->6->5|5->6->7/-1/-1\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Trees [0] 6/-1/-1->5->4|4->5->6/-1/-1 [1] 6/-1/-1->5->4|4->5->6/-1/-1 [2] 6/-1/-1->5->4|4->5->6/-1/-1 [3] 6/-1/-1->5->4|4->5->6/-1/-1 [4] 6/-1/-1->5->4|4->5->6/-1/-1 [5] 6/-1/-1->5->4|4->5->6/-1/-1 [6] 6/-1/-1->5->4|4->5->6/-1/-1 [7] 6/-1/-1->5->4|4->5->6/-1/-1 [8] 6/-1/-1->5->4|4->5->6/-1/-1 [9] 6/-1/-1->5->4|4->5->6/-1/-1 [10] 6/-1/-1->5->4|4->5->6/-1/-1 [11] 6/-1/-1->5->4|4->5->6/-1/-1 [12] 6/-1/-1->5->4|4->5->6/-1/-1 [13] 6/-1/-1->5->4|4->5->6/-1/-1 [14] 6/-1/-1->5->4|4->5->6/-1/-1 [15] 6/-1/-1->5->4|4->5->6/-1/-1 [16] 6/-1/-1->5->4|4->5->6/-1/-1 [17] 6/-1/-1->5->4|4->5->6/-1/-1 [18] 6/-1/-1->5->4|4->5->6/-1/-1 [19] 6/-1/-1->5->4|4->5->6/-1/-1 [20] 6/-1/-1->5->4|4->5->6/-1/-1 [21] 6/-1/-1->5->4|4->5->6/-1/-1 [22] 6/-1/-1->5->4|4->5->6/-1/-1 [23] 6/-1/-1->5->4|4->5->6/-1/-1\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Setting affinity for GPU 5 to ffffff00,0000ffff,ff000000\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Setting affinity for GPU 6 to ffffff00,0000ffff,ff000000\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 00 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 00 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 00 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 00 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 00 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 00 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 00 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 00 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 00 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 00 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 00 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 00 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 00 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 00 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 00 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 01 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 01 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 01 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 01 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 01 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 01 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 01 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 01 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 01 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 01 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 01 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 01 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 01 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 01 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 01 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 02 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 02 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 02 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 02 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 02 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 02 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 02 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 02 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 02 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 02 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 02 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 02 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 02 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 02 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 02 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 03 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 03 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 03 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 03 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 03 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 03 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 03 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 03 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 03 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 03 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 03 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 03 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 03 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 03 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 03 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 04 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 04 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 04 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 04 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 04 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 04 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 04 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 04 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 04 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 04 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 04 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 04 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 04 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 04 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 04 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 05 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 05 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 05 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 05 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 05 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 05 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 05 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 05 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 05 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 05 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 05 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 05 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 05 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 05 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 05 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 06 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 06 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 06 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 06 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 06 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 06 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 06 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 06 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 06 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 06 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 06 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 06 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 06 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 06 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 06 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 07 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 07 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 07 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 07 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 07 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 07 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 07 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 07 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 07 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 07 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 07 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 07 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 07 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 07 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 07 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 08 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 08 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 08 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 08 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 08 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 08 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 08 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 08 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 08 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 08 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 08 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 08 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 08 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 08 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 08 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 09 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 09 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 09 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 09 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 09 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 09 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 09 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 09 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 09 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 09 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 09 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 09 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 09 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 09 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 09 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 10 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 10 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 10 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 10 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 10 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 10 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 10 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 10 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 10 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 10 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 10 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 10 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 10 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 10 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 10 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 11 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 11 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 11 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 11 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 11 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 11 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 11 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 11 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 11 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 11 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 11 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 11 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 11 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 11 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 11 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 12 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 12 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 12 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 12 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 12 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 12 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 12 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 12 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 12 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 12 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 12 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 12 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 12 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 12 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 12 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 13 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 13 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 13 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 13 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 13 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 13 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 13 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 13 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 13 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 13 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 13 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 13 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 13 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 13 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 13 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 14 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 14 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 14 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 14 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 14 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 14 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 14 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 14 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 14 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 14 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 14 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 14 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 14 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 14 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 14 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 15 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 15 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 15 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 15 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 15 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 15 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 15 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 15 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 15 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 15 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 15 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 15 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 15 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 15 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 15 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 16 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 16 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 16 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 16 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 16 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 16 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 16 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 16 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 16 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 16 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 16 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 16 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 16 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 16 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 16 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 17 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 17 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 17 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 17 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 17 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 17 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 17 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 17 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 17 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 17 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 17 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 17 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 17 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 17 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 17 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 18 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 18 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 18 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 18 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 18 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 18 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 18 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 18 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 18 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 18 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 18 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 18 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 18 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 18 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 18 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 19 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 19 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 19 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 19 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 19 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 19 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 19 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 19 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 19 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 19 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 19 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 19 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 19 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 19 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 19 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 20 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 20 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 20 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 20 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 20 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 20 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 20 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 20 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 20 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 20 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 20 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 20 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 20 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 20 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 20 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 21 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 21 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 21 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 21 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 21 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 21 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 21 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 21 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 21 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 21 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 21 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 21 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 21 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 21 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 21 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 22 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 22 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 22 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 22 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 22 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 22 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 22 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 22 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 22 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 22 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 22 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 22 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 22 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 22 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 22 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 23 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO Channel 23 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 23 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 23 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 23 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 23 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 23 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 23 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO Channel 23 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO Channel 23 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO Channel 23 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO Channel 23 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO Channel 23 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO Channel 23 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO Channel 23 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:algo-1:55:55 [7] NCCL INFO comm 0x5574f77f9890 rank 7 nranks 8 cudaDev 7 busId a01d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:516 [0] NCCL INFO comm 0x55c1d506afa0 rank 0 nranks 8 cudaDev 0 busId 101c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:algo-1:51:51 [4] NCCL INFO comm 0x562e1064f610 rank 4 nranks 8 cudaDev 4 busId 901c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:45:45 [1] NCCL INFO comm 0x55c4a32e5520 rank 1 nranks 8 cudaDev 1 busId 101d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:algo-1:53:53 [5] NCCL INFO comm 0x558ec3d3c680 rank 5 nranks 8 cudaDev 5 busId 901d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:47:47 [2] NCCL INFO comm 0x5609bf6c6c80 rank 2 nranks 8 cudaDev 2 busId 201c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:49:49 [3] NCCL INFO comm 0x556503f8fb90 rank 3 nranks 8 cudaDev 3 busId 201d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:algo-1:54:54 [6] NCCL INFO comm 0x563a38193660 rank 6 nranks 8 cudaDev 6 busId a01c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Running smdistributed.dataparallel v1.2.3\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:################################\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Global batch size: 256\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:each gpu batch_size: 32\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:world size: 8\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:##### Args: \u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: Namespace(batch_size=256, dropout=0.0, epochs=5, factor_num=32, gpu='0', log_interval=500, lr=0.001, model_dir='/opt/ml/model', num_layers=3, num_ng=4, out=True, seed=42, test_data_dir='/opt/ml/input/data/test', test_num_ng=99, top_k=10, train_data_dir='/opt/ml/input/data/train')\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:args.train_data_dir: \u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:args.test_data_dir: \u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:args.model_dir: \u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:=====> data loading <===========\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Get train data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Get test data sampler and data loader\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Processes 621356/4970845 (13%) of train data\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Processes 604000/604000 (100%) of test data\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Pretrained model is NOT used\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:516:740 [0] NCCL INFO Launch mode Parallel\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:### Model loaded\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:labels_ps:  994169\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:labels_ng:  3976676\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:total train size :  4970845\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:labels_ps:  994169\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:labels_ng:  3976676\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:total train size :  4970845\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:labels_ps:  994169\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:labels_ng:  3976676\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:total train size :  4970845\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:labels_ps:  994169\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:labels_ng:  3976676\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:total train size :  4970845\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:labels_ps:  994169\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:labels_ng:  3976676\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:total train size :  4970845\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:labels_ps:  994169\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:labels_ng:  3976676\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:total train size :  4970845\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:labels_ps:  994169\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:labels_ng:  3976676\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:total train size :  4970845\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2022-05-30 07:42:10.844 algo-1:51 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2022-05-30 07:42:10.843 algo-1:516 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2022-05-30 07:42:10.843 algo-1:45 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2022-05-30 07:42:10.843 algo-1:49 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2022-05-30 07:42:10.844 algo-1:53 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2022-05-30 07:42:10.852 algo-1:55 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2022-05-30 07:42:10.946 algo-1:45 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2022-05-30 07:42:10.946 algo-1:49 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2022-05-30 07:42:10.946 algo-1:55 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2022-05-30 07:42:10.946 algo-1:516 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2022-05-30 07:42:10.946 algo-1:53 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2022-05-30 07:42:10.946 algo-1:51 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2022-05-30 07:42:10.947 algo-1:55 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2022-05-30 07:42:10.947 algo-1:49 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2022-05-30 07:42:10.947 algo-1:45 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2022-05-30 07:42:10.947 algo-1:516 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2022-05-30 07:42:10.947 algo-1:53 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2022-05-30 07:42:10.947 algo-1:51 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2022-05-30 07:42:10.947 algo-1:45 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2022-05-30 07:42:10.947 algo-1:55 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2022-05-30 07:42:10.947 algo-1:49 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2022-05-30 07:42:10.947 algo-1:516 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2022-05-30 07:42:10.947 algo-1:53 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2022-05-30 07:42:10.947 algo-1:51 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2022-05-30 07:42:10.947 algo-1:49 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2022-05-30 07:42:10.947 algo-1:45 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2022-05-30 07:42:10.947 algo-1:55 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2022-05-30 07:42:10.947 algo-1:516 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2022-05-30 07:42:10.947 algo-1:53 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2022-05-30 07:42:10.947 algo-1:55 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2022-05-30 07:42:10.947 algo-1:45 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2022-05-30 07:42:10.947 algo-1:516 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2022-05-30 07:42:10.947 algo-1:53 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2022-05-30 07:42:10.947 algo-1:51 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2022-05-30 07:42:10.948 algo-1:49 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2022-05-30 07:42:10.948 algo-1:51 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:labels_ps:  994169\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:labels_ng:  3976676\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:total train size :  4970845\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2022-05-30 07:42:11.568 algo-1:54 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2022-05-30 07:42:11.599 algo-1:54 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2022-05-30 07:42:11.600 algo-1:54 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2022-05-30 07:42:11.600 algo-1:54 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2022-05-30 07:42:11.601 algo-1:54 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2022-05-30 07:42:11.601 algo-1:54 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2022-05-30 07:42:11.973 algo-1:47 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2022-05-30 07:42:12.005 algo-1:47 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2022-05-30 07:42:12.006 algo-1:47 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2022-05-30 07:42:12.006 algo-1:47 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2022-05-30 07:42:12.007 algo-1:47 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2022-05-30 07:42:12.007 algo-1:47 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2022-05-30 07:42:12.018 algo-1:516 INFO hook.py:591] name:module.embed_user_GMF.weight count_params:193280\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2022-05-30 07:42:12.018 algo-1:516 INFO hook.py:591] name:module.embed_item_GMF.weight count_params:118592\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2022-05-30 07:42:12.018 algo-1:516 INFO hook.py:591] name:module.embed_user_MLP.weight count_params:773120\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2022-05-30 07:42:12.019 algo-1:516 INFO hook.py:591] name:module.embed_item_MLP.weight count_params:474368\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2022-05-30 07:42:12.019 algo-1:516 INFO hook.py:591] name:module.MLP_layers.1.weight count_params:32768\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2022-05-30 07:42:12.019 algo-1:516 INFO hook.py:591] name:module.MLP_layers.1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2022-05-30 07:42:12.019 algo-1:516 INFO hook.py:591] name:module.MLP_layers.4.weight count_params:8192\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2022-05-30 07:42:12.019 algo-1:516 INFO hook.py:591] name:module.MLP_layers.4.bias count_params:64\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2022-05-30 07:42:12.019 algo-1:516 INFO hook.py:591] name:module.MLP_layers.7.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2022-05-30 07:42:12.019 algo-1:516 INFO hook.py:591] name:module.MLP_layers.7.bias count_params:32\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2022-05-30 07:42:12.019 algo-1:516 INFO hook.py:591] name:module.predict_layer.weight count_params:64\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2022-05-30 07:42:12.019 algo-1:516 INFO hook.py:591] name:module.predict_layer.bias count_params:1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2022-05-30 07:42:12.019 algo-1:516 INFO hook.py:593] Total Trainable Params: 1602657\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2022-05-30 07:42:12.019 algo-1:516 INFO hook.py:425] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2022-05-30 07:42:12.019 algo-1:45 INFO hook.py:591] name:module.embed_user_GMF.weight count_params:193280\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2022-05-30 07:42:12.019 algo-1:45 INFO hook.py:591] name:module.embed_item_GMF.weight count_params:118592\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2022-05-30 07:42:12.019 algo-1:45 INFO hook.py:591] name:module.embed_user_MLP.weight count_params:773120\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2022-05-30 07:42:12.019 algo-1:45 INFO hook.py:591] name:module.embed_item_MLP.weight count_params:474368\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2022-05-30 07:42:12.019 algo-1:45 INFO hook.py:591] name:module.MLP_layers.1.weight count_params:32768\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2022-05-30 07:42:12.019 algo-1:45 INFO hook.py:591] name:module.MLP_layers.1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2022-05-30 07:42:12.019 algo-1:45 INFO hook.py:591] name:module.MLP_layers.4.weight count_params:8192\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2022-05-30 07:42:12.019 algo-1:45 INFO hook.py:591] name:module.MLP_layers.4.bias count_params:64\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2022-05-30 07:42:12.019 algo-1:45 INFO hook.py:591] name:module.MLP_layers.7.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2022-05-30 07:42:12.020 algo-1:45 INFO hook.py:591] name:module.MLP_layers.7.bias count_params:32\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2022-05-30 07:42:12.020 algo-1:45 INFO hook.py:591] name:module.predict_layer.weight count_params:64\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2022-05-30 07:42:12.020 algo-1:45 INFO hook.py:591] name:module.predict_layer.bias count_params:1\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2022-05-30 07:42:12.020 algo-1:45 INFO hook.py:593] Total Trainable Params: 1602657\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2022-05-30 07:42:12.020 algo-1:45 INFO hook.py:425] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2022-05-30 07:42:12.020 algo-1:49 INFO hook.py:591] name:module.embed_user_GMF.weight count_params:193280\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2022-05-30 07:42:12.020 algo-1:49 INFO hook.py:591] name:module.embed_item_GMF.weight count_params:118592\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2022-05-30 07:42:12.020 algo-1:49 INFO hook.py:591] name:module.embed_user_MLP.weight count_params:773120\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2022-05-30 07:42:12.020 algo-1:49 INFO hook.py:591] name:module.embed_item_MLP.weight count_params:474368\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2022-05-30 07:42:12.020 algo-1:49 INFO hook.py:591] name:module.MLP_layers.1.weight count_params:32768\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2022-05-30 07:42:12.020 algo-1:49 INFO hook.py:591] name:module.MLP_layers.1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2022-05-30 07:42:12.020 algo-1:49 INFO hook.py:591] name:module.MLP_layers.4.weight count_params:8192\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2022-05-30 07:42:12.021 algo-1:49 INFO hook.py:591] name:module.MLP_layers.4.bias count_params:64\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2022-05-30 07:42:12.021 algo-1:49 INFO hook.py:591] name:module.MLP_layers.7.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2022-05-30 07:42:12.021 algo-1:49 INFO hook.py:591] name:module.MLP_layers.7.bias count_params:32\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2022-05-30 07:42:12.021 algo-1:49 INFO hook.py:591] name:module.predict_layer.weight count_params:64\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2022-05-30 07:42:12.021 algo-1:49 INFO hook.py:591] name:module.predict_layer.bias count_params:1\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2022-05-30 07:42:12.021 algo-1:49 INFO hook.py:593] Total Trainable Params: 1602657\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2022-05-30 07:42:12.021 algo-1:49 INFO hook.py:425] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2022-05-30 07:42:12.022 algo-1:55 INFO hook.py:591] name:module.embed_user_GMF.weight count_params:193280\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2022-05-30 07:42:12.023 algo-1:55 INFO hook.py:591] name:module.embed_item_GMF.weight count_params:118592\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2022-05-30 07:42:12.023 algo-1:55 INFO hook.py:591] name:module.embed_user_MLP.weight count_params:773120\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2022-05-30 07:42:12.023 algo-1:55 INFO hook.py:591] name:module.embed_item_MLP.weight count_params:474368\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2022-05-30 07:42:12.023 algo-1:55 INFO hook.py:591] name:module.MLP_layers.1.weight count_params:32768\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2022-05-30 07:42:12.023 algo-1:55 INFO hook.py:591] name:module.MLP_layers.1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2022-05-30 07:42:12.023 algo-1:55 INFO hook.py:591] name:module.MLP_layers.4.weight count_params:8192\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2022-05-30 07:42:12.023 algo-1:55 INFO hook.py:591] name:module.MLP_layers.4.bias count_params:64\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2022-05-30 07:42:12.023 algo-1:55 INFO hook.py:591] name:module.MLP_layers.7.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2022-05-30 07:42:12.023 algo-1:55 INFO hook.py:591] name:module.MLP_layers.7.bias count_params:32\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2022-05-30 07:42:12.023 algo-1:55 INFO hook.py:591] name:module.predict_layer.weight count_params:64\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2022-05-30 07:42:12.023 algo-1:55 INFO hook.py:591] name:module.predict_layer.bias count_params:1\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2022-05-30 07:42:12.024 algo-1:55 INFO hook.py:593] Total Trainable Params: 1602657\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2022-05-30 07:42:12.023 algo-1:53 INFO hook.py:591] name:module.embed_user_GMF.weight count_params:193280\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2022-05-30 07:42:12.024 algo-1:53 INFO hook.py:591] name:module.embed_item_GMF.weight count_params:118592\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2022-05-30 07:42:12.024 algo-1:55 INFO hook.py:425] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2022-05-30 07:42:12.024 algo-1:53 INFO hook.py:591] name:module.embed_user_MLP.weight count_params:773120\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2022-05-30 07:42:12.024 algo-1:53 INFO hook.py:591] name:module.embed_item_MLP.weight count_params:474368\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2022-05-30 07:42:12.024 algo-1:53 INFO hook.py:591] name:module.MLP_layers.1.weight count_params:32768\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2022-05-30 07:42:12.024 algo-1:53 INFO hook.py:591] name:module.MLP_layers.1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2022-05-30 07:42:12.024 algo-1:53 INFO hook.py:591] name:module.MLP_layers.4.weight count_params:8192\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2022-05-30 07:42:12.024 algo-1:53 INFO hook.py:591] name:module.MLP_layers.4.bias count_params:64\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2022-05-30 07:42:12.024 algo-1:53 INFO hook.py:591] name:module.MLP_layers.7.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2022-05-30 07:42:12.024 algo-1:53 INFO hook.py:591] name:module.MLP_layers.7.bias count_params:32\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2022-05-30 07:42:12.024 algo-1:53 INFO hook.py:591] name:module.predict_layer.weight count_params:64\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2022-05-30 07:42:12.024 algo-1:53 INFO hook.py:591] name:module.predict_layer.bias count_params:1\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2022-05-30 07:42:12.024 algo-1:53 INFO hook.py:593] Total Trainable Params: 1602657\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2022-05-30 07:42:12.025 algo-1:53 INFO hook.py:425] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2022-05-30 07:42:12.084 algo-1:51 INFO hook.py:591] name:module.embed_user_GMF.weight count_params:193280\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2022-05-30 07:42:12.085 algo-1:51 INFO hook.py:591] name:module.embed_item_GMF.weight count_params:118592\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2022-05-30 07:42:12.085 algo-1:51 INFO hook.py:591] name:module.embed_user_MLP.weight count_params:773120\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2022-05-30 07:42:12.085 algo-1:51 INFO hook.py:591] name:module.embed_item_MLP.weight count_params:474368\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2022-05-30 07:42:12.085 algo-1:51 INFO hook.py:591] name:module.MLP_layers.1.weight count_params:32768\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2022-05-30 07:42:12.085 algo-1:51 INFO hook.py:591] name:module.MLP_layers.1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2022-05-30 07:42:12.085 algo-1:51 INFO hook.py:591] name:module.MLP_layers.4.weight count_params:8192\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2022-05-30 07:42:12.085 algo-1:51 INFO hook.py:591] name:module.MLP_layers.4.bias count_params:64\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2022-05-30 07:42:12.085 algo-1:51 INFO hook.py:591] name:module.MLP_layers.7.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2022-05-30 07:42:12.085 algo-1:51 INFO hook.py:591] name:module.MLP_layers.7.bias count_params:32\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2022-05-30 07:42:12.085 algo-1:51 INFO hook.py:591] name:module.predict_layer.weight count_params:64\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2022-05-30 07:42:12.085 algo-1:51 INFO hook.py:591] name:module.predict_layer.bias count_params:1\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2022-05-30 07:42:12.085 algo-1:51 INFO hook.py:593] Total Trainable Params: 1602657\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2022-05-30 07:42:12.086 algo-1:51 INFO hook.py:425] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2022-05-30 07:42:12.356 algo-1:54 INFO hook.py:591] name:module.embed_user_GMF.weight count_params:193280\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2022-05-30 07:42:12.356 algo-1:54 INFO hook.py:591] name:module.embed_item_GMF.weight count_params:118592\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2022-05-30 07:42:12.356 algo-1:54 INFO hook.py:591] name:module.embed_user_MLP.weight count_params:773120\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2022-05-30 07:42:12.357 algo-1:54 INFO hook.py:591] name:module.embed_item_MLP.weight count_params:474368\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2022-05-30 07:42:12.357 algo-1:54 INFO hook.py:591] name:module.MLP_layers.1.weight count_params:32768\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2022-05-30 07:42:12.357 algo-1:54 INFO hook.py:591] name:module.MLP_layers.1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2022-05-30 07:42:12.357 algo-1:54 INFO hook.py:591] name:module.MLP_layers.4.weight count_params:8192\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2022-05-30 07:42:12.357 algo-1:54 INFO hook.py:591] name:module.MLP_layers.4.bias count_params:64\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2022-05-30 07:42:12.357 algo-1:54 INFO hook.py:591] name:module.MLP_layers.7.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2022-05-30 07:42:12.357 algo-1:54 INFO hook.py:591] name:module.MLP_layers.7.bias count_params:32\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2022-05-30 07:42:12.357 algo-1:54 INFO hook.py:591] name:module.predict_layer.weight count_params:64\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2022-05-30 07:42:12.357 algo-1:54 INFO hook.py:591] name:module.predict_layer.bias count_params:1\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2022-05-30 07:42:12.357 algo-1:54 INFO hook.py:593] Total Trainable Params: 1602657\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2022-05-30 07:42:12.357 algo-1:54 INFO hook.py:425] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2022-05-30 07:42:12.781 algo-1:47 INFO hook.py:591] name:module.embed_user_GMF.weight count_params:193280\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2022-05-30 07:42:12.782 algo-1:47 INFO hook.py:591] name:module.embed_item_GMF.weight count_params:118592\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2022-05-30 07:42:12.782 algo-1:47 INFO hook.py:591] name:module.embed_user_MLP.weight count_params:773120\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2022-05-30 07:42:12.782 algo-1:47 INFO hook.py:591] name:module.embed_item_MLP.weight count_params:474368\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2022-05-30 07:42:12.782 algo-1:47 INFO hook.py:591] name:module.MLP_layers.1.weight count_params:32768\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2022-05-30 07:42:12.782 algo-1:47 INFO hook.py:591] name:module.MLP_layers.1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2022-05-30 07:42:12.782 algo-1:47 INFO hook.py:591] name:module.MLP_layers.4.weight count_params:8192\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2022-05-30 07:42:12.782 algo-1:47 INFO hook.py:591] name:module.MLP_layers.4.bias count_params:64\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2022-05-30 07:42:12.782 algo-1:47 INFO hook.py:591] name:module.MLP_layers.7.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2022-05-30 07:42:12.782 algo-1:47 INFO hook.py:591] name:module.MLP_layers.7.bias count_params:32\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2022-05-30 07:42:12.782 algo-1:47 INFO hook.py:591] name:module.predict_layer.weight count_params:64\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2022-05-30 07:42:12.782 algo-1:47 INFO hook.py:591] name:module.predict_layer.bias count_params:1\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2022-05-30 07:42:12.782 algo-1:47 INFO hook.py:593] Total Trainable Params: 1602657\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2022-05-30 07:42:12.782 algo-1:47 INFO hook.py:425] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 0 [128000/621356 (21%)] Loss=0.406764;\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 0 [256000/621356 (41%)] Loss=0.356486;\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 0 [384000/621356 (62%)] Loss=0.266208;\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 0 [512000/621356 (82%)] Loss=0.311822;\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:The time elapse of epoch 000 is: 00: 00: 20\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:cuda\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:HR=0.600; #011 NDCG=0.340;\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:best_hr:  0.5995033112582782\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:the model is saved at /opt/ml/model/NeuMF-end.pth\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [128000/621356 (21%)] Loss=0.257670;\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [256000/621356 (41%)] Loss=0.240731;\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [384000/621356 (62%)] Loss=0.254493;\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [512000/621356 (82%)] Loss=0.272233;\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:The time elapse of epoch 001 is: 00: 00: 16\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:cuda\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:HR=0.645; #011 NDCG=0.372;\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:best_hr:  0.6448675496688742\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:the model is saved at /opt/ml/model/NeuMF-end.pth\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [128000/621356 (21%)] Loss=0.226734;\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [256000/621356 (41%)] Loss=0.255459;\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [384000/621356 (62%)] Loss=0.234466;\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [512000/621356 (82%)] Loss=0.262132;\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:The time elapse of epoch 002 is: 00: 00: 16\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:cuda\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:HR=0.661; #011 NDCG=0.388;\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:best_hr:  0.6612582781456954\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:the model is saved at /opt/ml/model/NeuMF-end.pth\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [128000/621356 (21%)] Loss=0.206911;\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [256000/621356 (41%)] Loss=0.287660;\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [384000/621356 (62%)] Loss=0.216213;\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [512000/621356 (82%)] Loss=0.247090;\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:The time elapse of epoch 003 is: 00: 00: 17\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:cuda\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:HR=0.672; #011 NDCG=0.400;\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:best_hr:  0.6720198675496689\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:the model is saved at /opt/ml/model/NeuMF-end.pth\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [128000/621356 (21%)] Loss=0.227486;\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [256000/621356 (41%)] Loss=0.271635;\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [384000/621356 (62%)] Loss=0.229236;\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [512000/621356 (82%)] Loss=0.292867;\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:The time elapse of epoch 004 is: 00: 00: 17\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:cuda\u001b[0m\n",
      "\n",
      "2022-05-30 07:44:39 Uploading - Uploading generated training model\u001b[34m[1,0]<stdout>:HR=0.679; #011 NDCG=0.403;\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:best_hr:  0.6789735099337748\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:the model is saved at /opt/ml/model/NeuMF-end.pth\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:End. Best epoch 004: HR = 0.679, NDCG = 0.403\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:__main__:Train Epoch: 0 [128000/621356 (21%)] Loss=0.406764;\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:__main__:Train Epoch: 0 [256000/621356 (41%)] Loss=0.356486;\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:__main__:Train Epoch: 0 [384000/621356 (62%)] Loss=0.266208;\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:__main__:Train Epoch: 0 [512000/621356 (82%)] Loss=0.311822;\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:__main__:the model is saved at /opt/ml/model/NeuMF-end.pth\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:__main__:Train Epoch: 1 [128000/621356 (21%)] Loss=0.257670;\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:__main__:Train Epoch: 1 [256000/621356 (41%)] Loss=0.240731;\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:__main__:Train Epoch: 1 [384000/621356 (62%)] Loss=0.254493;\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:__main__:Train Epoch: 1 [512000/621356 (82%)] Loss=0.272233;\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:__main__:the model is saved at /opt/ml/model/NeuMF-end.pth\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:__main__:Train Epoch: 2 [128000/621356 (21%)] Loss=0.226734;\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:__main__:Train Epoch: 2 [256000/621356 (41%)] Loss=0.255459;\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:__main__:Train Epoch: 2 [384000/621356 (62%)] Loss=0.234466;\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:__main__:Train Epoch: 2 [512000/621356 (82%)] Loss=0.262132;\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:__main__:the model is saved at /opt/ml/model/NeuMF-end.pth\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:__main__:Train Epoch: 3 [128000/621356 (21%)] Loss=0.206911;\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:__main__:Train Epoch: 3 [256000/621356 (41%)] Loss=0.287660;\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:__main__:Train Epoch: 3 [384000/621356 (62%)] Loss=0.216213;\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:__main__:Train Epoch: 3 [512000/621356 (82%)] Loss=0.247090;\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:__main__:the model is saved at /opt/ml/model/NeuMF-end.pth\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:__main__:Train Epoch: 4 [128000/621356 (21%)] Loss=0.227486;\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:__main__:Train Epoch: 4 [256000/621356 (41%)] Loss=0.271635;\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:__main__:Train Epoch: 4 [384000/621356 (62%)] Loss=0.229236;\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:__main__:Train Epoch: 4 [512000/621356 (82%)] Loss=0.292867;\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:__main__:the model is saved at /opt/ml/model/NeuMF-end.pth\u001b[0m\n",
      "\u001b[34m2022-05-30 07:44:34,103 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2022-05-30 07:45:08 Completed - Training job completed\n",
      "ProfilerReport-1653895620: NoIssuesFound\n",
      "Training seconds: 518\n",
      "Billable seconds: 518\n",
      "CPU times: user 2.22 s, sys: 120 ms, total: 2.34 s\n",
      "Wall time: 18min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "host_estimator.logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 실험 결과 보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "위의 실험한 결과를 확인 합니다.\n",
    "- 각각의 훈련잡의 시도에 대한 훈련 사용 데이터, 모델 입력 하이퍼 파라미터, 모델 평가 지표, 모델 아티펙트 결과 위치 등의 확인이 가능합니다.\n",
    "- **아래의 모든 내용은 SageMaker Studio 를 통해서 직관적으로 확인이 가능합니다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TrialComponentName</th>\n",
       "      <th>DisplayName</th>\n",
       "      <th>SourceArn</th>\n",
       "      <th>SageMaker.ImageUri</th>\n",
       "      <th>SageMaker.InstanceCount</th>\n",
       "      <th>SageMaker.InstanceType</th>\n",
       "      <th>SageMaker.VolumeSizeInGB</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epochs</th>\n",
       "      <th>factor_num</th>\n",
       "      <th>log_interval</th>\n",
       "      <th>lr</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>num_ng</th>\n",
       "      <th>sagemaker_container_log_level</th>\n",
       "      <th>sagemaker_distributed_dataparallel_custom_mpi_options</th>\n",
       "      <th>sagemaker_distributed_dataparallel_enabled</th>\n",
       "      <th>sagemaker_instance_type</th>\n",
       "      <th>sagemaker_job_name</th>\n",
       "      <th>sagemaker_program</th>\n",
       "      <th>sagemaker_region</th>\n",
       "      <th>sagemaker_submit_directory</th>\n",
       "      <th>test_num_ng</th>\n",
       "      <th>top_k</th>\n",
       "      <th>...</th>\n",
       "      <th>HR - Min</th>\n",
       "      <th>HR - Max</th>\n",
       "      <th>HR - Avg</th>\n",
       "      <th>HR - StdDev</th>\n",
       "      <th>HR - Last</th>\n",
       "      <th>HR - Count</th>\n",
       "      <th>NDCG - Min</th>\n",
       "      <th>NDCG - Max</th>\n",
       "      <th>NDCG - Avg</th>\n",
       "      <th>NDCG - StdDev</th>\n",
       "      <th>NDCG - Last</th>\n",
       "      <th>NDCG - Count</th>\n",
       "      <th>test - MediaType</th>\n",
       "      <th>test - Value</th>\n",
       "      <th>train - MediaType</th>\n",
       "      <th>train - Value</th>\n",
       "      <th>SageMaker.DebugHookOutput - MediaType</th>\n",
       "      <th>SageMaker.DebugHookOutput - Value</th>\n",
       "      <th>SageMaker.ModelArtifact - MediaType</th>\n",
       "      <th>SageMaker.ModelArtifact - Value</th>\n",
       "      <th>Trials</th>\n",
       "      <th>Experiments</th>\n",
       "      <th>sagemaker_mpi_custom_mpi_options</th>\n",
       "      <th>sagemaker_mpi_enabled</th>\n",
       "      <th>sagemaker_mpi_num_of_processes_per_host</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pytorch-training-2022-05-30-07-27-00-364-aws-t...</td>\n",
       "      <td>Training</td>\n",
       "      <td>arn:aws:sagemaker:us-east-1:057716757052:train...</td>\n",
       "      <td>763104351884.dkr.ecr.us-east-1.amazonaws.com/p...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ml.p4d.24xlarge</td>\n",
       "      <td>30.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>\"\"</td>\n",
       "      <td>true</td>\n",
       "      <td>\"ml.p4d.24xlarge\"</td>\n",
       "      <td>\"pytorch-training-2022-05-30-07-27-00-364\"</td>\n",
       "      <td>\"train_sm_ddp.py\"</td>\n",
       "      <td>\"us-east-1\"</td>\n",
       "      <td>\"s3://sagemaker-us-east-1-057716757052/pytorch...</td>\n",
       "      <td>99.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.6514</td>\n",
       "      <td>0.031469</td>\n",
       "      <td>0.679</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.380600</td>\n",
       "      <td>0.025764</td>\n",
       "      <td>0.403</td>\n",
       "      <td>5.0</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-057716757052/NCFModel...</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-057716757052/NCFModel...</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-057716757052/</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-057716757052/pytorch-...</td>\n",
       "      <td>[NCFModel-single-train-2022-05-30-06-42-53-130...</td>\n",
       "      <td>[NCFModel-single-train]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pytorch-training-2022-05-30-07-10-08-261-aws-t...</td>\n",
       "      <td>Training</td>\n",
       "      <td>arn:aws:sagemaker:us-east-1:057716757052:train...</td>\n",
       "      <td>763104351884.dkr.ecr.us-east-1.amazonaws.com/p...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ml.p3.16xlarge</td>\n",
       "      <td>30.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>\"\"</td>\n",
       "      <td>true</td>\n",
       "      <td>\"ml.p3.16xlarge\"</td>\n",
       "      <td>\"pytorch-training-2022-05-30-07-10-08-261\"</td>\n",
       "      <td>\"train_sm_ddp.py\"</td>\n",
       "      <td>\"us-east-1\"</td>\n",
       "      <td>\"s3://sagemaker-us-east-1-057716757052/pytorch...</td>\n",
       "      <td>99.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>0.028775</td>\n",
       "      <td>0.675</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.378400</td>\n",
       "      <td>0.023870</td>\n",
       "      <td>0.399</td>\n",
       "      <td>5.0</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-057716757052/NCFModel...</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-057716757052/NCFModel...</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-057716757052/</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-057716757052/pytorch-...</td>\n",
       "      <td>[NCFModel-single-train-2022-05-30-06-42-53-130...</td>\n",
       "      <td>[NCFModel-single-train]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>pytorch-training-2022-05-22-03-52-23-671-aws-t...</td>\n",
       "      <td>Training</td>\n",
       "      <td>arn:aws:sagemaker:us-east-1:057716757052:train...</td>\n",
       "      <td>763104351884.dkr.ecr.us-east-1.amazonaws.com/p...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ml.p3.2xlarge</td>\n",
       "      <td>30.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"pytorch-training-2022-05-22-03-52-23-671\"</td>\n",
       "      <td>\"train.py\"</td>\n",
       "      <td>\"us-east-1\"</td>\n",
       "      <td>\"s3://sagemaker-us-east-1-057716757052/pytorch...</td>\n",
       "      <td>99.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.6825</td>\n",
       "      <td>0.019609</td>\n",
       "      <td>0.687</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0.410200</td>\n",
       "      <td>0.017080</td>\n",
       "      <td>0.417</td>\n",
       "      <td>10.0</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-057716757052/NCFModel...</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-057716757052/NCFModel...</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-057716757052/</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-057716757052/pytorch-...</td>\n",
       "      <td>[NCFModel-single-train-2022-05-22-03-52-16-349...</td>\n",
       "      <td>[NCFModel-single-train]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>pytorch-training-2022-05-22-03-16-01-173-aws-t...</td>\n",
       "      <td>Training</td>\n",
       "      <td>arn:aws:sagemaker:us-east-1:057716757052:train...</td>\n",
       "      <td>763104351884.dkr.ecr.us-east-1.amazonaws.com/p...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ml.p3.2xlarge</td>\n",
       "      <td>30.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"pytorch-training-2022-05-22-03-16-01-173\"</td>\n",
       "      <td>\"train.py\"</td>\n",
       "      <td>\"us-east-1\"</td>\n",
       "      <td>\"s3://sagemaker-us-east-1-057716757052/pytorch...</td>\n",
       "      <td>99.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.6600</td>\n",
       "      <td>0.031225</td>\n",
       "      <td>0.685</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.384667</td>\n",
       "      <td>0.024132</td>\n",
       "      <td>0.405</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-057716757052/NCFModel...</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-057716757052/NCFModel...</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-057716757052/</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-057716757052/pytorch-...</td>\n",
       "      <td>[NCFModel-single-train-2022-05-22-03-14-07-894...</td>\n",
       "      <td>[NCFModel-single-train]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   TrialComponentName DisplayName  \\\n",
       "0   pytorch-training-2022-05-30-07-27-00-364-aws-t...    Training   \n",
       "1   pytorch-training-2022-05-30-07-10-08-261-aws-t...    Training   \n",
       "..                                                ...         ...   \n",
       "22  pytorch-training-2022-05-22-03-52-23-671-aws-t...    Training   \n",
       "23  pytorch-training-2022-05-22-03-16-01-173-aws-t...    Training   \n",
       "\n",
       "                                            SourceArn  \\\n",
       "0   arn:aws:sagemaker:us-east-1:057716757052:train...   \n",
       "1   arn:aws:sagemaker:us-east-1:057716757052:train...   \n",
       "..                                                ...   \n",
       "22  arn:aws:sagemaker:us-east-1:057716757052:train...   \n",
       "23  arn:aws:sagemaker:us-east-1:057716757052:train...   \n",
       "\n",
       "                                   SageMaker.ImageUri  \\\n",
       "0   763104351884.dkr.ecr.us-east-1.amazonaws.com/p...   \n",
       "1   763104351884.dkr.ecr.us-east-1.amazonaws.com/p...   \n",
       "..                                                ...   \n",
       "22  763104351884.dkr.ecr.us-east-1.amazonaws.com/p...   \n",
       "23  763104351884.dkr.ecr.us-east-1.amazonaws.com/p...   \n",
       "\n",
       "    SageMaker.InstanceCount SageMaker.InstanceType  SageMaker.VolumeSizeInGB  \\\n",
       "0                       1.0        ml.p4d.24xlarge                      30.0   \n",
       "1                       1.0         ml.p3.16xlarge                      30.0   \n",
       "..                      ...                    ...                       ...   \n",
       "22                      1.0          ml.p3.2xlarge                      30.0   \n",
       "23                      1.0          ml.p3.2xlarge                      30.0   \n",
       "\n",
       "    batch_size  dropout  epochs  factor_num  log_interval     lr  num_layers  \\\n",
       "0        256.0      0.0     5.0        32.0         500.0  0.001         3.0   \n",
       "1        256.0      0.0     5.0        32.0         500.0  0.001         3.0   \n",
       "..         ...      ...     ...         ...           ...    ...         ...   \n",
       "22       256.0      0.0    10.0        32.0           NaN  0.001         3.0   \n",
       "23       256.0      0.0     3.0        32.0           NaN  0.001         3.0   \n",
       "\n",
       "    num_ng  sagemaker_container_log_level  \\\n",
       "0      4.0                           20.0   \n",
       "1      4.0                           20.0   \n",
       "..     ...                            ...   \n",
       "22     4.0                           20.0   \n",
       "23     4.0                           20.0   \n",
       "\n",
       "   sagemaker_distributed_dataparallel_custom_mpi_options  \\\n",
       "0                                                  \"\"      \n",
       "1                                                  \"\"      \n",
       "..                                                ...      \n",
       "22                                                NaN      \n",
       "23                                                NaN      \n",
       "\n",
       "   sagemaker_distributed_dataparallel_enabled sagemaker_instance_type  \\\n",
       "0                                        true       \"ml.p4d.24xlarge\"   \n",
       "1                                        true        \"ml.p3.16xlarge\"   \n",
       "..                                        ...                     ...   \n",
       "22                                        NaN                     NaN   \n",
       "23                                        NaN                     NaN   \n",
       "\n",
       "                            sagemaker_job_name  sagemaker_program  \\\n",
       "0   \"pytorch-training-2022-05-30-07-27-00-364\"  \"train_sm_ddp.py\"   \n",
       "1   \"pytorch-training-2022-05-30-07-10-08-261\"  \"train_sm_ddp.py\"   \n",
       "..                                         ...                ...   \n",
       "22  \"pytorch-training-2022-05-22-03-52-23-671\"         \"train.py\"   \n",
       "23  \"pytorch-training-2022-05-22-03-16-01-173\"         \"train.py\"   \n",
       "\n",
       "   sagemaker_region                         sagemaker_submit_directory  \\\n",
       "0       \"us-east-1\"  \"s3://sagemaker-us-east-1-057716757052/pytorch...   \n",
       "1       \"us-east-1\"  \"s3://sagemaker-us-east-1-057716757052/pytorch...   \n",
       "..              ...                                                ...   \n",
       "22      \"us-east-1\"  \"s3://sagemaker-us-east-1-057716757052/pytorch...   \n",
       "23      \"us-east-1\"  \"s3://sagemaker-us-east-1-057716757052/pytorch...   \n",
       "\n",
       "    test_num_ng  top_k  ...  HR - Min  HR - Max  HR - Avg  HR - StdDev  \\\n",
       "0          99.0   10.0  ...     0.600     0.679    0.6514     0.031469   \n",
       "1          99.0   10.0  ...     0.605     0.675    0.6500     0.028775   \n",
       "..          ...    ...  ...       ...       ...       ...          ...   \n",
       "22         99.0   10.0  ...     0.630     0.696    0.6825     0.019609   \n",
       "23         99.0   10.0  ...     0.625     0.685    0.6600     0.031225   \n",
       "\n",
       "    HR - Last  HR - Count  NDCG - Min  NDCG - Max  NDCG - Avg  NDCG - StdDev  \\\n",
       "0       0.679         5.0       0.340       0.403    0.380600       0.025764   \n",
       "1       0.675         5.0       0.341       0.399    0.378400       0.023870   \n",
       "..        ...         ...         ...         ...         ...            ...   \n",
       "22      0.687        10.0       0.366       0.421    0.410200       0.017080   \n",
       "23      0.685         3.0       0.358       0.405    0.384667       0.024132   \n",
       "\n",
       "    NDCG - Last  NDCG - Count  test - MediaType  \\\n",
       "0         0.403           5.0              None   \n",
       "1         0.399           5.0              None   \n",
       "..          ...           ...               ...   \n",
       "22        0.417          10.0              None   \n",
       "23        0.405           3.0              None   \n",
       "\n",
       "                                         test - Value  train - MediaType  \\\n",
       "0   s3://sagemaker-us-east-1-057716757052/NCFModel...               None   \n",
       "1   s3://sagemaker-us-east-1-057716757052/NCFModel...               None   \n",
       "..                                                ...                ...   \n",
       "22  s3://sagemaker-us-east-1-057716757052/NCFModel...               None   \n",
       "23  s3://sagemaker-us-east-1-057716757052/NCFModel...               None   \n",
       "\n",
       "                                        train - Value  \\\n",
       "0   s3://sagemaker-us-east-1-057716757052/NCFModel...   \n",
       "1   s3://sagemaker-us-east-1-057716757052/NCFModel...   \n",
       "..                                                ...   \n",
       "22  s3://sagemaker-us-east-1-057716757052/NCFModel...   \n",
       "23  s3://sagemaker-us-east-1-057716757052/NCFModel...   \n",
       "\n",
       "    SageMaker.DebugHookOutput - MediaType  \\\n",
       "0                                    None   \n",
       "1                                    None   \n",
       "..                                    ...   \n",
       "22                                   None   \n",
       "23                                   None   \n",
       "\n",
       "         SageMaker.DebugHookOutput - Value  \\\n",
       "0   s3://sagemaker-us-east-1-057716757052/   \n",
       "1   s3://sagemaker-us-east-1-057716757052/   \n",
       "..                                     ...   \n",
       "22  s3://sagemaker-us-east-1-057716757052/   \n",
       "23  s3://sagemaker-us-east-1-057716757052/   \n",
       "\n",
       "    SageMaker.ModelArtifact - MediaType  \\\n",
       "0                                  None   \n",
       "1                                  None   \n",
       "..                                  ...   \n",
       "22                                 None   \n",
       "23                                 None   \n",
       "\n",
       "                      SageMaker.ModelArtifact - Value  \\\n",
       "0   s3://sagemaker-us-east-1-057716757052/pytorch-...   \n",
       "1   s3://sagemaker-us-east-1-057716757052/pytorch-...   \n",
       "..                                                ...   \n",
       "22  s3://sagemaker-us-east-1-057716757052/pytorch-...   \n",
       "23  s3://sagemaker-us-east-1-057716757052/pytorch-...   \n",
       "\n",
       "                                               Trials  \\\n",
       "0   [NCFModel-single-train-2022-05-30-06-42-53-130...   \n",
       "1   [NCFModel-single-train-2022-05-30-06-42-53-130...   \n",
       "..                                                ...   \n",
       "22  [NCFModel-single-train-2022-05-22-03-52-16-349...   \n",
       "23  [NCFModel-single-train-2022-05-22-03-14-07-894...   \n",
       "\n",
       "                Experiments  sagemaker_mpi_custom_mpi_options  \\\n",
       "0   [NCFModel-single-train]                               NaN   \n",
       "1   [NCFModel-single-train]                               NaN   \n",
       "..                      ...                               ...   \n",
       "22  [NCFModel-single-train]                               NaN   \n",
       "23  [NCFModel-single-train]                               NaN   \n",
       "\n",
       "    sagemaker_mpi_enabled sagemaker_mpi_num_of_processes_per_host  \n",
       "0                     NaN                                     NaN  \n",
       "1                     NaN                                     NaN  \n",
       "..                    ...                                     ...  \n",
       "22                    NaN                                     NaN  \n",
       "23                    NaN                                     NaN  \n",
       "\n",
       "[24 rows x 62 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.analytics import ExperimentAnalytics\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = 50\n",
    "pd.options.display.max_rows = 5\n",
    "pd.options.display.max_colwidth = 50\n",
    "\n",
    "search_expression = {\n",
    "    \"Filters\": [\n",
    "        {\n",
    "            \"Name\": \"DisplayName\",\n",
    "            \"Operator\": \"Equals\",\n",
    "            \"Value\": \"Training\",\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "\n",
    "trial_component_analytics = ExperimentAnalytics(\n",
    "    sagemaker_session= sagemaker_session,\n",
    "    experiment_name= experiment_name,\n",
    "    search_expression=search_expression,\n",
    ")\n",
    "\n",
    "trial_component_analytics.dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 평가 지표에 순서에 따른 시도 보기\n",
    "- 아래는 모델 평가 지표에 따른 순서로 보여주기 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TrialComponentName</th>\n",
       "      <th>DisplayName</th>\n",
       "      <th>SourceArn</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epochs</th>\n",
       "      <th>factor_num</th>\n",
       "      <th>lr</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>num_ng</th>\n",
       "      <th>test_num_ng</th>\n",
       "      <th>top_k</th>\n",
       "      <th>HR - Min</th>\n",
       "      <th>HR - Max</th>\n",
       "      <th>HR - Avg</th>\n",
       "      <th>HR - StdDev</th>\n",
       "      <th>HR - Last</th>\n",
       "      <th>HR - Count</th>\n",
       "      <th>test - MediaType</th>\n",
       "      <th>test - Value</th>\n",
       "      <th>train - MediaType</th>\n",
       "      <th>train - Value</th>\n",
       "      <th>SageMaker.DebugHookOutput - MediaType</th>\n",
       "      <th>SageMaker.DebugHookOutput - Value</th>\n",
       "      <th>SageMaker.ModelArtifact - MediaType</th>\n",
       "      <th>SageMaker.ModelArtifact - Value</th>\n",
       "      <th>Trials</th>\n",
       "      <th>Experiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pytorch-training-2022-05-27-10-14-43-786-aws-t...</td>\n",
       "      <td>Training</td>\n",
       "      <td>arn:aws:sagemaker:us-east-1:057716757052:train...</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.6718</td>\n",
       "      <td>0.031668</td>\n",
       "      <td>0.681</td>\n",
       "      <td>10.0</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-057716757052/NCFModel...</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-057716757052/NCFModel...</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-057716757052/</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-057716757052/pytorch-...</td>\n",
       "      <td>[NCFModel-single-train-2022-05-27-10-14-43-519...</td>\n",
       "      <td>[NCFModel-single-train]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pytorch-training-2022-05-22-03-52-23-671-aws-t...</td>\n",
       "      <td>Training</td>\n",
       "      <td>arn:aws:sagemaker:us-east-1:057716757052:train...</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.6825</td>\n",
       "      <td>0.019609</td>\n",
       "      <td>0.687</td>\n",
       "      <td>10.0</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-057716757052/NCFModel...</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-057716757052/NCFModel...</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-057716757052/</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-057716757052/pytorch-...</td>\n",
       "      <td>[NCFModel-single-train-2022-05-22-03-52-16-349...</td>\n",
       "      <td>[NCFModel-single-train]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>pytorch-training-2022-05-30-06-28-57-387-aws-t...</td>\n",
       "      <td>Training</td>\n",
       "      <td>arn:aws:sagemaker:us-east-1:057716757052:train...</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-057716757052/NCFModel...</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-057716757052/NCFModel...</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-057716757052/</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-057716757052/pytorch-...</td>\n",
       "      <td>[NCFModel-single-train-2022-05-30-06-20-53-973...</td>\n",
       "      <td>[NCFModel-single-train]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>pytorch-training-2022-05-30-06-53-21-093-aws-t...</td>\n",
       "      <td>Training</td>\n",
       "      <td>arn:aws:sagemaker:us-east-1:057716757052:train...</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-057716757052/NCFModel...</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-057716757052/NCFModel...</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-057716757052/</td>\n",
       "      <td>None</td>\n",
       "      <td>s3://sagemaker-us-east-1-057716757052/pytorch-...</td>\n",
       "      <td>[NCFModel-single-train-2022-05-30-06-42-53-130...</td>\n",
       "      <td>[NCFModel-single-train]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   TrialComponentName DisplayName  \\\n",
       "0   pytorch-training-2022-05-27-10-14-43-786-aws-t...    Training   \n",
       "1   pytorch-training-2022-05-22-03-52-23-671-aws-t...    Training   \n",
       "..                                                ...         ...   \n",
       "22  pytorch-training-2022-05-30-06-28-57-387-aws-t...    Training   \n",
       "23  pytorch-training-2022-05-30-06-53-21-093-aws-t...    Training   \n",
       "\n",
       "                                            SourceArn  batch_size  dropout  \\\n",
       "0   arn:aws:sagemaker:us-east-1:057716757052:train...       256.0      0.0   \n",
       "1   arn:aws:sagemaker:us-east-1:057716757052:train...       256.0      0.0   \n",
       "..                                                ...         ...      ...   \n",
       "22  arn:aws:sagemaker:us-east-1:057716757052:train...       256.0      0.0   \n",
       "23  arn:aws:sagemaker:us-east-1:057716757052:train...       256.0      0.0   \n",
       "\n",
       "    epochs  factor_num     lr  num_layers  num_ng  test_num_ng  top_k  \\\n",
       "0     10.0        32.0  0.001         3.0     4.0         99.0   10.0   \n",
       "1     10.0        32.0  0.001         3.0     4.0         99.0   10.0   \n",
       "..     ...         ...    ...         ...     ...          ...    ...   \n",
       "22     5.0        32.0  0.001         3.0     4.0         99.0   10.0   \n",
       "23     5.0        32.0  0.001         3.0     4.0         99.0   10.0   \n",
       "\n",
       "    HR - Min  HR - Max  HR - Avg  HR - StdDev  HR - Last  HR - Count  \\\n",
       "0      0.593     0.697    0.6718     0.031668      0.681        10.0   \n",
       "1      0.630     0.696    0.6825     0.019609      0.687        10.0   \n",
       "..       ...       ...       ...          ...        ...         ...   \n",
       "22       NaN       NaN       NaN          NaN        NaN         NaN   \n",
       "23       NaN       NaN       NaN          NaN        NaN         NaN   \n",
       "\n",
       "   test - MediaType                                       test - Value  \\\n",
       "0              None  s3://sagemaker-us-east-1-057716757052/NCFModel...   \n",
       "1              None  s3://sagemaker-us-east-1-057716757052/NCFModel...   \n",
       "..              ...                                                ...   \n",
       "22             None  s3://sagemaker-us-east-1-057716757052/NCFModel...   \n",
       "23             None  s3://sagemaker-us-east-1-057716757052/NCFModel...   \n",
       "\n",
       "   train - MediaType                                      train - Value  \\\n",
       "0               None  s3://sagemaker-us-east-1-057716757052/NCFModel...   \n",
       "1               None  s3://sagemaker-us-east-1-057716757052/NCFModel...   \n",
       "..               ...                                                ...   \n",
       "22              None  s3://sagemaker-us-east-1-057716757052/NCFModel...   \n",
       "23              None  s3://sagemaker-us-east-1-057716757052/NCFModel...   \n",
       "\n",
       "   SageMaker.DebugHookOutput - MediaType  \\\n",
       "0                                   None   \n",
       "1                                   None   \n",
       "..                                   ...   \n",
       "22                                  None   \n",
       "23                                  None   \n",
       "\n",
       "         SageMaker.DebugHookOutput - Value  \\\n",
       "0   s3://sagemaker-us-east-1-057716757052/   \n",
       "1   s3://sagemaker-us-east-1-057716757052/   \n",
       "..                                     ...   \n",
       "22  s3://sagemaker-us-east-1-057716757052/   \n",
       "23  s3://sagemaker-us-east-1-057716757052/   \n",
       "\n",
       "   SageMaker.ModelArtifact - MediaType  \\\n",
       "0                                 None   \n",
       "1                                 None   \n",
       "..                                 ...   \n",
       "22                                None   \n",
       "23                                None   \n",
       "\n",
       "                      SageMaker.ModelArtifact - Value  \\\n",
       "0   s3://sagemaker-us-east-1-057716757052/pytorch-...   \n",
       "1   s3://sagemaker-us-east-1-057716757052/pytorch-...   \n",
       "..                                                ...   \n",
       "22  s3://sagemaker-us-east-1-057716757052/pytorch-...   \n",
       "23  s3://sagemaker-us-east-1-057716757052/pytorch-...   \n",
       "\n",
       "                                               Trials              Experiments  \n",
       "0   [NCFModel-single-train-2022-05-27-10-14-43-519...  [NCFModel-single-train]  \n",
       "1   [NCFModel-single-train-2022-05-22-03-52-16-349...  [NCFModel-single-train]  \n",
       "..                                                ...                      ...  \n",
       "22  [NCFModel-single-train-2022-05-30-06-20-53-973...  [NCFModel-single-train]  \n",
       "23  [NCFModel-single-train-2022-05-30-06-42-53-130...  [NCFModel-single-train]  \n",
       "\n",
       "[24 rows x 28 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "trial_component_training_analytics = ExperimentAnalytics(\n",
    "    sagemaker_session= sagemaker_session,\n",
    "    experiment_name= experiment_name,\n",
    "    search_expression=search_expression,\n",
    "    sort_by=\"metrics.HR.max\",        \n",
    "    sort_order=\"Descending\",\n",
    "    metric_names=[\"HR\"],    \n",
    "    parameter_names=[\"epochs\", \"batch_size\", \"dropout\", \"factor_num\", \n",
    "                     \"lr\", \"num_layers\" ,\"num_ng\", \"test_num_ng\", \"top_k\",\n",
    "                    ],\n",
    ")\n",
    "\n",
    "trial_component_training_analytics.dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 모델 아티펙트 저장\n",
    "- S3 에 저장된 모델 아티펙트를 저장하여 추론시 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "horovod_artifact_path:  s3://sagemaker-us-east-1-057716757052/pytorch-training-2022-05-30-07-27-00-364/output/model.tar.gz\n",
      "Stored 'horovod_artifact_path' (str)\n"
     ]
    }
   ],
   "source": [
    "horovod_artifact_path = host_estimator.model_data\n",
    "print(\"horovod_artifact_path: \", horovod_artifact_path)\n",
    "\n",
    "%store horovod_artifact_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기타 변수 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'bucket' (str)\n",
      "Stored 'prefix' (str)\n"
     ]
    }
   ],
   "source": [
    "%store bucket \n",
    "%store prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
