{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acd571a5",
   "metadata": {},
   "source": [
    "# [Module 1.1] 로컬 스크래치 훈련 (SageMaker 사용 안함)\n",
    " \n",
    "### 본 워크샵의 모든 노트북은 `conda_python3` 여기에서 작업 합니다.\n",
    "\n",
    "이 노트북은 아래와 같은 작업을 합니다.\n",
    "\n",
    "- 1. 환경 셋업\n",
    "- 2. 데이터 확인\n",
    "- 3. 로컬 모델 훈련\n",
    "- 4. 로컬 추론\n",
    "- 5. 로컬에서 훈련 스크립트로 실행\n",
    "\n",
    "## 참고:\n",
    "- 세이지 메이커로 파이토치 사용 --> [Use PyTorch with the SageMaker Python SDK](https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c972f89",
   "metadata": {},
   "source": [
    "# 1. 환경 셋업"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9d1082",
   "metadata": {},
   "source": [
    "## 기본 세팅\n",
    "사용하는 패키지는 import 시점에 다시 재로딩 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0b3b004",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# src 폴더 경로 설정\n",
    "import sys\n",
    "sys.path.append('./src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d46f660",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from IPython.display import display as dp\n",
    "\n",
    "### 커스텀 라이브러리\n",
    "import config \n",
    "import model \n",
    "import evaluate \n",
    "import data_utils "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f28673",
   "metadata": {},
   "source": [
    "# 2. 데이터 확인\n",
    "- [원본: 데이터 설명](https://github.com/hexiangnan/neural_collaborative_filtering)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4593701",
   "metadata": {},
   "source": [
    "## 2.1. 데이터 및 훈련 설정 파일 확인\n",
    "- 사용 데이터 파일 위치 및 모델 이름 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d931deb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m# dataset name \u001b[39;49;00m\n",
      "dataset = \u001b[33m'\u001b[39;49;00m\u001b[33mml-1m\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "\u001b[34massert\u001b[39;49;00m dataset \u001b[35min\u001b[39;49;00m [\u001b[33m'\u001b[39;49;00m\u001b[33mml-1m\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mpinterest-20\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\n",
      "\n",
      "\u001b[37m# model name \u001b[39;49;00m\n",
      "model = \u001b[33m'\u001b[39;49;00m\u001b[33mNeuMF-end\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "\u001b[34massert\u001b[39;49;00m model \u001b[35min\u001b[39;49;00m [\u001b[33m'\u001b[39;49;00m\u001b[33mMLP\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mGMF\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mNeuMF-end\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mNeuMF-pre\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\n",
      "\n",
      "main_path = \u001b[33m'\u001b[39;49;00m\u001b[33m../data/\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "\n",
      "train_rating = main_path + \u001b[33m'\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m.train.rating\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(dataset)\n",
      "test_rating = main_path + \u001b[33m'\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m.test.rating\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(dataset)\n",
      "test_negative = main_path + \u001b[33m'\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m.test.negative\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(dataset)\n",
      "\n",
      "model_path = \u001b[33m'\u001b[39;49;00m\u001b[33m./models/\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "GMF_model_path = model_path + \u001b[33m'\u001b[39;49;00m\u001b[33mGMF.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "MLP_model_path = model_path + \u001b[33m'\u001b[39;49;00m\u001b[33mMLP.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "NeuMF_model_path = model_path + \u001b[33m'\u001b[39;49;00m\u001b[33mNeuMF.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "gs_NeuMF_model_path = model_path + \u001b[33m'\u001b[39;49;00m\u001b[33mNeuMF-end.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "! pygmentize src/config.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45642729",
   "metadata": {},
   "source": [
    "## 2.2. Raw 파일 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392d4ef8",
   "metadata": {},
   "source": [
    "### train_rating\n",
    "- user_id, item_id, rating, timestamp 의 4개의 컬럼으로 구성 됨.\n",
    "    - 참고로 test_rating 파일을 본 코드에서 사용되지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea4fc359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t32\t4\t978824330\n",
      "0\t34\t4\t978824330\n",
      "0\t4\t5\t978824291\n",
      "0\t35\t4\t978824291\n",
      "0\t30\t4\t978824291\n"
     ]
    }
   ],
   "source": [
    "! head -n5 {config.train_rating}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710a69ea",
   "metadata": {},
   "source": [
    "### test_negative\n",
    "- user_id 별로 구성됨\n",
    "- 아래는 첫번째 user_id \"0\" 의 내용 임. \n",
    "    - 첫 번째 항목은 (0,25) \"0\" 의 user_id 가 25 번 item_id 를 rating 했다는 것을 기록 함. \n",
    "    - 나머지 99 개는 \"0\" user_id 가 rating  하지 않은 item_id 99 개를 가져옴\n",
    "        - 실제 모델 추론시에 top k (예; k=5)  항목을 추천을 받았을 시에  \"25\" 이 top k 에 포함의 유무에 따라서 performance metric 을 계산 함. \n",
    "        - 예를 들어서 추론을 하여 받은 추천 리스트가 (1064, 25, 2791, 1902, 915) 일 경우에 HR (Hit Ratio) 는 1 이 됨. 만약 (1064, 1135, 2791, 1902, 915) 처럼 25 가 없으면 HR 은 0 임.\n",
    "\n",
    "```\n",
    "(0,25)\t1064\t174\t2791\t3373\t269\t2678\t1902\t3641\t1216\t915\t3672\t2803\t2344\t986\t3217\t2824\t2598\t464\t2340\t1952\t1855\t1353\t1547\t3487\t3293\t1541\t2414\t2728\t340\t1421\t1963\t2545\t972\t487\t3463\t2727\t1135\t3135\t128\t175\t2423\t1974\t2515\t3278\t3079\t1527\t2182\t1018\t2800\t1830\t1539\t617\t247\t3448\t1699\t1420\t2487\t198\t811\t1010\t1423\t2840\t1770\t881\t1913\t1803\t1734\t3326\t1617\t224\t3352\t1869\t1182\t1331\t336\t2517\t1721\t3512\t3656\t273\t1026\t1991\t2190\t998\t3386\t3369\t185\t2822\t864\t2854\t3067\t58\t2551\t2333\t2688\t3703\t1300\t1924\t3118\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4679d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,25)\t1064\t174\t2791\t3373\t269\t2678\t1902\t3641\t1216\t915\t3672\t2803\t2344\t986\t3217\t2824\t2598\t464\t2340\t1952\t1855\t1353\t1547\t3487\t3293\t1541\t2414\t2728\t340\t1421\t1963\t2545\t972\t487\t3463\t2727\t1135\t3135\t128\t175\t2423\t1974\t2515\t3278\t3079\t1527\t2182\t1018\t2800\t1830\t1539\t617\t247\t3448\t1699\t1420\t2487\t198\t811\t1010\t1423\t2840\t1770\t881\t1913\t1803\t1734\t3326\t1617\t224\t3352\t1869\t1182\t1331\t336\t2517\t1721\t3512\t3656\t273\t1026\t1991\t2190\t998\t3386\t3369\t185\t2822\t864\t2854\t3067\t58\t2551\t2333\t2688\t3703\t1300\t1924\t3118\n",
      "(1,133)\t1072\t3154\t3368\t3644\t549\t1810\t937\t1514\t1713\t2186\t660\t2303\t2416\t670\t1176\t788\t889\t3120\t2344\t2525\t3301\t2055\t1436\t2630\t11\t2773\t2176\t1847\t740\t2332\t3561\t263\t3658\t3282\t1980\t2093\t3287\t3190\t3475\t569\t2315\t1442\t592\t546\t3133\t1852\t2648\t934\t337\t483\t1017\t3452\t467\t1183\t1765\t601\t2413\t2602\t2801\t2976\t918\t753\t3540\t3341\t2973\t1580\t2118\t3511\t526\t1719\t525\t1520\t486\t557\t1353\t500\t2902\t1687\t1295\t2997\t2415\t797\t2518\t926\t3537\t1746\t1676\t1875\t3029\t1535\t341\t3525\t1429\t2225\t1628\t2061\t469\t3056\t2553\n"
     ]
    }
   ],
   "source": [
    "! head -n2 {config.test_negative}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cf2a4c",
   "metadata": {},
   "source": [
    "## 2.3. 훈련 및 테스트 데이터 확인\n",
    "- raw 파일로 부터 훈련, 테스트 데이터 로딩\n",
    "- 데이터 상세\n",
    "    - 훈련 데이타는 994,169 의 rating 개수\n",
    "    - 테스트 데이타는 604,000 의 rating 개수\n",
    "    - user_num: 6040, item_num: 3706 의 유니크한 항목"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fe8dc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, user_num ,item_num, train_mat = data_utils.load_all()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ca6dacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train sahpe:  (994169, 2)\n",
      "test sahpe:  (604000, 2)\n",
      "user_num: 6040, item_num: 3706\n",
      "[[0, 32], [0, 34], [0, 4], [0, 35], [0, 30]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(\"train sahpe: \", np.asarray(train_data).shape)\n",
    "print(\"test sahpe: \", np.asarray(test_data).shape)\n",
    "print(f\"user_num: {user_num}, item_num: {item_num}\")\n",
    "print(train_data[0:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c523557",
   "metadata": {},
   "source": [
    "### 훈련 데이터 상세\n",
    "- 훈련 데이타는 rating 컬럼을 사용하지 않고, user_id, item_id 두개만 사용 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c929b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df shape:  (994169, 2)\n",
      "train_df info: \n",
      " user    6040\n",
      "item    3704\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_data_df = pd.DataFrame(train_data, columns=['user','item'])\n",
    "print(\"train_df shape: \", train_data_df.shape)\n",
    "print(\"train_df info: \\n\", train_data_df.nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "25a5fcc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user  item\n",
       "42     0     0\n",
       "21     0     1\n",
       "26     0     2\n",
       "45     0     3\n",
       "2      0     4"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_df.sort_values(by=['user','item']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc20011",
   "metadata": {},
   "source": [
    "user_id 당 item rating의 개수를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa88f372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      item\n",
       "user      \n",
       "0       52\n",
       "1      128\n",
       "2       50\n",
       "3       20\n",
       "4      197"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_df.groupby('user').count().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a002f1e7",
   "metadata": {},
   "source": [
    "### 테스트 데이터 상세"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "032428dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item\n",
       "0     0    25\n",
       "1     0  1064\n",
       "2     0   174\n",
       "3     0  2791\n",
       "4     0  3373"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_data_df = pd.DataFrame(test_data, columns=['user','item'])\n",
    "dp(test_data_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0b7fe5",
   "metadata": {},
   "source": [
    "테스트 데이타는 user_id 당 모두 100개의 항목으로 구성 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "260a468b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      item\n",
       "user      \n",
       "0      100\n",
       "1      100\n",
       "2      100\n",
       "3      100\n",
       "4      100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dp(test_data_df.groupby('user').count().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39daec76",
   "metadata": {},
   "source": [
    "# 3. 로컬 모델 훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2935c069",
   "metadata": {},
   "source": [
    "## 3.1. 파라미터 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398a45a7",
   "metadata": {},
   "source": [
    "## 모델의 하이퍼파라미터 정의\n",
    "- 하아퍼 파라미터 오브젝트 이름을 args 로 생성\n",
    "    - 추후 SageMaker의 Script Mode 사용사에 args 오브젝트가 사용되기에, 이름을 맞추기 위해서 같은 이름을 사용 함\n",
    "- 아래 파라미터는 로직 확인 용이기에, 훈련이 빨리 끝나기 위한 파라미터 값을 설정 함(에; epoch)    \n",
    "    - 약 2분 30초 소요 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "754b6ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of epochs:  1\n"
     ]
    }
   ],
   "source": [
    "class Params:\n",
    "    def __init__(self):\n",
    "        self.epochs = 1        \n",
    "        self.num_ng = 4\n",
    "        self.batch_size = 256\n",
    "        self.test_num_ng = 99\n",
    "        self.factor_num = 32\n",
    "        self.num_layers = 3\n",
    "        self.dropout = 0.0\n",
    "        self.lr = 0.001\n",
    "        self.top_k = 10\n",
    "        self.out = True\n",
    "        self.gpu = \"0\"\n",
    "                        \n",
    "args = Params()\n",
    "print(\"# of epochs: \", args.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d311a1",
   "metadata": {},
   "source": [
    "## 3.2. 데이터 셋 및 데이터 로더 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bf5ca9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = data_utils.NCFData(\n",
    "\t\ttrain_data, item_num, train_mat, args.num_ng, True)\n",
    "\n",
    "test_dataset = data_utils.NCFData(\n",
    "\t\ttest_data, item_num, train_mat, 0, False)\n",
    "\n",
    "train_loader = data.DataLoader(train_dataset,\n",
    "\t\tbatch_size=args.batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "test_loader = data.DataLoader(test_dataset,\n",
    "\t\tbatch_size=args.test_num_ng+1, shuffle=False, num_workers=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a311c55c",
   "metadata": {},
   "source": [
    "## 3.3. 모델 네트워크 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d641759e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda\n",
      "Pretrained model is NOT used\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NCF(\n",
       "  (embed_user_GMF): Embedding(6040, 32)\n",
       "  (embed_item_GMF): Embedding(3706, 32)\n",
       "  (embed_user_MLP): Embedding(6040, 128)\n",
       "  (embed_item_MLP): Embedding(3706, 128)\n",
       "  (MLP_layers): Sequential(\n",
       "    (0): Dropout(p=0.0, inplace=False)\n",
       "    (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.0, inplace=False)\n",
       "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Dropout(p=0.0, inplace=False)\n",
       "    (7): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (8): ReLU()\n",
       "  )\n",
       "  (predict_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########################### CREATE MODEL #################################\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"device: \", device)\n",
    "\n",
    "if config.model == 'NeuMF-pre':\n",
    "    assert os.path.exists(config.GMF_model_path), 'lack of GMF model'\n",
    "    assert os.path.exists(config.MLP_model_path), 'lack of MLP model'\n",
    "    GMF_model = torch.load(config.GMF_model_path)\n",
    "    MLP_model = torch.load(config.MLP_model_path)\n",
    "    print(\"Pretrained model is used\")\n",
    "else:\n",
    "    GMF_model = None\n",
    "    MLP_model = None\n",
    "    print(\"Pretrained model is NOT used\")    \n",
    "\n",
    "NCF_model = model.NCF(user_num, item_num, args.factor_num, args.num_layers, \n",
    "\t\t\t\t\t\targs.dropout, config.model, GMF_model, MLP_model)\n",
    "NCF_model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f120b5",
   "metadata": {},
   "source": [
    "## 3.4. 손실 함수 및 옵티마이저 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "08d1c5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "\n",
    "if config.model == 'NeuMF-pre':\n",
    "\toptimizer = optim.SGD(NCF_model.parameters(), lr=args.lr)\n",
    "else:\n",
    "\toptimizer = optim.Adam(NCF_model.parameters(), lr=args.lr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea36dec8",
   "metadata": {},
   "source": [
    "## 3.5 훈련 루프 실행\n",
    "- 훈련 루프에 들어가면서 `train_loader.dataset.ng_sample()` 를 통해서 Negative sample을 생성함.\n",
    "    - self.num_ng = 4 * Positive Samples 만큼 생성 됨.\n",
    "    - 아래는 예시 임.\n",
    "```\n",
    "labels_ps:  994169\n",
    "labels_ng:  3976676\n",
    "total train size :  4970845\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "23df66fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====> Staring Traiing <===========\n",
      "device:  cuda\n",
      "labels_ps:  994169\n",
      "labels_ng:  3976676\n",
      "total train size :  4970845\n",
      "last batch number is 19418\n",
      "user\n",
      "tensor([3100, 1448, 4008, 4057, 1973, 4125, 3421,  986, 1355, 4378, 1184, 2938,\n",
      "        3515, 2678, 5716, 5298,  970, 4672, 5830, 4483, 3884,  535, 3497,  254,\n",
      "        3355, 1968, 5820, 4592, 4636, 4386, 3016, 1500, 1839, 3352, 1748, 5452,\n",
      "        4152,  313, 5474, 3760, 5041, 2218, 2009, 5821, 1077, 4444, 6035,  698,\n",
      "        2971, 5396, 3065, 3398, 1261, 2096, 3079, 2062,  412,  880, 3599, 4731,\n",
      "        2974, 3525,  977, 1172, 4477, 5954, 3640, 4210, 5270, 1300, 2177, 4116,\n",
      "        2819, 1067, 1118,  779, 5293, 3153, 4793, 3647, 5725,  159, 2582, 1100,\n",
      "        5546, 5507, 5256, 4063, 2154, 5396, 3929, 5901, 2619], device='cuda:0'), item\n",
      "tensor([ 124,  165, 3643, 2759,  465, 1668, 2956,  180,  140, 3191, 3491,    3,\n",
      "        3245,  678, 1478, 2365, 2088, 1778, 2646,  443, 2416,  905, 1574,  724,\n",
      "        1555,  176, 2485, 1987, 1314, 1603, 2113, 3189,  622, 2142,  974,  690,\n",
      "        2466, 2677, 2242, 3620,  915, 1672,  699,  736, 2076,  424, 1278, 1707,\n",
      "          93,  348, 2390, 2971, 1425, 1638, 2182, 3070,  967, 1127, 2482, 1084,\n",
      "        2337,  888, 3324, 3118, 3570, 2162, 3260, 3436, 2192,  168,  147, 2881,\n",
      "        1692, 1118, 1308,  758,  929, 1481, 2140, 2975,  699, 2036,  425, 1470,\n",
      "        2977,  611, 1793,  664, 2099,  460,  984,  726, 1945], device='cuda:0'), label\n",
      "tensor([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
      "        0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0.], device='cuda:0'): \n",
      "cuda\n",
      "The time elapse of epoch 000 is: 00: 02: 06\n",
      "HR: 0.643\tNDCG: 0.371\n",
      "End. Best epoch 000: HR = 0.643, NDCG = 0.371\n"
     ]
    }
   ],
   "source": [
    "print(\"=====> Staring Traiing <===========\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"device: \", device)\n",
    "\n",
    "\n",
    "count, best_hr = 0, 0\n",
    "for epoch in range(args.epochs):\n",
    "    NCF_model.train() # Enable dropout (if have).\n",
    "    start_time = time.time()\n",
    "    # negative sample 생성\n",
    "    train_loader.dataset.ng_sample()\n",
    "\n",
    "    for user, item, label in train_loader:\n",
    "        user = user.to(device)\n",
    "        item = item.to(device)\n",
    "        label = label.float().to(device)\n",
    "\n",
    "        NCF_model.zero_grad()\n",
    "        prediction = NCF_model(user, item)\n",
    "        loss = loss_function(prediction, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        count += 1\n",
    "        \n",
    "    # 미자믹 배치의 user, item, label 확인\n",
    "    print(f\"last batch number is {count}\")\n",
    "    print(f\"user\\n{user}, item\\n{item}, label\\n{label}: \")\n",
    "\n",
    "\n",
    "    NCF_model.eval()\n",
    "    HR, NDCG = evaluate.metrics(NCF_model, test_loader, args.top_k)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"The time elapse of epoch {:03d}\".format(epoch) + \" is: \" + \n",
    "            time.strftime(\"%H: %M: %S\", time.gmtime(elapsed_time)))\n",
    "    print(\"HR: {:.3f}\\tNDCG: {:.3f}\".format(np.mean(HR), np.mean(NDCG)))\n",
    "\n",
    "    if HR > best_hr:\n",
    "        best_hr, best_ndcg, best_epoch = HR, NDCG, epoch\n",
    "        if args.out:\n",
    "            if not os.path.exists(config.model_path):\n",
    "                os.mkdir(config.model_path)\n",
    "            torch.save(NCF_model.state_dict(),'{}{}.pth'.format(config.model_path, config.model))\n",
    "\n",
    "            \n",
    "print(\"End. Best epoch {:03d}: HR = {:.3f}, NDCG = {:.3f}\".format(\n",
    "\t\t\t\t\t\t\t\t\tbest_epoch, best_hr, best_ndcg))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0a1055",
   "metadata": {},
   "source": [
    "# 4. 로컬 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "18b5a2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "867a9935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paylaod: \n",
      " {'user': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'item': [25, 1064, 174, 2791, 3373, 269, 2678, 1902, 3641, 1216, 915, 3672, 2803, 2344, 986, 3217, 2824, 2598, 464, 2340, 1952, 1855, 1353, 1547, 3487, 3293, 1541, 2414, 2728, 340, 1421, 1963, 2545, 972, 487, 3463, 2727, 1135, 3135, 128, 175, 2423, 1974, 2515, 3278, 3079, 1527, 2182, 1018, 2800, 1830, 1539, 617, 247, 3448, 1699, 1420, 2487, 198, 811, 1010, 1423, 2840, 1770, 881, 1913, 1803, 1734, 3326, 1617, 224, 3352, 1869, 1182, 1331, 336, 2517, 1721, 3512, 3656, 273, 1026, 1991, 2190, 998, 3386, 3369, 185, 2822, 864, 2854, 3067, 58, 2551, 2333, 2688, 3703, 1300, 1924, 3118]}\n"
     ]
    }
   ],
   "source": [
    "for user, item, label in test_loader:   \n",
    "    user_np = user.detach().cpu().numpy()\n",
    "    item_np = item.detach().cpu().numpy()            \n",
    "    break\n",
    "payload = {'user':user_np.tolist(), 'item':item_np.tolist()}\n",
    "\n",
    "print(\"paylaod: \\n\" , payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dfacd1c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[128, 273, 174, 25, 58, 175, 464, 881, 1064, 198]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(NCF_model, payload, top_k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da12bd5",
   "metadata": {},
   "source": [
    "# 5. 로컬에서 훈련 스크립트로 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca32d14",
   "metadata": {},
   "source": [
    "- 이번에는 훈련 코드를 스크립트 src/train_lib.py 로 만들고 train(args) 를 호출 하여 실행 합니다.\n",
    "    - 위와의 차이점은 추후 SageMaker 에서 실행하기 위해서 python file 로 모듈화를 한 것 입니다.\n",
    "\n",
    "\n",
    "- 중요한 단계를 로깅 합니다.\n",
    "    - 훈련 환경 셋업, \n",
    "    - 데이터 준비 및 데이터 로더 생성\n",
    "    - 모델 네트워크 로딩\n",
    "    - 모델 훈련 시작\n",
    "    - 모델 훈련 완료\n",
    "    - 모델 아티펙트 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09eebb20",
   "metadata": {},
   "source": [
    "이번에도 하이퍼 파라미터를 정의해서 실행 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e228546b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of epochs:  1\n"
     ]
    }
   ],
   "source": [
    "class ParamsScript:\n",
    "    def __init__(self):\n",
    "        self.epochs = 1\n",
    "        self.lr = 0.001 # 0.001 오리지널 버전        \n",
    "        self.num_ng = 4\n",
    "        self.batch_size = 256\n",
    "        self.test_num_ng = 99\n",
    "        self.factor_num = 32\n",
    "        self.num_layers = 3\n",
    "        self.dropout = 0.0\n",
    "        self.top_k = 10\n",
    "        self.out = True\n",
    "        self.gpu = \"0\"\n",
    "        self.model_dir = f\"{config.model_path}\"                                       \n",
    "        self.train_data_dir = f\"{config.main_path}\"               \n",
    "        self.test_data_dir = f\"{config.main_path}\"                       \n",
    "\n",
    "                        \n",
    "script_args = ParamsScript()\n",
    "print(\"# of epochs: \", script_args.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c915d6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_lib import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "afff730d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args: \n",
      " <__main__.ParamsScript object at 0x7f4d8f58f9b0>\n",
      "device:  cuda\n",
      "args.train_data_dir:  ../data/\n",
      "args.test_data_dir:  ../data/\n",
      "args.model_dir:  ./models/\n",
      "=====> data loading <===========\n",
      "=====> create data loader <===========\n",
      "Pretrained model is NOT used\n",
      "=====> Staring Traiing <===========\n",
      "labels_ps:  994169\n",
      "labels_ng:  3976676\n",
      "total train size :  4970845\n",
      "cuda\n",
      "The time elapse of epoch 000 is: 00: 02: 05\n",
      "HR=0.628; \t NDCG=0.366;\n",
      "best_hr:  0\n",
      "the model is saved at ./models/NeuMF-end.pth\n",
      "End. Best epoch 000: HR = 0.628, NDCG = 0.366\n",
      "CPU times: user 2min 9s, sys: 10.3 s, total: 2min 20s\n",
      "Wall time: 2min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "train(script_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ae2f46",
   "metadata": {},
   "source": [
    "# 참고:  평가 방법\n",
    "\n",
    "[Neural Collaborative Filtering 논문](https://arxiv.org/pdf/1708.05031.pdf)\n",
    "- Evaluation Protocols. To evaluate the performance of item recommendation, we adopted the leave-one-out evalu- ation, which has been widely used in literature [1, 14, 27]. For each user, we held-out her latest interaction as the test set and utilized the remaining data for training. Since it is too time-consuming to rank all items for every user during evaluation, we followed the common strategy [6, 21] that randomly samples 100 items that are not interacted by the user, ranking the test item among the 100 items. The perfor- mance of a ranked list is judged by Hit Ratio (HR) and Nor- malized Discounted Cumulative Gain (NDCG) [11]. With- out special mention, we truncated the ranked list at 10 for both metrics. As such, the HR intuitively measures whether the test item is present on the top-10 list, and the NDCG accounts for the position of the hit by assigning higher scores to hits at top ranks. We calculated both metrics for each test user and reported the average score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8ce1b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
