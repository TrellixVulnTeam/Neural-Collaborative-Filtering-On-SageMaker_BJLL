{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Module 1.2] 로컬 모드 및 스크립트 모드로 훈련 (SageMaker 사용)\n",
    "\n",
    "### 본 워크샵의 모든 노트북은 `conda_python3` 여기에서 작업 합니다.\n",
    "\n",
    "이 노트북은 아래와 같은 작업을 합니다.\n",
    "- 1. 환경 셋업\n",
    "- 2. 세이지 메이크 로컬 모드 훈련\n",
    "- 3. SageMaker Host Mode 로 훈련\n",
    "- 4. 모델 아티펙트 저장\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 환경 셋업"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기본 세팅\n",
    "사용하는 패키지는 import 시점에 다시 재로딩 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('./src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 커스텀 라이브러리\n",
    "import config "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "버킷 및 폴더(prefix) 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "use_default_bucket = True\n",
    "if use_default_bucket:\n",
    "    bucket = sagemaker_session.default_bucket()\n",
    "else:\n",
    "    bucket = '<Type your bucket>'\n",
    "    \n",
    "prefix = \"NCFModel\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 세이지 메이크 로컬 모드 훈련\n",
    "#### 로컬의 GPU, CPU 여부로 instance_type 결정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance type = local_gpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "\n",
    "try:\n",
    "    if subprocess.call(\"nvidia-smi\") == 0:\n",
    "        ## Set type to GPU if one is present\n",
    "        instance_type = \"local_gpu\"\n",
    "    else:\n",
    "        instance_type = \"local\"        \n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(\"Instance type = \" + instance_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. 스크립트 모드의 코드 작성 방법\n",
    "- ![script_mode_example](img/script_mode_example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.훈련 코드 확인\n",
    "- 아래의 코드는 전형적인 스크립트 모드의 코드 작성 방법을 따르고 있습니다.\n",
    "- 훈련 함수는 `from train_lib import train` 로서 이전 노트북의 **[세이지 메이커 없이]** 작성한 스크래치 버전에서 사용한 훈련 함수와 동일 합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\n",
      "sys.path.append(\u001b[33m'\u001b[39;49;00m\u001b[33m./src\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtrain_lib\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m train\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\n",
      "    parser = argparse.ArgumentParser()\n",
      "\n",
      "    \u001b[37m##################################\u001b[39;49;00m\n",
      "    \u001b[37m#### 세이지 메이커 프레임워크의 도커 컨테이너 환경 변수 인자\u001b[39;49;00m\n",
      "    \u001b[37m##################################\u001b[39;49;00m\n",
      "\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--train-data-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAIN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    \n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--test-data-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TEST\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "\n",
      "    \n",
      "        \n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--model-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])    \n",
      "           \n",
      "    \n",
      "    \u001b[37m##################################\u001b[39;49;00m\n",
      "    \u001b[37m#### 사용자 정의 커맨드 인자\u001b[39;49;00m\n",
      "    \u001b[37m##################################\u001b[39;49;00m\n",
      "\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--lr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, \n",
      "        default=\u001b[34m0.001\u001b[39;49;00m, \n",
      "        help=\u001b[33m\"\u001b[39;49;00m\u001b[33mlearning rate\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--dropout\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m,\n",
      "        default=\u001b[34m0.0\u001b[39;49;00m,  \n",
      "        help=\u001b[33m\"\u001b[39;49;00m\u001b[33mdropout rate\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--batch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, \n",
      "        default=\u001b[34m256\u001b[39;49;00m, \n",
      "        help=\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch size for training\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--epochs\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m,\n",
      "        default=\u001b[34m20\u001b[39;49;00m,  \n",
      "        help=\u001b[33m\"\u001b[39;49;00m\u001b[33mtraining epoches\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--top_k\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, \n",
      "        default=\u001b[34m10\u001b[39;49;00m, \n",
      "        help=\u001b[33m\"\u001b[39;49;00m\u001b[33mcompute metrics@top_k\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--factor_num\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m,\n",
      "        default=\u001b[34m32\u001b[39;49;00m, \n",
      "        help=\u001b[33m\"\u001b[39;49;00m\u001b[33mpredictive factors numbers in the model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--num_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m,\n",
      "        default=\u001b[34m3\u001b[39;49;00m, \n",
      "        help=\u001b[33m\"\u001b[39;49;00m\u001b[33mnumber of layers in MLP model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--num_ng\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m,\n",
      "        default=\u001b[34m4\u001b[39;49;00m, \n",
      "        help=\u001b[33m\"\u001b[39;49;00m\u001b[33msample negative items for training\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--test_num_ng\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m,\n",
      "        default=\u001b[34m99\u001b[39;49;00m, \n",
      "        help=\u001b[33m\"\u001b[39;49;00m\u001b[33msample part of negative items for testing\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--out\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \n",
      "        default=\u001b[34mTrue\u001b[39;49;00m,\n",
      "        help=\u001b[33m\"\u001b[39;49;00m\u001b[33msave model or not\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--gpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m,\n",
      "        default=\u001b[33m\"\u001b[39;49;00m\u001b[33m0\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,  \n",
      "        help=\u001b[33m\"\u001b[39;49;00m\u001b[33mgpu card ID\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    args = parser.parse_args()\n",
      "    \n",
      "\n",
      "    \u001b[37m##################################\u001b[39;49;00m\n",
      "    \u001b[37m#### 훈련 함수 콜\u001b[39;49;00m\n",
      "    \u001b[37m##################################\u001b[39;49;00m\n",
      "    \n",
      "    train(args)\n"
     ]
    }
   ],
   "source": [
    "train_code = 'src/train.py'\n",
    "!pygmentize {train_code}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. 로컬에 있는 데이타 세트의 위치를 지정 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_inputs:  ../data/\n"
     ]
    }
   ],
   "source": [
    "local_inputs = config.main_path\n",
    "print(\"local_inputs: \", local_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_inputs = {'train': f'file://{local_inputs}',\n",
    "          'test': f'file://{local_inputs}'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. 로컬 모드로 훈련 실행\n",
    "- 아래의 두 라인이 로컬모드로 훈련을 지시 합니다.\n",
    "```python\n",
    "    instance_type=instance_type, # local_gpu or local 지정\n",
    "    session = sagemaker.LocalSession(), # 로컬 세션을 사용합니다.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {'epochs': 1, \n",
    "                   'lr': 0.001,\n",
    "                   'batch_size': 256,\n",
    "                   'top_k' : 10,\n",
    "                   'dropout' : 0.0,\n",
    "                   'factor_num' : 32,\n",
    "                   'num_layers' : 3,\n",
    "                   'num_ng' : 4,\n",
    "                   'test_num_ng' : 99,                   \n",
    "                    }  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating cewpqtd5wr-algo-1-1ticz ... \n",
      "Creating cewpqtd5wr-algo-1-1ticz ... done\n",
      "Attaching to cewpqtd5wr-algo-1-1ticz\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m 2022-05-21 13:37:11,710 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m 2022-05-21 13:37:11,733 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m 2022-05-21 13:37:11,735 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m 2022-05-21 13:37:11,928 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m /opt/conda/bin/python3.6 -m pip install -r requirements.txt\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m Requirement already satisfied: nvidia-ml-py3==7.352 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (7.352.0)\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m Collecting pandas==0.24.2\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m   Downloading pandas-0.24.2-cp36-cp36m-manylinux1_x86_64.whl (10.1 MB)\n",
      "     |████████████████████████████████| 10.1 MB 24.4 MB/s            \n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m \u001b[?25hCollecting numpy==1.16.6\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m   Downloading numpy-1.16.6-cp36-cp36m-manylinux1_x86_64.whl (17.4 MB)\n",
      "     |████████████████████████████████| 17.4 MB 44.7 MB/s            \n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m \u001b[?25hRequirement already satisfied: torch==1.8.1 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 4)) (1.8.1)\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m Collecting torchsummary==1.5.1\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m   Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m Collecting gensim==3.7.1\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m   Downloading gensim-3.7.1-cp36-cp36m-manylinux1_x86_64.whl (24.2 MB)\n",
      "     |████████████████████████████████| 24.2 MB 46.5 MB/s            \n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m \u001b[?25hCollecting tensorboardX==1.6\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m   Downloading tensorboardX-1.6-py2.py3-none-any.whl (129 kB)\n",
      "     |████████████████████████████████| 129 kB 52.6 MB/s            \n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m \u001b[?25hRequirement already satisfied: pytz>=2011k in /opt/conda/lib/python3.6/site-packages (from pandas==0.24.2->-r requirements.txt (line 2)) (2021.3)\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m Requirement already satisfied: python-dateutil>=2.5.0 in /opt/conda/lib/python3.6/site-packages (from pandas==0.24.2->-r requirements.txt (line 2)) (2.8.2)\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.6/site-packages (from torch==1.8.1->-r requirements.txt (line 4)) (3.10.0.2)\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from torch==1.8.1->-r requirements.txt (line 4)) (0.8)\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m Requirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.6/site-packages (from gensim==3.7.1->-r requirements.txt (line 6)) (1.5.4)\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m Requirement already satisfied: smart-open>=1.7.0 in /opt/conda/lib/python3.6/site-packages (from gensim==3.7.1->-r requirements.txt (line 6)) (5.2.1)\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m Requirement already satisfied: six>=1.5.0 in /opt/conda/lib/python3.6/site-packages (from gensim==3.7.1->-r requirements.txt (line 6)) (1.16.0)\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m Requirement already satisfied: protobuf>=3.2.0 in /opt/conda/lib/python3.6/site-packages (from tensorboardX==1.6->-r requirements.txt (line 7)) (3.19.1)\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m Installing collected packages: numpy, torchsummary, tensorboardX, pandas, gensim\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m   Attempting uninstall: numpy\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m     Found existing installation: numpy 1.19.1\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m     Uninstalling numpy-1.19.1:\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m       Successfully uninstalled numpy-1.19.1\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m   Attempting uninstall: pandas\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m     Found existing installation: pandas 1.1.5\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m     Uninstalling pandas-1.1.5:\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m       Successfully uninstalled pandas-1.1.5\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m Successfully installed gensim-3.7.1 numpy-1.16.6 pandas-0.24.2 tensorboardX-1.6 torchsummary-1.5.1\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m \n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m 2022-05-21 13:37:24,701 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m \n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m Training Env:\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m \n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m {\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m         \"train\": \"/opt/ml/input/data/train\",\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m         \"test\": \"/opt/ml/input/data/test\"\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m     },\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m     \"current_host\": \"algo-1-1ticz\",\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m     \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m     \"hosts\": [\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m         \"algo-1-1ticz\"\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m     ],\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m         \"epochs\": 1,\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m         \"lr\": 0.001,\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m         \"batch_size\": 256,\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m         \"top_k\": 10,\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m         \"dropout\": 0.0,\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m         \"factor_num\": 32,\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m         \"num_layers\": 3,\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m         \"num_ng\": 4,\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m         \"test_num_ng\": 99\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m     },\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m         \"train\": {\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m         },\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m         \"test\": {\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m         }\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m     },\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m     \"job_name\": \"pytorch-training-2022-05-21-13-37-08-541\",\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m     \"master_hostname\": \"algo-1-1ticz\",\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-057716757052/pytorch-training-2022-05-21-13-37-08-541/source/sourcedir.tar.gz\",\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m     \"module_name\": \"train\",\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m     \"num_cpus\": 8,\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m     \"num_gpus\": 1,\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m         \"current_host\": \"algo-1-1ticz\",\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m         \"hosts\": [\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m             \"algo-1-1ticz\"\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m         ]\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m     },\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m     \"user_entry_point\": \"train.py\"\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m }\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m \n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m Environment variables:\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m \n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m SM_HOSTS=[\"algo-1-1ticz\"]\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m SM_HPS={\"batch_size\":256,\"dropout\":0.0,\"epochs\":1,\"factor_num\":32,\"lr\":0.001,\"num_layers\":3,\"num_ng\":4,\"test_num_ng\":99,\"top_k\":10}\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m SM_USER_ENTRY_POINT=train.py\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-1ticz\",\"hosts\":[\"algo-1-1ticz\"]}\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m SM_INPUT_DATA_CONFIG={\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m SM_CHANNELS=[\"test\",\"train\"]\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m SM_CURRENT_HOST=algo-1-1ticz\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m SM_MODULE_NAME=train\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m SM_NUM_CPUS=8\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m SM_NUM_GPUS=1\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-057716757052/pytorch-training-2022-05-21-13-37-08-541/source/sourcedir.tar.gz\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1-1ticz\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1-1ticz\"],\"hyperparameters\":{\"batch_size\":256,\"dropout\":0.0,\"epochs\":1,\"factor_num\":32,\"lr\":0.001,\"num_layers\":3,\"num_ng\":4,\"test_num_ng\":99,\"top_k\":10},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2022-05-21-13-37-08-541\",\"log_level\":20,\"master_hostname\":\"algo-1-1ticz\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-057716757052/pytorch-training-2022-05-21-13-37-08-541/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-1ticz\",\"hosts\":[\"algo-1-1ticz\"]},\"user_entry_point\":\"train.py\"}\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m SM_USER_ARGS=[\"--batch_size\",\"256\",\"--dropout\",\"0.0\",\"--epochs\",\"1\",\"--factor_num\",\"32\",\"--lr\",\"0.001\",\"--num_layers\",\"3\",\"--num_ng\",\"4\",\"--test_num_ng\",\"99\",\"--top_k\",\"10\"]\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m SM_CHANNEL_TEST=/opt/ml/input/data/test\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m SM_HP_EPOCHS=1\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m SM_HP_LR=0.001\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m SM_HP_BATCH_SIZE=256\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m SM_HP_TOP_K=10\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m SM_HP_DROPOUT=0.0\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m SM_HP_FACTOR_NUM=32\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m SM_HP_NUM_LAYERS=3\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m SM_HP_NUM_NG=4\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m SM_HP_TEST_NUM_NG=99\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m \n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m \n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m /opt/conda/bin/python3.6 train.py --batch_size 256 --dropout 0.0 --epochs 1 --factor_num 32 --lr 0.001 --num_layers 3 --num_ng 4 --test_num_ng 99 --top_k 10\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m \n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m \n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m args: \n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m  Namespace(batch_size=256, dropout=0.0, epochs=1, factor_num=32, gpu='0', lr=0.001, model_dir='/opt/ml/model', num_layers=3, num_ng=4, out=True, test_data_dir='/opt/ml/input/data/test', test_num_ng=99, top_k=10, train_data_dir='/opt/ml/input/data/train')\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m device:  cuda\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m args.train_data_dir:  /opt/ml/input/data/train\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m args.test_data_dir:  /opt/ml/input/data/test\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m args.model_dir:  /opt/ml/model\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m =====> data loading <===========\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m =====> create data loader <===========\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m Pretrained model is NOT used\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m =====> Staring Traiing <===========\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m [2022-05-21 13:37:54.819 algo-1-1ticz:32 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m [2022-05-21 13:37:54.863 algo-1-1ticz:32 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m The time elapse of epoch 000 is: 00: 02: 28\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m HR: 0.630\tNDCG: 0.367\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m the model is saved at /opt/ml/model/NeuMF-end.pth\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m End. Best epoch 000: HR = 0.630, NDCG = 0.367\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m \n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz |\u001b[0m 2022-05-21 13:40:13,314 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "\u001b[36mcewpqtd5wr-algo-1-1ticz exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "\n",
    "local_estimator = PyTorch(\n",
    "    entry_point=\"train.py\",    \n",
    "    source_dir='src',    \n",
    "    role=role,\n",
    "    framework_version='1.8.1',\n",
    "    py_version='py3',\n",
    "    instance_count=1,\n",
    "    instance_type=instance_type, # local_gpu or local 지정\n",
    "    session = sagemaker.LocalSession(), # 로컬 세션을 사용합니다.\n",
    "    hyperparameters= hyperparameters               \n",
    "    \n",
    ")\n",
    "local_estimator.fit(local_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. SageMaker Host Mode 로 훈련\n",
    "- instance_type, session 을 수정 합니다.\n",
    "- 입력 데이터를 inputs로서 S3 의 경로를 제공합니다.\n",
    "- wait=False 로 지정해서 async 모드로 훈련을 실행합니다. \n",
    "- 실행 경과는 아래의 cifar10_estimator.logs() 에서 확인 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. 데이터 세트를 S3에 업로드\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3_data_loc:  s3://sagemaker-us-east-1-057716757052/NCFModel/data\n"
     ]
    }
   ],
   "source": [
    "s3_data_loc = sagemaker_session.upload_data(path=config.main_path, bucket=bucket, \n",
    "                                       key_prefix=f\"{prefix}/data\")\n",
    "print(\"s3_data_loc: \", s3_data_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-21 07:03:58     128039 NCFModel/data/.ipynb_checkpoints/ml-1m.test-checkpoint.rating\n",
      "2022-05-21 13:40:46    2891424 NCFModel/data/ml-1m.test.negative\n",
      "2022-05-21 13:40:43     128039 NCFModel/data/ml-1m.test.rating\n",
      "2022-05-21 13:40:44   20982911 NCFModel/data/ml-1m.train.rating\n",
      "2022-05-21 07:03:58   27404899 NCFModel/data/pinterest-20.test.negative\n",
      "2022-05-21 07:03:54     807267 NCFModel/data/pinterest-20.test.rating\n",
      "2022-05-21 07:03:55   21138451 NCFModel/data/pinterest-20.train.rating\n"
     ]
    }
   ],
   "source": [
    "! aws s3 ls {s3_data_loc} --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. 훈련 및 테스트 데이터를 S3 로 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3_inputs: \n",
      " {'train': 's3://sagemaker-us-east-1-057716757052/NCFModel/data', 'test': 's3://sagemaker-us-east-1-057716757052/NCFModel/data'}\n"
     ]
    }
   ],
   "source": [
    "s3_inputs = {\n",
    "            'train': f'{s3_data_loc}',\n",
    "            'test': f'{s3_data_loc}'\n",
    "            }\n",
    "\n",
    "print(\"s3_inputs: \\n\", s3_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 훈련 실행\n",
    "- epochs 값을 조절해서 실행 시간을 조정 하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_hyperparameters = {'epochs': 10, \n",
    "                       'lr': 0.001,\n",
    "                       'batch_size': 256,\n",
    "                       'top_k' : 10,\n",
    "                       'dropout' : 0.0,\n",
    "                       'factor_num' : 32,\n",
    "                       'num_layers' : 3,\n",
    "                       'num_ng' : 4,\n",
    "                       'test_num_ng' : 99,                   \n",
    "                    }  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "instance_type = 'ml.p3.2xlarge'\n",
    "\n",
    "host_estimator = PyTorch(\n",
    "    entry_point=\"train.py\",    \n",
    "    source_dir='src',    \n",
    "    role=role,\n",
    "    framework_version='1.8.1',\n",
    "    py_version='py3',\n",
    "    instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    session = sagemaker.Session(), # 세이지 메이커 세션\n",
    "    hyperparameters=host_hyperparameters\n",
    "    \n",
    ")\n",
    "host_estimator.fit(s3_inputs, wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-21 14:50:07 Starting - Preparing the instances for training\n",
      "2022-05-21 14:50:07 Downloading - Downloading input data\n",
      "2022-05-21 14:50:07 Training - Training image download completed. Training in progress.\n",
      "2022-05-21 14:50:07 Uploading - Uploading generated training model\n",
      "2022-05-21 14:50:07 Completed - Training job completed\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2022-05-21 13:48:40,935 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2022-05-21 13:48:40,958 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2022-05-21 13:48:40,966 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2022-05-21 13:48:41,447 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: nvidia-ml-py3==7.352 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (7.352.0)\u001b[0m\n",
      "\u001b[34mCollecting pandas==0.24.2\n",
      "  Downloading pandas-0.24.2-cp36-cp36m-manylinux1_x86_64.whl (10.1 MB)\u001b[0m\n",
      "\u001b[34mCollecting numpy==1.16.6\n",
      "  Downloading numpy-1.16.6-cp36-cp36m-manylinux1_x86_64.whl (17.4 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch==1.8.1 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 4)) (1.8.1)\u001b[0m\n",
      "\u001b[34mCollecting torchsummary==1.5.1\n",
      "  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting gensim==3.7.1\n",
      "  Downloading gensim-3.7.1-cp36-cp36m-manylinux1_x86_64.whl (24.2 MB)\u001b[0m\n",
      "\u001b[34mCollecting tensorboardX==1.6\n",
      "  Downloading tensorboardX-1.6-py2.py3-none-any.whl (129 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2011k in /opt/conda/lib/python3.6/site-packages (from pandas==0.24.2->-r requirements.txt (line 2)) (2021.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.5.0 in /opt/conda/lib/python3.6/site-packages (from pandas==0.24.2->-r requirements.txt (line 2)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.6/site-packages (from torch==1.8.1->-r requirements.txt (line 4)) (3.10.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from torch==1.8.1->-r requirements.txt (line 4)) (0.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.6/site-packages (from gensim==3.7.1->-r requirements.txt (line 6)) (1.5.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5.0 in /opt/conda/lib/python3.6/site-packages (from gensim==3.7.1->-r requirements.txt (line 6)) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: smart-open>=1.7.0 in /opt/conda/lib/python3.6/site-packages (from gensim==3.7.1->-r requirements.txt (line 6)) (5.2.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf>=3.2.0 in /opt/conda/lib/python3.6/site-packages (from tensorboardX==1.6->-r requirements.txt (line 7)) (3.19.1)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: numpy, torchsummary, tensorboardX, pandas, gensim\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.1\n",
      "    Uninstalling numpy-1.19.1:\n",
      "      Successfully uninstalled numpy-1.19.1\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.1.5\n",
      "    Uninstalling pandas-1.1.5:\u001b[0m\n",
      "\u001b[34m      Successfully uninstalled pandas-1.1.5\u001b[0m\n",
      "\u001b[34mSuccessfully installed gensim-3.7.1 numpy-1.16.6 pandas-0.24.2 tensorboardX-1.6 torchsummary-1.5.1\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m2022-05-21 13:48:56,879 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch_size\": 256,\n",
      "        \"dropout\": 0.0,\n",
      "        \"epochs\": 20,\n",
      "        \"factor_num\": 32,\n",
      "        \"lr\": 0.001,\n",
      "        \"num_layers\": 3,\n",
      "        \"num_ng\": 4,\n",
      "        \"test_num_ng\": 99,\n",
      "        \"top_k\": 10\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2022-05-21-13-41-33-332\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-057716757052/pytorch-training-2022-05-21-13-41-33-332/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p3.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p3.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch_size\":256,\"dropout\":0.0,\"epochs\":20,\"factor_num\":32,\"lr\":0.001,\"num_layers\":3,\"num_ng\":4,\"test_num_ng\":99,\"top_k\":10}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-057716757052/pytorch-training-2022-05-21-13-41-33-332/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch_size\":256,\"dropout\":0.0,\"epochs\":20,\"factor_num\":32,\"lr\":0.001,\"num_layers\":3,\"num_ng\":4,\"test_num_ng\":99,\"top_k\":10},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2022-05-21-13-41-33-332\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-057716757052/pytorch-training-2022-05-21-13-41-33-332/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch_size\",\"256\",\"--dropout\",\"0.0\",\"--epochs\",\"20\",\"--factor_num\",\"32\",\"--lr\",\"0.001\",\"--num_layers\",\"3\",\"--num_ng\",\"4\",\"--test_num_ng\",\"99\",\"--top_k\",\"10\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH_SIZE=256\u001b[0m\n",
      "\u001b[34mSM_HP_DROPOUT=0.0\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=20\u001b[0m\n",
      "\u001b[34mSM_HP_FACTOR_NUM=32\u001b[0m\n",
      "\u001b[34mSM_HP_LR=0.001\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_LAYERS=3\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_NG=4\u001b[0m\n",
      "\u001b[34mSM_HP_TEST_NUM_NG=99\u001b[0m\n",
      "\u001b[34mSM_HP_TOP_K=10\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 train.py --batch_size 256 --dropout 0.0 --epochs 20 --factor_num 32 --lr 0.001 --num_layers 3 --num_ng 4 --test_num_ng 99 --top_k 10\u001b[0m\n",
      "\u001b[34margs: \n",
      " Namespace(batch_size=256, dropout=0.0, epochs=20, factor_num=32, gpu='0', lr=0.001, model_dir='/opt/ml/model', num_layers=3, num_ng=4, out=True, test_data_dir='/opt/ml/input/data/test', test_num_ng=99, top_k=10, train_data_dir='/opt/ml/input/data/train')\u001b[0m\n",
      "\u001b[34mdevice:  cuda\u001b[0m\n",
      "\u001b[34margs.train_data_dir:  /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34margs.test_data_dir:  /opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34margs.model_dir:  /opt/ml/model\u001b[0m\n",
      "\u001b[34m=====> data loading <===========\u001b[0m\n",
      "\u001b[34m=====> create data loader <===========\u001b[0m\n",
      "\u001b[34mPretrained model is NOT used\u001b[0m\n",
      "\u001b[34m=====> Staring Traiing <===========\u001b[0m\n",
      "\u001b[34m[2022-05-21 13:49:36.457 algo-1:32 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2022-05-21 13:49:36.571 algo-1:32 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2022-05-21 13:49:36.572 algo-1:32 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2022-05-21 13:49:36.573 algo-1:32 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2022-05-21 13:49:36.573 algo-1:32 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2022-05-21 13:49:36.573 algo-1:32 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2022-05-21 13:49:38.163 algo-1:32 INFO hook.py:591] name:embed_user_GMF.weight count_params:193280\u001b[0m\n",
      "\u001b[34m[2022-05-21 13:49:38.163 algo-1:32 INFO hook.py:591] name:embed_item_GMF.weight count_params:118592\u001b[0m\n",
      "\u001b[34m[2022-05-21 13:49:38.163 algo-1:32 INFO hook.py:591] name:embed_user_MLP.weight count_params:773120\u001b[0m\n",
      "\u001b[34m[2022-05-21 13:49:38.163 algo-1:32 INFO hook.py:591] name:embed_item_MLP.weight count_params:474368\u001b[0m\n",
      "\u001b[34m[2022-05-21 13:49:38.163 algo-1:32 INFO hook.py:591] name:MLP_layers.1.weight count_params:32768\u001b[0m\n",
      "\u001b[34m[2022-05-21 13:49:38.163 algo-1:32 INFO hook.py:591] name:MLP_layers.1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2022-05-21 13:49:38.164 algo-1:32 INFO hook.py:591] name:MLP_layers.4.weight count_params:8192\u001b[0m\n",
      "\u001b[34m[2022-05-21 13:49:38.164 algo-1:32 INFO hook.py:591] name:MLP_layers.4.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2022-05-21 13:49:38.164 algo-1:32 INFO hook.py:591] name:MLP_layers.7.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[2022-05-21 13:49:38.164 algo-1:32 INFO hook.py:591] name:MLP_layers.7.bias count_params:32\u001b[0m\n",
      "\u001b[34m[2022-05-21 13:49:38.164 algo-1:32 INFO hook.py:591] name:predict_layer.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2022-05-21 13:49:38.164 algo-1:32 INFO hook.py:591] name:predict_layer.bias count_params:1\u001b[0m\n",
      "\u001b[34m[2022-05-21 13:49:38.164 algo-1:32 INFO hook.py:593] Total Trainable Params: 1602657\u001b[0m\n",
      "\u001b[34m[2022-05-21 13:49:38.164 algo-1:32 INFO hook.py:425] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2022-05-21 13:49:38.167 algo-1:32 INFO hook.py:488] Hook is writing from the hook with pid: 32\u001b[0m\n",
      "\u001b[34mThe time elapse of epoch 000 is: 00: 03: 00\u001b[0m\n",
      "\u001b[34mHR: 0.629#011NDCG: 0.361\u001b[0m\n",
      "\u001b[34mthe model is saved at /opt/ml/model/NeuMF-end.pth\u001b[0m\n",
      "\u001b[34mThe time elapse of epoch 001 is: 00: 02: 58\u001b[0m\n",
      "\u001b[34mHR: 0.668#011NDCG: 0.394\u001b[0m\n",
      "\u001b[34mThe time elapse of epoch 002 is: 00: 02: 57\u001b[0m\n",
      "\u001b[34mHR: 0.684#011NDCG: 0.408\u001b[0m\n",
      "\u001b[34mThe time elapse of epoch 003 is: 00: 02: 58\u001b[0m\n",
      "\u001b[34mHR: 0.688#011NDCG: 0.411\u001b[0m\n",
      "\u001b[34mThe time elapse of epoch 004 is: 00: 02: 58\u001b[0m\n",
      "\u001b[34mHR: 0.692#011NDCG: 0.413\u001b[0m\n",
      "\u001b[34mThe time elapse of epoch 005 is: 00: 02: 58\u001b[0m\n",
      "\u001b[34mHR: 0.696#011NDCG: 0.420\u001b[0m\n",
      "\u001b[34mThe time elapse of epoch 006 is: 00: 02: 57\u001b[0m\n",
      "\u001b[34mHR: 0.692#011NDCG: 0.416\u001b[0m\n",
      "\u001b[34mThe time elapse of epoch 007 is: 00: 02: 58\u001b[0m\n",
      "\u001b[34mHR: 0.696#011NDCG: 0.419\u001b[0m\n",
      "\u001b[34mThe time elapse of epoch 008 is: 00: 02: 56\u001b[0m\n",
      "\u001b[34mHR: 0.695#011NDCG: 0.424\u001b[0m\n",
      "\u001b[34mThe time elapse of epoch 009 is: 00: 02: 56\u001b[0m\n",
      "\u001b[34mHR: 0.696#011NDCG: 0.421\u001b[0m\n",
      "\u001b[34mThe time elapse of epoch 010 is: 00: 03: 00\u001b[0m\n",
      "\u001b[34mHR: 0.689#011NDCG: 0.421\u001b[0m\n",
      "\u001b[34mThe time elapse of epoch 011 is: 00: 02: 57\u001b[0m\n",
      "\u001b[34mHR: 0.693#011NDCG: 0.419\u001b[0m\n",
      "\u001b[34mThe time elapse of epoch 012 is: 00: 02: 55\u001b[0m\n",
      "\u001b[34mHR: 0.692#011NDCG: 0.420\u001b[0m\n",
      "\u001b[34mThe time elapse of epoch 013 is: 00: 02: 58\u001b[0m\n",
      "\u001b[34mHR: 0.692#011NDCG: 0.419\u001b[0m\n",
      "\u001b[34mThe time elapse of epoch 014 is: 00: 02: 57\u001b[0m\n",
      "\u001b[34mHR: 0.685#011NDCG: 0.417\u001b[0m\n",
      "\u001b[34mThe time elapse of epoch 015 is: 00: 02: 59\u001b[0m\n",
      "\u001b[34mHR: 0.680#011NDCG: 0.415\u001b[0m\n",
      "\u001b[34mThe time elapse of epoch 016 is: 00: 02: 56\u001b[0m\n",
      "\u001b[34mHR: 0.674#011NDCG: 0.411\u001b[0m\n",
      "\u001b[34mThe time elapse of epoch 017 is: 00: 02: 58\u001b[0m\n",
      "\u001b[34mHR: 0.674#011NDCG: 0.410\u001b[0m\n",
      "\u001b[34mThe time elapse of epoch 018 is: 00: 02: 57\u001b[0m\n",
      "\u001b[34mHR: 0.680#011NDCG: 0.414\u001b[0m\n",
      "\u001b[34mThe time elapse of epoch 019 is: 00: 03: 00\u001b[0m\n",
      "\u001b[34mHR: 0.673#011NDCG: 0.408\u001b[0m\n",
      "\u001b[34mEnd. Best epoch 009: HR = 0.696, NDCG = 0.421\u001b[0m\n",
      "\u001b[34m2022-05-21 14:48:47,320 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "Training seconds: 3976\n",
      "Billable seconds: 3976\n",
      "CPU times: user 43 ms, sys: 13.1 ms, total: 56.2 ms\n",
      "Wall time: 466 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "host_estimator.logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 모델 아티펙트 저장\n",
    "- S3 에 저장된 모델 아티펙트를 저장하여 추론시 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artifact_path:  s3://sagemaker-us-east-1-057716757052/pytorch-training-2022-05-21-13-41-33-332/output/model.tar.gz\n",
      "Stored 'artifact_path' (str)\n"
     ]
    }
   ],
   "source": [
    "artifact_path = host_estimator.model_data\n",
    "print(\"artifact_path: \", artifact_path)\n",
    "\n",
    "%store artifact_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기타 변수 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'bucket' (str)\n",
      "Stored 'prefix' (str)\n"
     ]
    }
   ],
   "source": [
    "%store bucket \n",
    "%store prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
